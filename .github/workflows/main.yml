# -----------------------------------------------------------------------------------
# Persistent VPS (Immortal Edition) - SMART FAST BACKUP VERSION
#
# v12.1 - Smart selective backup - 10x faster, only backs up essential data
# -----------------------------------------------------------------------------------

name: Persistent VPS (Immortal Edition)

on:
  schedule:
    - cron: '0 */4 * * *'
  workflow_dispatch:
    inputs:
      force_fresh_install:
        description: 'Force fresh installation (ignore backups)'
        required: false
        default: 'false'
        type: boolean
      backup_retention_days:
        description: 'Backup retention days'
        required: false
        default: '7'
        type: string
      session_duration_minutes:
        description: 'Session duration in minutes'
        required: false
        default: '220'
        type: string

env:
  BACKUP_STORE: /tmp/vps-backups
  SMART_BACKUP_NAME: smart-selective-backup.tar.zst
  MEGA_REMOTE: mega:vps-backup

jobs:
  vps:
    runs-on: ubuntu-22.04
    timeout-minutes: 235
    permissions:
      contents: read
      actions: write

    steps:
      - name: '🚀 Initialize Environment'
        uses: actions/checkout@v4

      - name: '🔧 Install Enhanced Toolchain'
        run: |
          set -euo pipefail
          echo "Installing enhanced toolchain..."
          
          sudo apt-get update -qq
          sudo DEBIAN_FRONTEND=noninteractive apt-get install -y \
            zstd pv rsync jq curl wget psmisc screen tmate \
            htop fail2ban ufw python3-pip tree fuse \
            software-properties-common apt-transport-https ca-certificates \
            gnupg lsb-release
          
          curl -fsSL https://rclone.org/install.sh | sudo bash
          pip3 install --user psutil requests
          
          rclone version
          zstd --version
          echo "✅ Enhanced toolchain installed successfully."

      - name: '🔐 Configure Rclone'
        run: |
          set -euo pipefail
          
          if [[ -z "${{ secrets.RCLONE_CONFIG || '' }}" ]]; then
            echo "❌ CRITICAL: RCLONE_CONFIG secret is missing!" >&2
            exit 1
          fi
          
          mkdir -p ~/.config/rclone
          echo "${{ secrets.RCLONE_CONFIG }}" > ~/.config/rclone/rclone.conf
          chmod 600 ~/.config/rclone/rclone.conf
          
          if ! rclone listremotes | grep -q "mega:"; then
            echo "❌ CRITICAL: Rclone MEGA remote not configured properly!" >&2
            exit 1
          fi
          
          echo "✅ Rclone configured and tested successfully."

      - name: '🔍 Smart Backup Discovery'
        id: discover_backup
        run: |
          set -euo pipefail
          echo "🔎 Looking for previous smart backups..."
          
          BACKUP_FOUND=false
          BACKUP_SOURCE=""
          BACKUP_URL=""
          
          if [[ "${{ github.event.inputs.force_fresh_install || 'false' }}" == "true" ]]; then
            echo "🔄 Fresh installation forced by user."
            echo "backup_found=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          WORKFLOW_ID=$(curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            "https://api.github.com/repos/${{ github.repository }}/actions/workflows" \
            | jq -r '.workflows[] | select(.name == "Persistent VPS (Immortal Edition)") | .id' | head -1)
          
          if [[ -n "$WORKFLOW_ID" && "$WORKFLOW_ID" != "null" ]]; then
            LATEST_RUN_ID=$(curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
              "https://api.github.com/repos/${{ github.repository }}/actions/workflows/${WORKFLOW_ID}/runs?status=success&per_page=5" \
              | jq -r '.workflow_runs[] | select(.id != ${{ github.run_id }}) | .id' | head -1)
            
            if [[ -n "$LATEST_RUN_ID" && "$LATEST_RUN_ID" != "null" ]]; then
              ARTIFACTS_JSON=$(curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
                "https://api.github.com/repos/${{ github.repository }}/actions/runs/${LATEST_RUN_ID}/artifacts")
              
              SMART_ARTIFACT_ID=$(echo "$ARTIFACTS_JSON" | jq -r ".artifacts[] | select(.name | contains(\"smart\")) | .id" | head -1)
              if [[ -n "$SMART_ARTIFACT_ID" && "$SMART_ARTIFACT_ID" != "null" ]]; then
                BACKUP_URL="https://api.github.com/repos/${{ github.repository }}/actions/artifacts/${SMART_ARTIFACT_ID}/zip"
                BACKUP_SOURCE="github_artifact"
                BACKUP_FOUND=true
              fi
            fi
          fi
          
          if [[ "$BACKUP_FOUND" == "false" ]] && rclone ls "${MEGA_REMOTE}/smart_backup_link.txt" >/dev/null 2>&1; then
            BACKUP_URL=$(rclone cat "${MEGA_REMOTE}/smart_backup_link.txt" | head -1)
            BACKUP_SOURCE="mega_link"
            BACKUP_FOUND=true
          fi
          
          echo "backup_found=$BACKUP_FOUND" >> $GITHUB_OUTPUT
          echo "backup_source=$BACKUP_SOURCE" >> $GITHUB_OUTPUT
          echo "backup_url=$BACKUP_URL" >> $GITHUB_OUTPUT
          
          if [[ "$BACKUP_FOUND" == "true" ]]; then
            echo "✅ Smart backup found from $BACKUP_SOURCE"
          else
            echo "ℹ️ No previous smart backup found. Will perform fresh installation."
          fi

      - name: '🔄 Smart System Restoration'
        if: steps.discover_backup.outputs.backup_found == 'true'
        run: |
          set -euo pipefail
          echo "🚀 Restoring from smart selective backup..."
          
          sudo mkdir -p /mnt/restore
          cd /mnt/restore
          
          max_attempts=3
          for attempt in $(seq 1 $max_attempts); do
            echo "Download attempt $attempt/$max_attempts..."
            if timeout 600 curl --retry 3 -L \
              -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
              "${{ steps.discover_backup.outputs.backup_url }}" -o "backup.zip"; then
              break
            fi
            if [[ $attempt -eq $max_attempts ]]; then
              echo "❌ Download failed after $max_attempts attempts!" >&2
              exit 1
            fi
            sleep 30
          done
          
          sudo unzip -q backup.zip
          BACKUP_FILE=$(find . -name "*.tar.zst" -type f | head -1)
          
          if [[ ! -f "$BACKUP_FILE" ]] || ! zstd -t "$BACKUP_FILE"; then
            echo "❌ Backup file invalid!" >&2
            exit 1
          fi
          
          echo "✅ Backup verified (Size: $(du -h "$BACKUP_FILE" | cut -f1))"
          echo "🔄 Restoring selective backup (this is fast)..."
          
          pv "$BACKUP_FILE" | sudo tar -I zstd -xpf - -C / --exclude='./tmp/*' --exclude='./proc/*' --exclude='./sys/*'
          
          sudo rm -rf /mnt/restore
          echo "✅ Smart restoration completed successfully."

      - name: '🛠️ Post-Restoration System Repair'
        if: steps.discover_backup.outputs.backup_found == 'true'
        run: |
          set -euo pipefail
          echo "🔧 Performing post-restoration repairs..."
          
          sudo apt-get update -qq || true
          
          if ! command -v docker >/dev/null 2>&1; then
            curl -fsSL https://get.docker.com | sudo sh
          fi
          
          for service in ssh docker mariadb fail2ban; do
            if systemctl list-unit-files --type=service | grep -q "^${service}\.service"; then
              sudo systemctl daemon-reload
              sudo systemctl enable "$service" 2>/dev/null || true
              sudo systemctl restart "$service" 2>/dev/null || true
            fi
          done
          
          if [[ -d "/var/lib/mysql" ]]; then
            sudo chown -R mysql:mysql /var/lib/mysql
            sudo systemctl restart mariadb 2>/dev/null || true
          fi
          
          if [[ -f "/tmp/db_dumps/all_databases.sql" ]]; then
            echo "Restoring database from dump..."
            sudo mysql < /tmp/db_dumps/all_databases.sql || echo "⚠️ Database restore failed"
            sudo rm -rf /tmp/db_dumps
          fi
          
          if [[ -d "/tmp/docker_backup" ]] && command -v docker >/dev/null 2>&1; then
            echo "Importing Docker containers..."
            for container_file in /tmp/docker_backup/*.tar.gz; do
              if [[ -f "$container_file" ]]; then
                container_name=$(basename "$container_file" .tar.gz)
                gunzip -c "$container_file" | docker import - "$container_name" || true
              fi
            done
            sudo rm -rf /tmp/docker_backup
          fi
          
          if [[ -f "/www/server/panel/init.sh" ]]; then
            sudo /www/server/panel/init.sh restart || true
          fi
          
          echo "✅ Post-restoration repair completed."

      - name: '🆕 Enhanced Fresh Installation'
        if: steps.discover_backup.outputs.backup_found == 'false'
        run: |
          set -euo pipefail
          echo "🚀 Performing fresh installation..."
          
          if ! command -v docker >/dev/null 2>&1; then
            curl -fsSL https://get.docker.com | sudo sh
            sudo usermod -aG docker "$USER"
          fi
          
          sudo DEBIAN_FRONTEND=noninteractive apt-get install -y \
            mariadb-server fail2ban ufw openssh-server nginx
          
          if curl -fsSL -o /tmp/install_aapanel.sh "http://www.aapanel.com/script/install-ubuntu_6.0_en.sh"; then
            chmod +x /tmp/install_aapanel.sh
            timeout 1200 bash -c "printf 'y\nyes\n' | sudo bash /tmp/install_aapanel.sh" || \
              echo "⚠️ aaPanel installation timed out"
          fi
          
          echo "✅ Fresh installation completed."

      - name: '🔐 Security & User Setup'
        if: steps.discover_backup.outputs.backup_found == 'false'
        run: |
          set -euo pipefail
          echo "🔐 Setting up security..."
          
          if ! id "jacky" >/dev/null 2>&1; then
            sudo useradd -m -s /bin/bash -G sudo,docker jacky
            if [[ -n "${{ secrets.USER_PASSWORD || '' }}" ]]; then
              echo "jacky:${{ secrets.USER_PASSWORD }}" | sudo chpasswd
              echo "jacky ALL=(ALL:ALL) NOPASSWD:ALL" | sudo tee /etc/sudoers.d/jacky
            fi
          fi
          
          if systemctl is-active --quiet mariadb && [[ -n "${{ secrets.DB_ROOT_PASSWORD || '' }}" ]]; then
            sudo mysql -e "ALTER USER 'root'@'localhost' IDENTIFIED VIA mysql_native_password USING PASSWORD('${{ secrets.DB_ROOT_PASSWORD }}'); FLUSH PRIVILEGES;" || true
          fi
          
          if [[ -f "/www/server/panel/init.sh" ]]; then
            timeout 30 bash -c 'echo "Jacky" | sudo bt 6' || true
            timeout 30 bash -c 'echo "spidey" | sudo bt 5' || true
          fi
          
          sudo ufw --force reset
          sudo ufw default deny incoming
          sudo ufw default allow outgoing
          sudo ufw allow ssh
          sudo ufw allow http
          sudo ufw allow https
          sudo ufw allow 8888/tcp
          sudo ufw --force enable
          
          for service in fail2ban ssh mariadb docker nginx; do
            if systemctl list-unit-files --type=service | grep -q "^${service}\.service"; then
              sudo systemctl enable --now "$service" 2>/dev/null || true
            fi
          done
          
          echo "✅ Security setup completed."

      - name: '🌐 Configure Network Access'
        run: |
          set -euo pipefail
          echo "🌐 Setting up network access..."
          
          if ! command -v tailscale >/dev/null 2>&1; then
            curl -fsSL https://tailscale.com/install.sh | sh
          fi
          
          if [[ -n "${{ secrets.TAILSCALE_AUTHKEY || '' }}" ]]; then
            sudo systemctl enable --now tailscaled
            if [[ -f "/var/lib/tailscale/tailscaled.state" ]]; then
              sudo tailscale up --accept-routes || true
            else
              sudo tailscale up \
                --authkey="${{ secrets.TAILSCALE_AUTHKEY }}" \
                --hostname="github-vps-smart-$(date +%s)" \
                --reset --accept-routes || true
            fi
          fi
          
          tmate -S /tmp/tmate.sock new-session -d
          timeout 60 bash -c 'while ! tmate -S /tmp/tmate.sock wait tmate-ready; do sleep 1; done' || true
          
          echo ""
          echo "================================================="
          echo "🎉      SMART VPS IS READY FOR CONNECTION      🎉"
          echo "================================================="
          
          if command -v tailscale >/dev/null 2>&1; then
            TAILSCALE_IP=$(sudo tailscale ip -4 2>/dev/null || echo "Not available")
            echo "🌐 Tailscale IP: $TAILSCALE_IP"
          fi
          
          if tmate -S /tmp/tmate.sock list-sessions >/dev/null 2>&1; then
            TMATE_SSH=$(tmate -S /tmp/tmate.sock display -p '#{tmate_ssh}' 2>/dev/null || echo "Not available")
            echo "🔑 tmate SSH:    $TMATE_SSH"
          fi
          
          if [[ -f "/www/server/panel/init.sh" ]]; then
            echo ""
            echo "📊 aaPanel Information:"
            sudo bt default || true
          fi
          
          echo "================================================="

      - name: '⏳ Session Maintenance'
        run: |
          set -euo pipefail
          echo "⏳ Starting session maintenance..."
          
          SESSION_DURATION_MINUTES=${{ github.event.inputs.session_duration_minutes || '220' }}
          SESSION_DURATION_SECONDS=$((SESSION_DURATION_MINUTES * 60))
          
          log_message() { echo "$(date '+%Y-%m-%d %H:%M:%S') - $1"; }
          
          cat << 'EOF' > /tmp/session_keeper.sh
          #!/bin/bash
          log_message() { echo "$(date '+%Y-%m-%d %H:%M:%S') - $1"; }
          
          while true; do
              for service in ssh tailscaled docker mariadb; do
                  if systemctl list-unit-files --type=service | grep -q "^${service}\.service"; then
                      if systemctl is-enabled --quiet "$service" 2>/dev/null && ! systemctl is-active --quiet "$service"; then
                          log_message "⚠️ $service down, restarting..."
                          sudo systemctl restart "$service"
                      fi
                  fi
              done
              
              if ! tmate -S /tmp/tmate.sock list-sessions >/dev/null 2>&1; then
                  log_message "⚠️ tmate session lost, restarting..."
                  tmate -S /tmp/tmate.sock new-session -d
                  sleep 5
                  tmate -S /tmp/tmate.sock wait tmate-ready
                  log_message "✅ tmate restarted: $(tmate -S /tmp/tmate.sock display -p '#{tmate_ssh}' 2>/dev/null)"
              fi
              
              sleep 300
          done
          EOF
          
          chmod +x /tmp/session_keeper.sh
          nohup bash /tmp/session_keeper.sh > /tmp/session_keeper.log 2>&1 &
          KEEPER_PID=$!
          
          log_message "🖥️ Session started (PID: $KEEPER_PID, Duration: $SESSION_DURATION_MINUTES min)"
          log_message "🛑 To shutdown early: touch /tmp/stop"
          
          END_TIME=$((SECONDS + SESSION_DURATION_SECONDS))
          
          while [ $SECONDS -lt $END_TIME ]; do
            if [ -f "/tmp/stop" ]; then
              log_message "✅ Early shutdown requested"
              sudo rm -f "/tmp/stop"
              break
            fi
            
            REMAINING_MINUTES=$(( (END_TIME - SECONDS) / 60 ))
            if (( SECONDS % 1800 == 0 )); then
              log_message "📊 $REMAINING_MINUTES minutes remaining"
            fi
            
            sleep 60
          done
          
          if kill -0 $KEEPER_PID 2>/dev/null; then
            kill $KEEPER_PID
          fi
          
          log_message "⏰ Session concluded. Starting smart backup..."

---

### **The Critical Fix: Array-Based Backup**
This section shows the core changes that make the workflow more reliable by using a **Bash array** instead of a text file for backup paths. This prevents the `tar` command from failing if a directory doesn't exist.

```yaml
      - name: '📦 Create Super Fast Smart Backup'
        id: create_backup
        if: always()
        run: |
          set -euo pipefail
          echo "📦 Creating super fast smart selective backup..."
          
          mkdir -p "${{ env.BACKUP_STORE }}"
          
          echo "📊 Creating comprehensive system inventory..."
          INVENTORY_DIR="/tmp/system_inventory"
          mkdir -p "$INVENTORY_DIR"
          
          dpkg-query -W -f='${Package}\t${Version}\t${Architecture}\t${Status}\n' > "$INVENTORY_DIR/packages.txt" 2>/dev/null || true
          snap list > "$INVENTORY_DIR/snap_packages.txt" 2>/dev/null || true
          
          if command -v docker >/dev/null 2>&1; then
            docker ps -a --format "table {{.Names}}\t{{.Image}}\t{{.Status}}" > "$INVENTORY_DIR/docker_containers.txt" 2>/dev/null || true
            docker images --format "table {{.Repository}}\t{{.Tag}}\t{{.Size}}" > "$INVENTORY_DIR/docker_images.txt" 2>/dev/null || true
          fi
          
          systemctl list-units --type=service --state=active --no-pager > "$INVENTORY_DIR/active_services.txt" 2>/dev/null || true
          ip addr show > "$INVENTORY_DIR/network.txt" 2>/dev/null || true
          ss -tuln > "$INVENTORY_DIR/ports.txt" 2>/dev/null || true
          df -h > "$INVENTORY_DIR/disk_usage.txt" 2>/dev/null || true
          free -h > "$INVENTORY_DIR/memory.txt" 2>/dev/null || true
          cut -d: -f1,3,4,5,6,7 /etc/passwd > "$INVENTORY_DIR/users.txt" 2>/dev/null || true
          crontab -l > "$INVENTORY_DIR/root_cron.txt" 2>/dev/null || true
          find /var/www /srv /opt /usr/local /home -maxdepth 2 -type d 2>/dev/null | sort > "$INVENTORY_DIR/directories.txt" || true
          
          echo "✅ System inventory completed"
          
          echo "📋 Determining smart backup paths..."
          # Use a Bash array to store paths for a more robust backup process
          BACKUP_PATHS=(
            "/etc"
            "/root"
            "/home"
          )
          
          if [[ -d "/var/www" ]]; then BACKUP_PATHS+=("/var/www"); fi
          if [[ -d "/srv" ]]; then BACKUP_PATHS+=("/srv"); fi
          if [[ -d "/www" ]]; then BACKUP_PATHS+=("/www"); fi
          
          if [[ -d "/var/lib/mysql" ]]; then
            MYSQL_SIZE=$(sudo du -sm /var/lib/mysql 2>/dev/null | cut -f1)
            if [[ ${MYSQL_SIZE:-0} -lt 500 ]]; then
              BACKUP_PATHS+=("/var/lib/mysql");
            else
              echo "Creating database dump (MySQL too large: ${MYSQL_SIZE}MB)..."
              mkdir -p /tmp/db_dumps
              sudo mysqldump --all-databases --single-transaction > /tmp/db_dumps/all_databases.sql 2>/dev/null || true
              BACKUP_PATHS+=("/tmp/db_dumps");
            fi
          fi
          
          if command -v docker >/dev/null 2>&1; then
            mkdir -p /tmp/docker_backup
            echo "Exporting Docker containers..."
            docker ps -q | while read container_id; do
              if [[ -n "$container_id" ]]; then
                container_name=$(docker inspect --format='{{.Name}}' "$container_id" | sed 's/^.//')
                sudo docker export "$container_id" | gzip > "/tmp/docker_backup/${container_name}.tar.gz" 2>/dev/null || true
              fi
            done
            find /home /opt /root -name "docker-compose.y*ml" 2>/dev/null | xargs -I {} sudo cp {} /tmp/docker_backup/ 2>/dev/null || true
            BACKUP_PATHS+=("/tmp/docker_backup");
          fi
          
          if [[ -d "/opt" ]]; then BACKUP_PATHS+=("/opt"); fi
          if [[ -d "/usr/local" ]]; then BACKUP_PATHS+=("/usr/local"); fi
          if [[ -d "/etc/letsencrypt" ]]; then BACKUP_PATHS+=("/etc/letsencrypt"); fi
          
          BACKUP_PATHS+=("/tmp/system_inventory");
          
          echo "✅ Will backup ${#BACKUP_PATHS[@]} essential locations"
          
          echo "🔄 Briefly stopping services for consistent backup..."
          if systemctl is-active --quiet mariadb; then
            sudo systemctl stop mariadb
            echo "mariadb" > /tmp/stopped_services.txt
          fi
          
          sleep 2
          
          BACKUP_FILE="${{ env.BACKUP_STORE }}/${{ env.SMART_BACKUP_NAME }}"
          
          echo "🚀 Creating smart backup (this will be FAST)..."
          START_TIME=$(date +%s)
          
          # Use the array directly for a more reliable backup process
          sudo tar -cf - "${BACKUP_PATHS[@]}" --warning=none --ignore-failed-read 2>/dev/null | zstd -T0 -1 -q > "$BACKUP_FILE" || {
            echo "❌ Smart backup failed during tar/zstd process!" >&2
            exit 1
          }
          
          END_TIME=$(date +%s)
          BACKUP_TIME=$((END_TIME - START_TIME))
          
          if [[ -f /tmp/stopped_services.txt ]]; then
            while read -r service; do
              [[ -n "$service" ]] && sudo systemctl start "$service"
            done < /tmp/stopped_services.txt
          fi
          
          if [[ ! -f "$BACKUP_FILE" ]] || [[ ! -s "$BACKUP_FILE" ]]; then
            echo "❌ Smart backup failed! Creating emergency config backup..."
            BACKUP_FILE="${{ env.BACKUP_STORE }}/emergency-config-backup.tar.zst"
            sudo tar -cf - /etc /root/.bashrc /home 2>/dev/null | zstd -T0 -1 -q > "$BACKUP_FILE"
            ARTIFACT_NAME="emergency-config-backup.tar.zst"
          else
            ARTIFACT_NAME="${{ env.SMART_BACKUP_NAME }}"
          fi
          
          if ! zstd -t "$BACKUP_FILE" 2>/dev/null; then
            echo "❌ Backup corrupted!" >&2
            exit 1
          fi
          
          BACKUP_SIZE=$(du -h "$BACKUP_FILE" | cut -f1)
          
          echo "✅ SMART BACKUP COMPLETED!"
          echo "📊 Size: $BACKUP_SIZE"
          echo "⚡ Time: ${BACKUP_TIME} seconds"
          echo "🎯 Contains: configs, web data, databases, apps, Docker containers, system inventory"
          
          rm -rf /tmp/db_dumps /tmp/docker_backup
          
          echo "backup_file=$BACKUP_FILE" >> $GITHUB_OUTPUT
          echo "artifact_name=$ARTIFACT_NAME" >> $GITHUB_OUTPUT
          echo "backup_size=$BACKUP_SIZE" >> $GITHUB_OUTPUT
          echo "backup_time=${BACKUP_TIME}s" >> $GITHUB_OUTPUT
