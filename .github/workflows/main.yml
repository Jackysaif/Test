# GitHub Actions Workflow: Persistent VPS Session with Backup/Restore and Provisioning
#
# Secrets required:
# - TAILSCALE_AUTHKEY: Tailscale auth key string
# - MEGA_RCLONE: base64-encoded or raw rclone config text for MEGA remote
# - DB_ROOT_PASSWORD: MariaDB root password
#
# This workflow runs on ubuntu-22.04, triggered by workflow_dispatch and every 6 hours.
# It attempts to restore VPS state from GitHub artifact or MEGA backup, or provisions fresh.
# It runs a ~6 hour session with periodic graceful shutdown detection and backup.
# Backups include selected persistent directories and service states.
# Uses only built-in and public actions, with robust error handling and comments.

name: VPS Persistent Session

on:
  workflow_dispatch:
  schedule:
    - cron: '0 */6 * * *'  # every 6 hours

jobs:
  vps:
    name: VPS Persistent Session
    runs-on: ubuntu-22.04
    timeout-minutes: 400  # ~6h + overhead (~6h40m)
    env:
      # Directories to backup (relative to root)
      BACKUP_DIRS: "/home /root /etc/apt /etc/nginx /etc/ssh /etc/aaPanel /var/www /opt /root/.config/aaPanel /var/lib/aaPanel /var/lib/mysql /var/lib/tailscale /var/lib/docker"
      # Backup artifact name pattern
      BACKUP_ARTIFACT_NAME: vps-backup.tar.gz
      # Backup folder on MEGA remote
      MEGA_BACKUP_FOLDER: vps-backups
      # User and password for sudo user
      SUDO_USER: jacky
      SUDO_PASS: spidey
      # aaPanel installer URL (will be fetched dynamically)
      AAPANEL_INSTALLER_URL: ""
      # Temporary working directory for restore/backup
      WORKDIR: ${{ runner.temp }}/vps-workdir
      # rclone config path
      RCLONE_CONF: ${{ github.workspace }}/.config/rclone/rclone.conf

    steps:
      # 1. Checkout repo
      - name: Checkout repository
        uses: actions/checkout@v4

      # 2. Prepare environment: install packages, decode rclone config, install tailscale, tmate
      - name: Prepare environment and install dependencies
        shell: bash
        run: |
          set -euo pipefail

          echo "Installing required packages: rclone, jq, tar, gzip, expect, mariadb-server, curl, gnupg, lsb-release"
          sudo apt-get update
          sudo apt-get install -y rclone jq tar gzip expect mariadb-server curl gnupg lsb-release tmate

          # Install tailscale official repo and tailscale
          if ! command -v tailscale &>/dev/null; then
            echo "Installing Tailscale..."
            curl -fsSL https://pkgs.tailscale.com/stable/ubuntu/jammy.gpg | sudo tee /usr/share/keyrings/tailscale-archive-keyring.gpg >/dev/null
            echo "deb [signed-by=/usr/share/keyrings/tailscale-archive-keyring.gpg] https://pkgs.tailscale.com/stable/ubuntu jammy main" | sudo tee /etc/apt/sources.list.d/tailscale.list
            sudo apt-get update
            sudo apt-get install -y tailscale
          fi

          # Prepare rclone config directory
          mkdir -p ~/.config/rclone

          # Decode MEGA_RCLONE secret (try base64 decode, fallback to raw)
          echo "Decoding MEGA_RCLONE secret to rclone config..."
          if echo "${{ secrets.MEGA_RCLONE }}" | base64 --decode &>/dev/null; then
            echo "${{ secrets.MEGA_RCLONE }}" | base64 --decode > ~/.config/rclone/rclone.conf
          else
            echo "${{ secrets.MEGA_RCLONE }}" > ~/.config/rclone/rclone.conf
          fi
          chmod 600 ~/.config/rclone/rclone.conf

          # Create working directory
          mkdir -p "$WORKDIR"

          # Fetch latest aaPanel installer URL dynamically
          echo "Fetching latest aaPanel v7.0 installer URL..."
          AAPANEL_INSTALLER_URL=$(curl -fsSL https://www.aapanel.com/script/install-ubuntu_7.0_en.sh | grep -oP 'https://download\.aaPanel\.com/.*?install-ubuntu_7\.0_en\.sh' | head -1)
          if [[ -z "$AAPANEL_INSTALLER_URL" ]]; then
            echo "Failed to fetch aaPanel installer URL, fallback to default"
            AAPANEL_INSTALLER_URL="https://download.aapanel.com/install-ubuntu_7.0_en.sh"
          fi
          echo "aaPanel installer URL: $AAPANEL_INSTALLER_URL"
          echo "AAPANEL_INSTALLER_URL=$AAPANEL_INSTALLER_URL" >> $GITHUB_ENV

      # 3. Attempt restore from GitHub artifact
      - name: Attempt restore from GitHub artifact
        id: restore_artifact
        shell: bash
        continue-on-error: true
        run: |
          set -euo pipefail
          echo "Looking for latest vps-backup artifact..."

          # Use GitHub API to find latest artifact named vps-backup.tar.gz
          ARTIFACT_URL=""
          RUN_ID=$(curl -sSL -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            "https://api.github.com/repos/${{ github.repository }}/actions/runs?event=workflow_dispatch&branch=${{ github.ref_name }}" \
            | jq -r '.workflow_runs[0].id // empty')

          if [[ -z "$RUN_ID" ]]; then
            echo "No recent workflow run found for workflow_dispatch event, trying default branch latest run..."
            RUN_ID=$(curl -sSL -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
              "https://api.github.com/repos/${{ github.repository }}/actions/runs?branch=${{ github.ref_name }}" \
              | jq -r '.workflow_runs[0].id // empty')
          fi

          if [[ -n "$RUN_ID" ]]; then
            ARTIFACTS_JSON=$(curl -sSL -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
              "https://api.github.com/repos/${{ github.repository }}/actions/runs/$RUN_ID/artifacts")
            ARTIFACT_URL=$(echo "$ARTIFACTS_JSON" | jq -r '.artifacts[] | select(.name | test("vps-backup")) | .archive_download_url' | head -1)
          fi

          if [[ -z "$ARTIFACT_URL" ]]; then
            echo "No vps-backup artifact found."
            exit 1
          fi

          echo "Downloading artifact from $ARTIFACT_URL"
          curl -L -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" -o "$WORKDIR/vps-backup.tar.gz" "$ARTIFACT_URL"

          echo "Extracting backup artifact..."
          mkdir -p "$WORKDIR/restore"
          tar -xzf "$WORKDIR/vps-backup.tar.gz" -C "$WORKDIR/restore"

          # Run restore script
          echo "Running restore.sh from artifact..."
          bash "$WORKDIR/restore/restore.sh"
          echo "Restore from artifact succeeded."

      # 4. If artifact restore fails, attempt restore from MEGA
      - name: Attempt restore from MEGA backup
        if: steps.restore_artifact.outcome != 'success'
        shell: bash
        continue-on-error: true
        run: |
          set -euo pipefail
          echo "Attempting restore from MEGA backup..."

          # List backups on MEGA remote
          BACKUP_FILE=$(rclone lsf --files-only --max-age 168h --order newest --max-items 1 "${MEGA_BACKUP_FOLDER}/" | grep -E '^vps-backup.*\.tar\.gz$' | head -1 || true)

          if [[ -z "$BACKUP_FILE" ]]; then
            echo "No MEGA backup file found."
            exit 1
          fi

          echo "Downloading MEGA backup file: $BACKUP_FILE"
          mkdir -p "$WORKDIR/restore"
          rclone copy "${MEGA_BACKUP_FOLDER}/$BACKUP_FILE" "$WORKDIR/restore/"

          echo "Extracting MEGA backup..."
          tar -xzf "$WORKDIR/restore/$BACKUP_FILE" -C "$WORKDIR/restore"

          # Run restore script
          echo "Running restore.sh from MEGA backup..."
          bash "$WORKDIR/restore/restore.sh"
          echo "Restore from MEGA backup succeeded."

      # 5. If both restores fail, run fresh provision
      - name: Fresh provision VPS
        if: steps.restore_artifact.outcome != 'success' && (steps.attempt_restore_from_MEGA_backup.outcome != 'success' || !steps.attempt_restore_from_MEGA_backup.outcome)
        shell: bash
        run: |
          set -euo pipefail
          echo "No backup restore succeeded, performing fresh provisioning..."

          # Create sudo user jacky with password spidey
          if ! id -u "$SUDO_USER" &>/dev/null; then
            echo "Creating sudo user $SUDO_USER..."
            sudo useradd -m -s /bin/bash "$SUDO_USER"
            echo "$SUDO_USER:$SUDO_PASS" | sudo chpasswd
            sudo usermod -aG sudo "$SUDO_USER"
          else
            echo "User  $SUDO_USER already exists."
          fi

          # Set hostname to Spidey
          sudo hostnamectl set-hostname Spidey

          # Install aaPanel with automated expect script
          echo "Installing aaPanel..."
          curl -fsSL "$AAPANEL_INSTALLER_URL" -o "$WORKDIR/aapanel_install.sh"
          chmod +x "$WORKDIR/aapanel_install.sh"

          # Automate installer prompts with expect
          expect -c "
            set timeout 600
            spawn sudo bash $WORKDIR/aapanel_install.sh
            expect {
              \"Enter y to install panel\" { send \"y\r\"; exp_continue }
              \"Force install\" { send \"yes\r\"; exp_continue }
              eof
            }
          "

          # Configure aaPanel credentials
          echo "Configuring aaPanel credentials..."
          # Wait for aaPanel CLI to be available
          for i in {1..10}; do
            if sudo bt 5 &>/dev/null && sudo bt 6 &>/dev/null; then
              break
            fi
            sleep 5
          done
          sudo bt 5 "$SUDO_USER"
          sudo bt 6 "$SUDO_PASS"

          # Install MariaDB server and configure root password
          echo "Configuring MariaDB..."
          sudo systemctl start mariadb || sudo systemctl start mysql || true
          sudo mysql -e "ALTER USER 'root'@'localhost' IDENTIFIED BY '${{ secrets.DB_ROOT_PASSWORD }}'; FLUSH PRIVILEGES;"
          sudo mysql -uroot -p"${{ secrets.DB_ROOT_PASSWORD }}" -e "CREATE DATABASE IF NOT EXISTS test;"

          # Install and start tailscale
          echo "Starting Tailscale with authkey..."
          sudo tailscale up --authkey "${{ secrets.TAILSCALE_AUTHKEY }}" --accept-routes --accept-dns

          # Save tailscale state immediately to MEGA
          echo "Backing up Tailscale state to MEGA..."
          sudo systemctl stop tailscaled
          sudo tar czf "$WORKDIR/tailscale-state.tar.gz" /var/lib/tailscale || true
          sudo systemctl start tailscaled
          rclone copy "$WORKDIR/tailscale-state.tar.gz" "${MEGA_BACKUP_FOLDER}/" || true

      # 6. Backup step: create backup tarball, upload artifact, upload to MEGA, write share link
      - name: Backup VPS state
        shell: bash
        run: |
          set -euo pipefail
          echo "Starting backup process..."

          TIMESTAMP=$(date -u +%Y%m%dT%H%M%SZ)
          BACKUP_NAME="vps-backup-$TIMESTAMP.tar.gz"
          BACKUP_PATH="$WORKDIR/$BACKUP_NAME"
          MANIFEST_PATH="$WORKDIR/backup-manifest.txt"

          # Create manifest listing included directories
          echo "Backup manifest:" > "$MANIFEST_PATH"
          for d in $BACKUP_DIRS; do
            if [ -d "$d" ]; then
              echo "$d" >> "$MANIFEST_PATH"
            fi
          done

          # Create backup tarball with selected directories and manifest
          echo "Creating backup tarball $BACKUP_NAME..."
          sudo tar czf "$BACKUP_PATH" -C / $(echo $BACKUP_DIRS | tr ' ' '\n' | sed 's|^/||') -C "$WORKDIR" "$(basename $MANIFEST_PATH)"
          # Add manifest inside tarball
          sudo tar --append --file="$BACKUP_PATH" -C "$WORKDIR" "$(basename $MANIFEST_PATH)"
          gzip -f "$BACKUP_PATH" || true

          # Upload artifact
          echo "Uploading backup artifact..."
          echo "::set-output name=backup_file::$BACKUP_PATH"
          # Use upload-artifact action below

      # 6b. Upload artifact (actions/upload-artifact@v4)
      - name: Upload backup artifact
        uses: actions/upload-artifact@v4
        with:
          name: vps-backup.tar.gz
          path: ${{ env.WORKDIR }}/vps-backup-*.tar.gz

      # 6c. Upload backup to MEGA and create public share link
      - name: Upload backup to MEGA and create public link
        shell: bash
        run: |
          set -euo pipefail
          echo "Uploading backup to MEGA..."

          BACKUP_FILE=$(ls -1t $WORKDIR/vps-backup-*.tar.gz | head -1)
          rclone copy "$BACKUP_FILE" "${MEGA_BACKUP_FOLDER}/"

          # Create or get public share link
          SHARE_LINK=$(rclone link "${MEGA_BACKUP_FOLDER}/$(basename "$BACKUP_FILE")" || true)
          if [[ -z "$SHARE_LINK" ]]; then
            echo "Failed to create MEGA share link."
            SHARE_LINK="Unavailable"
          fi

          echo "$SHARE_LINK" | tee "$WORKDIR/mega-backup-link.txt"

          # Upload mega-backup-link.txt as artifact as well
          gh release upload "vps-backup-link-$TIMESTAMP" "$WORKDIR/mega-backup-link.txt" --clobber || true

      # 7. Graceful shutdown detection loop (background)
      - name: Graceful shutdown detection and periodic backup
        shell: bash
        run: |
          set -euo pipefail
          echo "Starting graceful shutdown detection loop..."

          # Function to perform backup (reuse backup logic)
          backup() {
            TIMESTAMP=$(date -u +%Y%m%dT%H%M%SZ)
            BACKUP_NAME="vps-backup-$TIMESTAMP.tar.gz"
            BACKUP_PATH="$WORKDIR/$BACKUP_NAME"
            MANIFEST_PATH="$WORKDIR/backup-manifest.txt"

            echo "Backup manifest:" > "$MANIFEST_PATH"
            for d in $BACKUP_DIRS; do
              if [ -d "$d" ]; then
                echo "$d" >> "$MANIFEST_PATH"
              fi
            done

            echo "Creating backup tarball $BACKUP_NAME..."
            sudo tar czf "$BACKUP_PATH" -C / $(echo $BACKUP_DIRS | tr ' ' '\n' | sed 's|^/||') -C "$WORKDIR" "$(basename $MANIFEST_PATH)"
            sudo tar --append --file="$BACKUP_PATH" -C "$WORKDIR" "$(basename $MANIFEST_PATH)"
            gzip -f "$BACKUP_PATH" || true

            echo "Uploading backup artifact..."
            gh run artifact upload --name vps-backup.tar.gz --path "$BACKUP_PATH" || true

            echo "Uploading backup to MEGA..."
            rclone copy "$BACKUP_PATH" "${MEGA_BACKUP_FOLDER}/" || true

            SHARE_LINK=$(rclone link "${MEGA_BACKUP_FOLDER}/$(basename "$BACKUP_PATH")" || true)
            if [[ -z "$SHARE_LINK" ]]; then
              SHARE_LINK="Unavailable"
            fi
            echo "$SHARE_LINK" | tee "$WORKDIR/mega-backup-link.txt"
          }

          # Periodic check every 5 minutes for /tmp/stop file
          while true; do
            if [ -f /tmp/stop ]; then
              echo "/tmp/stop detected, running final backup and exiting..."
              backup
              exit 0
            fi
            sleep 300
          done &

          # Keep main job alive for ~6 hours (360 minutes)
          sleep 21600

      # 8. After restore or provision, start/restart services and verify health
      - name: Start and verify services
        shell: bash
        run: |
          set -euo pipefail
          echo "Starting and verifying services..."

          SERVICES=(aaPanel mariadb nginx tailscaled docker)
          for svc in "${SERVICES[@]}"; do
            if systemctl list-unit-files | grep -q "^$svc.service"; then
              echo "Restarting $svc.service..."
              sudo systemctl daemon-reload || true
              sudo systemctl restart "$svc" || true
              sleep 5
              sudo systemctl is-active --quiet "$svc" && echo "$svc is running." || echo "Warning: $svc failed to start."
            else
              echo "Service $svc not found, skipping."
            fi
          done

      # 9. Final cleanup and permissions fix
      - name: Fix permissions and cleanup
        shell: bash
        run: |
          set -euo pipefail
          echo "Fixing permissions..."

          # MariaDB data ownership
          sudo chown -R mysql:mysql /var/lib/mysql || true

          # aaPanel ownership
          sudo chown -R www-data:www-data /var/lib/aaPanel /root/.config/aaPanel /etc/aaPanel || true

          # Tailscale ownership
          sudo chown -R root:root /var/lib/tailscale || true

          echo "Cleanup done."
