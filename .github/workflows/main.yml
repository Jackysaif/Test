name: Persistent VPS with GitHub Artifact Backup

on:
  workflow_dispatch:
    inputs:
      skip_restore:
        description: 'Skip restoration from backup (fresh start)'
        required: false
        default: 'false'
        type: boolean
      session_timeout:
        description: 'Session timeout (e.g., 1h, 2h, 6h)'
        required: false
        default: '6h'
        type: string
  workflow_call:

env:
  VPS_USER: jacky
  VPS_PASSWORD: ${{ secrets.VPS_PASSWORD || 'ChangeMe123!' }}
  VPS_HOSTNAME: github-vps
  SESSION_TIMEOUT: ${{ inputs.session_timeout || '6h' }}
  BACKUP_RETENTION_DAYS: 7
  MAX_RETRIES: 3

jobs:
  vps:
    runs-on: ubuntu-22.04
    timeout-minutes: 360

    steps:
      # ===== INITIALIZATION =====
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install system tools
        run: |
          sudo apt update
          sudo apt install -y curl tmate jq zip unzip pigz

      - name: Validate required secrets
        run: |
          if [ -z "${{ secrets.MEGA_USER }}" ] || [ -z "${{ secrets.MEGA_PASS }}" ]; then
            echo "‚ùå MEGA credentials not configured"
            exit 1
          fi
          if [ -z "${{ secrets.TAILSCALE_AUTHKEY }}" ]; then
            echo "‚ùå Tailscale auth key not configured"
            exit 1
          fi
          echo "‚úÖ All required secrets are configured"

      # ===== RCLONE SETUP =====
      - name: Install and configure rclone
        run: |
          # Install rclone using official method
          curl https://rclone.org/install.sh | sudo bash
          
          # Configure MEGA
          mkdir -p ~/.config/rclone
          cat > ~/.config/rclone/rclone.conf << EOF
          [mega]
          type = mega
          user = ${{ secrets.MEGA_USER }}
          pass = ${{ secrets.MEGA_PASS }}
          EOF
          
          echo "‚úÖ Rclone configured with MEGA"
          rclone about mega: || echo "‚ö†Ô∏è MEGA connection test failed"

      # ===== USER SETUP =====
      - name: Create user with sudo access
        run: |
          if ! id -u ${{ env.VPS_USER }} >/dev/null 2>&1; then
            sudo useradd -m -s /bin/bash ${{ env.VPS_USER }}
            echo "${{ env.VPS_USER }}:${{ env.VPS_PASSWORD }}" | sudo chpasswd
            sudo usermod -aG sudo ${{ env.VPS_USER }}
            echo "${{ env.VPS_USER }} ALL=(ALL) NOPASSWD:ALL" | sudo tee /etc/sudoers.d/${{ env.VPS_USER }}
            echo "‚úÖ User ${{ env.VPS_USER }} created with sudo access"
          else
            echo "üîÅ User ${{ env.VPS_USER }} already exists"
          fi

      - name: Set hostname
        run: |
          sudo hostnamectl set-hostname ${{ env.VPS_HOSTNAME }}
          echo "üè∑Ô∏è Hostname set to $(hostname)"

      # ===== CHECK FOR ARTIFACT LINK IN MEGA =====
      - name: Check for artifact link in MEGA
        if: ${{ inputs.skip_restore != true }}
        id: check-mega-link
        run: |
          mkdir -p restore
          echo "üîç Checking for artifact link in MEGA..."
          
          # Try to download artifact link file from MEGA with retry
          RETRY_COUNT=0
          while [ $RETRY_COUNT -lt ${{ env.MAX_RETRIES }} ]; do
            if rclone copy mega:artifact-link.txt restore/ --progress 2>/dev/null; then
              break
            fi
            RETRY_COUNT=$((RETRY_COUNT + 1))
            echo "‚ö†Ô∏è Download attempt $RETRY_COUNT failed, retrying..."
            sleep 5
          done
          
          if [ -f "restore/artifact-link.txt" ]; then
            DIRECT_LINK=$(cat restore/artifact-link.txt | tr -d '\n\r' | xargs)
            echo "üìã Found artifact link: $DIRECT_LINK"
            
            # Extract artifact ID from direct link
            ARTIFACT_ID=$(echo "$DIRECT_LINK" | grep -o 'artifacts/[0-9]*' | cut -d'/' -f2)
            
            if [ -n "$ARTIFACT_ID" ]; then
              echo "artifact_id=$ARTIFACT_ID" >> $GITHUB_OUTPUT
              echo "direct_link=$DIRECT_LINK" >> $GITHUB_OUTPUT
              echo "link_found=true" >> $GITHUB_OUTPUT
              echo "‚úÖ Valid artifact link found with ID: $ARTIFACT_ID"
            else
              echo "‚ö†Ô∏è Invalid artifact link format"
              echo "link_found=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "‚ö†Ô∏è No artifact-link.txt found in MEGA (fresh start)"
            echo "link_found=false" >> $GITHUB_OUTPUT
          fi

      # ===== FIND LATEST ARTIFACT (FALLBACK) =====
      - name: Find latest backup artifact (fallback)
        if: ${{ inputs.skip_restore != true && steps.check-mega-link.outputs.link_found != 'true' }}
        id: find-artifact
        run: |
          echo "üîç Searching for latest backup artifact as fallback..."
          
          # Get latest workflow runs
          RESPONSE=$(curl -s -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${{ github.repository }}/actions/runs?status=completed&per_page=20")
          
          # Find the most recent successful run with artifacts
          RUN_ID=$(echo "$RESPONSE" | jq -r '.workflow_runs[] | select(.conclusion == "success") | .id' | head -1)
          
          if [ -n "$RUN_ID" ] && [ "$RUN_ID" != "null" ]; then
            echo "üîç Checking run $RUN_ID for artifacts..."
            
            # Get artifacts from that run
            ARTIFACTS_JSON=$(curl -s -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
              -H "Accept: application/vnd.github.v3+json" \
              "https://api.github.com/repos/${{ github.repository }}/actions/runs/$RUN_ID/artifacts")
            
            ARTIFACT_ID=$(echo "$ARTIFACTS_JSON" | jq -r '.artifacts[] | select(.name == "vps-backup") | .id')
            
            if [ -n "$ARTIFACT_ID" ] && [ "$ARTIFACT_ID" != "null" ]; then
              echo "artifact_id=$ARTIFACT_ID" >> $GITHUB_OUTPUT
              echo "run_id=$RUN_ID" >> $GITHUB_OUTPUT
              echo "üì¶ Found backup artifact: $ARTIFACT_ID from run $RUN_ID"
            else
              echo "‚ö†Ô∏è No backup artifact found in recent runs"
              echo "artifact_id=" >> $GITHUB_OUTPUT
            fi
          else
            echo "‚ö†Ô∏è No successful workflow runs found"
            echo "artifact_id=" >> $GITHUB_OUTPUT
          fi

      # ===== DOWNLOAD ARTIFACT FROM MEGA LINK =====
      - name: Download backup from MEGA link
        if: ${{ steps.check-mega-link.outputs.link_found == 'true' }}
        id: download-from-mega-link
        run: |
          ARTIFACT_ID=${{ steps.check-mega-link.outputs.artifact_id }}
          DIRECT_LINK="${{ steps.check-mega-link.outputs.direct_link }}"
          echo "üì• Downloading artifact $ARTIFACT_ID from MEGA stored link..."
          
          mkdir -p restore
          
          # Download using direct GitHub API with retry
          RETRY_COUNT=0
          DOWNLOAD_SUCCESS=false
          
          while [ $RETRY_COUNT -lt ${{ env.MAX_RETRIES }} ] && [ "$DOWNLOAD_SUCCESS" = false ]; do
            HTTP_CODE=$(curl -L -w "%{http_code}" -o restore/backup.zip \
              -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
              -H "Accept: application/vnd.github.v3+json" \
              "https://api.github.com/repos/${{ github.repository }}/actions/artifacts/$ARTIFACT_ID/zip")
            
            if [ "$HTTP_CODE" = "200" ] && [ -f "restore/backup.zip" ]; then
              DOWNLOAD_SUCCESS=true
              break
            else
              RETRY_COUNT=$((RETRY_COUNT + 1))
              echo "‚ö†Ô∏è Download attempt $RETRY_COUNT failed (HTTP: $HTTP_CODE), retrying..."
              sleep 10
            fi
          done
          
          if [ "$DOWNLOAD_SUCCESS" = true ]; then
            echo "üì¶ Extracting backup..."
            cd restore
            unzip -o backup.zip
            rm backup.zip
            cd ..
            echo "‚úÖ Backup downloaded and extracted from MEGA link"
            echo "download_success=true" >> $GITHUB_OUTPUT
            ls -la restore/
          else
            echo "‚ùå Failed to download backup from MEGA link after ${{ env.MAX_RETRIES }} attempts"
            echo "download_success=false" >> $GITHUB_OUTPUT
          fi

      # ===== DOWNLOAD ARTIFACT DIRECTLY (FALLBACK) =====
      - name: Download backup artifact (API fallback)
        if: ${{ steps.check-mega-link.outputs.link_found != 'true' && steps.find-artifact.outputs.artifact_id != '' && steps.find-artifact.outputs.artifact_id != null }}
        id: download-artifact
        run: |
          ARTIFACT_ID=${{ steps.find-artifact.outputs.artifact_id }}
          echo "üì• Downloading artifact $ARTIFACT_ID via API fallback..."
          
          mkdir -p restore
          
          # Download using direct GitHub API with retry
          RETRY_COUNT=0
          DOWNLOAD_SUCCESS=false
          
          while [ $RETRY_COUNT -lt ${{ env.MAX_RETRIES }} ] && [ "$DOWNLOAD_SUCCESS" = false ]; do
            HTTP_CODE=$(curl -L -w "%{http_code}" -o restore/backup.zip \
              -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
              -H "Accept: application/vnd.github.v3+json" \
              "https://api.github.com/repos/${{ github.repository }}/actions/artifacts/$ARTIFACT_ID/zip")
            
            if [ "$HTTP_CODE" = "200" ] && [ -f "restore/backup.zip" ]; then
              DOWNLOAD_SUCCESS=true
              break
            else
              RETRY_COUNT=$((RETRY_COUNT + 1))
              echo "‚ö†Ô∏è Download attempt $RETRY_COUNT failed (HTTP: $HTTP_CODE), retrying..."
              sleep 10
            fi
          done
          
          if [ "$DOWNLOAD_SUCCESS" = true ]; then
            echo "üì¶ Extracting backup..."
            cd restore
            unzip -o backup.zip
            rm backup.zip
            cd ..
            echo "‚úÖ Backup downloaded and extracted via API"
            echo "download_success=true" >> $GITHUB_OUTPUT
            ls -la restore/
          else
            echo "‚ùå Failed to download backup via API after ${{ env.MAX_RETRIES }} attempts"
            echo "download_success=false" >> $GITHUB_OUTPUT
          fi

      # ===== RESTORE FROM BACKUP =====
      - name: Restore from backup
        if: ${{ steps.download-from-mega-link.outputs.download_success == 'true' || steps.download-artifact.outputs.download_success == 'true' }}
        run: |
          echo "üîÑ Restoring system from backup..."
          
          # Restore user data
          if [ -f "restore/user-home.tar.gz" ]; then
            echo "üè† Restoring user data..."
            sudo tar -xzf restore/user-home.tar.gz -C / --no-same-owner
            echo "‚úÖ User data restored"
          fi
          
          # Restore system packages
          if [ -f "restore/system-packages.list" ]; then
            echo "üì¶ Restoring packages..."
            sudo apt-get update
            sudo dpkg --set-selections < restore/system-packages.list || true
            sudo apt-get upgrade -y || true
            sudo apt-get dselect-upgrade -y || true
            echo "‚úÖ Packages restored"
          fi
          
          # Restore web server configs
          if [ -f "restore/webserver-config.tar.gz" ]; then
            echo "üåê Restoring web server config..."
            sudo tar -xzf restore/webserver-config.tar.gz -C / --no-same-owner || true
            echo "‚úÖ Web server config restored"
          fi
          
          # Restore website data
          if [ -f "restore/webserver-data.tar.gz" ]; then
            echo "üíæ Restoring website data..."
            sudo tar -xzf restore/webserver-data.tar.gz -C / --no-same-owner || true
            echo "‚úÖ Website data restored"
          fi
          
          # Restore databases securely
          if [ -f "restore/all-databases.sql.gz" ]; then
            echo "üóÑÔ∏è Restoring databases..."
            # Check if MySQL is installed
            if command -v mysql >/dev/null 2>&1; then
              # Try to start MySQL service
              sudo systemctl start mysql 2>/dev/null || sudo service mysql start 2>/dev/null || true
              sleep 10
              
              # Test MySQL connection with timeout
              if timeout 30s mysql -e "SELECT 1;" 2>/dev/null; then
                echo "‚úÖ MySQL connection successful, restoring databases..."
                gunzip -c restore/all-databases.sql.gz | mysql -f 2>/dev/null && \
                echo "‚úÖ Database restoration completed" || \
                echo "‚ö†Ô∏è Database restoration had errors (non-critical)"
              else
                echo "‚ö†Ô∏è MySQL not responding, skipping database restoration"
              fi
            else
              echo "‚ö†Ô∏è MySQL not installed, skipping database restoration"
            fi
          fi
          
          # Restore aaPanel config
          if [ -f "restore/aapanel-config.tar.gz" ]; then
            echo "‚öôÔ∏è Restoring aaPanel config..."
            sudo tar -xzf restore/aapanel-config.tar.gz -C / --no-same-owner || true
            echo "‚úÖ aaPanel config restored"
          fi
          
          # Restore PHP config
          if [ -f "restore/php-config.tar.gz" ]; then
            echo "üêò Restoring PHP config..."
            sudo tar -xzf restore/php-config.tar.gz -C / --no-same-owner || true
            echo "‚úÖ PHP config restored"
          fi
          
          # Restore system services
          if [ -f "restore/system-services.tar.gz" ]; then
            echo "üîß Restoring system services..."
            sudo tar -xzf restore/system-services.tar.gz -C / --no-same-owner || true
            echo "‚úÖ System services restored"
          fi
          
          # Start restored services
          sudo systemctl daemon-reload || true
          sudo systemctl start mysql 2>/dev/null || true
          sudo systemctl start apache2 2>/dev/null || true
          sudo systemctl start nginx 2>/dev/null || true
          
          echo "‚úÖ System restoration completed"

      # ===== SYSTEM HEALTH CHECK =====
      - name: System health check
        if: always()
        run: |
          echo "=================================="
          echo "üè• System Health Check"
          echo "=================================="
          echo "üìä Disk usage:"
          df -h / | tail -1
          echo ""
          echo "üíæ Memory usage:"
          free -h
          echo ""
          echo "üîß Service status:"
          systemctl is-active mysql 2>/dev/null && echo "‚úÖ MySQL: Running" || echo "‚ùå MySQL: Not running"
          systemctl is-active apache2 2>/dev/null && echo "‚úÖ Apache2: Running" || echo "‚ùå Apache2: Not running"
          systemctl is-active nginx 2>/dev/null && echo "‚úÖ Nginx: Running" || echo "‚ùå Nginx: Not running"
          echo "=================================="

      # ===== TAILSCALE SETUP =====
      - name: Setup Tailscale
        run: |
          curl -fsSL https://tailscale.com/install.sh | sh
          sudo tailscale up --authkey ${{ secrets.TAILSCALE_AUTHKEY }} --hostname ${{ env.VPS_HOSTNAME }} --ssh
          
          TAILSCALE_IP=$(tailscale ip -4 2>/dev/null || echo "Not available")
          echo "üåê Tailscale IP: $TAILSCALE_IP"
          echo "üîë SSH: ssh ${{ env.VPS_USER }}@$TAILSCALE_IP"
          
          # Save connection info to file
          cat > connection-info.txt << EOF
          VPS Connection Information
          ==========================
          Tailscale IP: $TAILSCALE_IP
          SSH Command: ssh ${{ env.VPS_USER }}@$TAILSCALE_IP
          Username: ${{ env.VPS_USER }}
          Password: [Protected]
          Hostname: ${{ env.VPS_HOSTNAME }}
          EOF

      # ===== VPS SESSION =====
      - name: Start VPS session with proper timeout
        run: |
          echo "üöÄ VPS Session Started"
          echo "========================"
          echo "üë§ User: ${{ env.VPS_USER }}"
          echo "üîë Pass: ${{ env.VPS_PASSWORD }}"
          echo "üåê IP: $(tailscale ip -4 2>/dev/null || echo 'Tailscale not ready')"
          echo "‚è∞ Timeout: ${{ env.SESSION_TIMEOUT }}"
          echo "========================"
          
          # Calculate timeout properly
          TIMEOUT=${{ env.SESSION_TIMEOUT }}
          if [[ "$TIMEOUT" =~ ^([0-9]+)([hms])$ ]]; then
            VALUE=${BASH_REMATCH[1]}
            UNIT=${BASH_REMATCH[2]}
            case $UNIT in
              h) TIMEOUT_SECONDS=$((VALUE * 3600)) ;;
              m) TIMEOUT_SECONDS=$((VALUE * 60)) ;;
              s) TIMEOUT_SECONDS=$VALUE ;;
              *) TIMEOUT_SECONDS=21600 ;; # Default 6 hours
            esac
          else
            TIMEOUT_SECONDS=21600
          fi
          
          # Start tmate session
          tmate -S /tmp/tmate.sock new-session -d
          tmate -S /tmp/tmate.sock wait tmate-ready
          
          # Get connection strings
          TMATE_SSH=$(tmate -S /tmp/tmate.sock display -p '#{tmate_ssh}')
          TMATE_WEB=$(tmate -S /tmp/tmate.sock display -p '#{tmate_web}')
          
          echo "üîó SSH Connect: $TMATE_SSH"
          echo "üåê Web Connect: $TMATE_WEB"
          
          # Start background resource monitor
          while true; do
            echo "=== Resource Status ==="
            echo "CPU: $(top -bn1 | grep "Cpu(s)" | sed "s/.*, *\([0-9.]*\)%* id.*/\1/" | awk '{print 100 - $1}')%"
            echo "Memory: $(free -m | awk 'NR==2{printf "%.1f%%", $3*100/$2}')"
            echo "Disk: $(df -h / | awk 'NR==2{print $5}')"
            sleep 300
          done &
          
          MONITOR_PID=$!
          
          # Keep session alive
          echo "‚è≥ Session will remain active for $TIMEOUT_SECONDS seconds"
          sleep $TIMEOUT_SECONDS
          
          # Cleanup monitor
          kill $MONITOR_PID 2>/dev/null || true

      # ===== COMPLETE BACKUP CREATION =====
      - name: Create complete backup
        if: always()
        run: |
          mkdir -p backup
          echo "üíæ Creating complete backup of everything..."
          
          # 1. Backup user home directory
          echo "üìÅ Backing up user data..."
          if [ -d "/home/${{ env.VPS_USER }}" ]; then
            sudo tar -czf backup/user-home.tar.gz \
              -C /home \
              --exclude='.cache' \
              --exclude='node_modules' \
              --exclude='*.tmp' \
              --exclude='*.log' \
              --warning=no-file-changed \
              ${{ env.VPS_USER }} 2>/dev/null || echo "‚ö†Ô∏è User data backup incomplete"
          fi

          # 2. Backup system packages
          echo "üì¶ Backing up installed packages..."
          dpkg --get-selections > backup/system-packages.list
          apt-mark showauto > backup/auto-packages.list

          # 3. Backup web server configurations
          echo "üåê Backing up web server configs..."
          CONFIG_DIRS=""
          [ -d "/etc/apache2" ] && CONFIG_DIRS="$CONFIG_DIRS /etc/apache2"
          [ -d "/etc/nginx" ] && CONFIG_DIRS="$CONFIG_DIRS /etc/nginx"
          [ -d "/etc/letsencrypt" ] && CONFIG_DIRS="$CONFIG_DIRS /etc/letsencrypt"
          
          if [ -n "$CONFIG_DIRS" ]; then
            sudo tar -czf backup/webserver-config.tar.gz \
              --ignore-failed-read \
              $CONFIG_DIRS \
              2>/dev/null || echo "‚ö†Ô∏è Web server config backup incomplete"
          else
            # Create empty tar file
            tar -czf backup/webserver-config.tar.gz --files-from /dev/null 2>/dev/null || true
            echo "‚ÑπÔ∏è No web server configs found, created empty backup"
          fi

          # 4. Backup website data
          echo "üíæ Backing up website data..."
          WEBSITE_DIRS=""
          [ -d "/var/www" ] && WEBSITE_DIRS="$WEBSITE_DIRS /var/www"
          [ -d "/home/${{ env.VPS_USER }}/www" ] && WEBSITE_DIRS="$WEBSITE_DIRS /home/${{ env.VPS_USER }}/www"
          [ -d "/home/${{ env.VPS_USER }}/public_html" ] && WEBSITE_DIRS="$WEBSITE_DIRS /home/${{ env.VPS_USER }}/public_html"
          
          if [ -n "$WEBSITE_DIRS" ]; then
            sudo tar -czf backup/webserver-data.tar.gz \
              --ignore-failed-read \
              $WEBSITE_DIRS \
              2>/dev/null || echo "‚ö†Ô∏è Website data backup incomplete"
          else
            tar -czf backup/webserver-data.tar.gz --files-from /dev/null 2>/dev/null || true
            echo "‚ÑπÔ∏è No website directories found, created empty backup"
          fi

          # 5. Backup databases
          echo "üóÑÔ∏è Backing up databases..."
          if command -v mysql >/dev/null 2>&1; then
            sudo systemctl start mysql 2>/dev/null || sudo service mysql start 2>/dev/null || true
            sleep 5
            
            if mysql -e "SELECT 1;" 2>/dev/null; then
              echo "‚úÖ MySQL connection successful, creating backup..."
              mysqldump --all-databases --single-transaction > backup/all-databases.sql 2>/dev/null && \
                pigz -f backup/all-databases.sql && echo "‚úÖ Database backup completed" || \
                echo "‚ö†Ô∏è Database backup failed"
            else
              echo "‚ö†Ô∏è MySQL connection failed, creating empty backup"
              touch backup/all-databases.sql && pigz backup/all-databases.sql
            fi
          else
            echo "‚ÑπÔ∏è MySQL not installed, creating empty backup"
            touch backup/all-databases.sql && pigz backup/all-databases.sql
          fi

          # 6. Backup aaPanel configuration
          echo "‚öôÔ∏è Backing up aaPanel config..."
          AAPANEL_DIRS=""
          [ -d "/www/server/panel" ] && AAPANEL_DIRS="$AAPANEL_DIRS /www/server/panel"
          [ -d "/www/server/data" ] && AAPANEL_DIRS="$AAPANEL_DIRS /www/server/data"
          [ -d "/www/server/nginx" ] && AAPANEL_DIRS="$AAPANEL_DIRS /www/server/nginx"
          [ -d "/www/server/apache" ] && AAPANEL_DIRS="$AAPANEL_DIRS /www/server/apache"
          [ -d "/www/server/php" ] && AAPANEL_DIRS="$AAPANEL_DIRS /www/server/php"
          [ -d "/www/server/mysql" ] && AAPANEL_DIRS="$AAPANEL_DIRS /www/server/mysql"
          
          if [ -n "$AAPANEL_DIRS" ]; then
            sudo tar -czf backup/aapanel-config.tar.gz \
              --ignore-failed-read \
              $AAPANEL_DIRS \
              2>/dev/null || echo "‚ö†Ô∏è aaPanel backup incomplete"
          else
            tar -czf backup/aapanel-config.tar.gz --files-from /dev/null 2>/dev/null || true
            echo "‚ÑπÔ∏è aaPanel not installed, created empty backup"
          fi

          # 7. Backup PHP configuration
          echo "üêò Backing up PHP config..."
          PHP_DIRS=""
          [ -d "/etc/php" ] && PHP_DIRS="$PHP_DIRS /etc/php"
          [ -d "/usr/lib/php" ] && PHP_DIRS="$PHP_DIRS /usr/lib/php"
          [ -d "/usr/local/php" ] && PHP_DIRS="$PHP_DIRS /usr/local/php"
          
          if [ -n "$PHP_DIRS" ]; then
            sudo tar -czf backup/php-config.tar.gz \
              --ignore-failed-read \
              $PHP_DIRS \
              2>/dev/null || echo "‚ö†Ô∏è PHP config backup incomplete"
          else
            tar -czf backup/php-config.tar.gz --files-from /dev/null 2>/dev/null || true
            echo "‚ÑπÔ∏è PHP config not found, created empty backup"
          fi

          # 8. Backup system services
          echo "üîß Backing up system services..."
          SERVICE_DIRS=""
          [ -d "/etc/systemd/system" ] && SERVICE_DIRS="$SERVICE_DIRS /etc/systemd/system"
          [ -d "/lib/systemd/system" ] && SERVICE_DIRS="$SERVICE_DIRS /lib/systemd/system"
          [ -d "/etc/init.d" ] && SERVICE_DIRS="$SERVICE_DIRS /etc/init.d"
          [ -d "/etc/default" ] && SERVICE_DIRS="$SERVICE_DIRS /etc/default"
          
          if [ -n "$SERVICE_DIRS" ]; then
            sudo tar -czf backup/system-services.tar.gz \
              --ignore-failed-read \
              $SERVICE_DIRS \
              2>/dev/null || echo "‚ö†Ô∏è System services backup incomplete"
          else
            tar -czf backup/system-services.tar.gz --files-from /dev/null 2>/dev/null || true
            echo "‚ÑπÔ∏è System services not found, created empty backup"
          fi

          # 9. Create backup manifest
          echo "üìù Creating backup manifest..."
          cat > backup/manifest.txt << EOF
          Backup created: $(date)
          Workflow run: ${{ github.run_id }}
          Repository: ${{ github.repository }}
          Components backed up:
          - User home directory
          - System packages  
          - Web server configurations
          - Website data
          - Databases
          - aaPanel configuration
          - PHP configuration
          - System services
          EOF

          BACKUP_SIZE=$(du -sh backup 2>/dev/null | cut -f1 || echo "Unknown")
          echo "‚úÖ Complete backup created: Size: $BACKUP_SIZE"

      # ===== VERIFY BACKUP INTEGRITY =====
      - name: Verify backup integrity
        if: always()
        run: |
          echo "üîç Comprehensive backup verification..."
          ERRORS=0
          
          for file in backup/*.tar.gz backup/*.gz; do
            if [ -f "$file" ]; then
              echo "Verifying $file..."
              
              # Check file integrity
              if [[ "$file" == *.gz ]]; then
                if pigz -t "$file" 2>/dev/null; then
                  echo "‚úÖ $file: gzip integrity OK"
                else
                  echo "‚ùå $file: gzip integrity FAILED"
                  ERRORS=$((ERRORS + 1))
                fi
              fi
              
              # For tar files, check structure
              if [[ "$file" == *.tar.gz ]]; then
                if tar -tzf "$file" >/dev/null 2>&1; then
                  FILE_COUNT=$(tar -tzf "$file" | wc -l)
                  echo "‚úÖ $file: tar structure OK ($FILE_COUNT files)"
                else
                  echo "‚ùå $file: tar structure FAILED"
                  ERRORS=$((ERRORS + 1))
                fi
              fi
            fi
          done
          
          if [ $ERRORS -gt 0 ]; then
            echo "‚ö†Ô∏è Found $ERRORS corrupted backup files"
            exit 1
          else
            echo "‚úÖ All backup files are valid"
          fi

      # ===== UPLOAD TO GITHUB ARTIFACTS =====
      - name: Upload backup as artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: vps-backup
          path: backup/
          retention-days: ${{ env.BACKUP_RETENTION_DAYS }}
          if-no-files-found: warn

      # ===== SAVE ARTIFACT LINK TO MEGA WITH RETRY =====
      - name: Save artifact link to MEGA with retry
        if: always()
        run: |
          echo "‚òÅÔ∏è Saving new artifact link to MEGA..."
          
          # Get current run ID
          RUN_ID="${{ github.run_id }}"
          
          # Wait for artifact to be processed
          echo "‚è≥ Waiting for artifact to be processed..."
          sleep 30
          
          # Get artifact ID from current run
          ARTIFACTS_JSON=$(curl -s -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${{ github.repository }}/actions/runs/$RUN_ID/artifacts")
          
          ARTIFACT_ID=$(echo "$ARTIFACTS_JSON" | jq -r '.artifacts[] | select(.name == "vps-backup") | .id')
          
          if [ -n "$ARTIFACT_ID" ] && [ "$ARTIFACT_ID" != "null" ]; then
            # Create direct artifact link
            ARTIFACT_LINK="https://github.com/${{ github.repository }}/actions/runs/$RUN_ID/artifacts/$ARTIFACT_ID"
            echo "üîó New artifact link: $ARTIFACT_LINK"
            
            # Test if artifact is accessible before saving link
            ARTIFACT_TEST=$(curl -s -o /dev/null -w "%{http_code}" \
              -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
              "https://api.github.com/repos/${{ github.repository }}/actions/artifacts/$ARTIFACT_ID")
            
            if [ "$ARTIFACT_TEST" = "200" ]; then
              echo "‚úÖ Artifact is accessible, saving link"
              echo "$ARTIFACT_LINK" > artifact-link.txt
              
              # Upload to MEGA with retry
              RETRY_COUNT=0
              UPLOAD_SUCCESS=false
              
              while [ $RETRY_COUNT -lt ${{ env.MAX_RETRIES }} ]; do
                if rclone copy artifact-link.txt mega: --progress; then
                  echo "‚úÖ Successfully uploaded artifact link to MEGA"
                  UPLOAD_SUCCESS=true
                  break
                else
                  RETRY_COUNT=$((RETRY_COUNT + 1))
                  echo "‚ö†Ô∏è Upload failed, retry $RETRY_COUNT/${{ env.MAX_RETRIES }}"
                  sleep 10
                fi
              done
              
              if [ "$UPLOAD_SUCCESS" = false ]; then
                echo "‚ùå Failed to upload artifact link to MEGA after ${{ env.MAX_RETRIES }} attempts"
              else
                echo "‚úÖ Artifact link saved to MEGA for next session"
              fi
            else
              echo "‚ùå Artifact not accessible (HTTP: $ARTIFACT_TEST), skipping link save"
            fi
          else
            echo "‚ö†Ô∏è Could not get artifact ID for current run"
            echo "üìã Manual link format: https://github.com/${{ github.repository }}/actions/runs/$RUN_ID/artifacts/ARTIFACT_ID"
          fi

      # ===== CLEANUP OLD ARTIFACTS =====
      - name: Cleanup old artifacts
        if: always()
        continue-on-error: true
        run: |
          echo "üßπ Cleaning up old artifacts..."
          
          # Get all artifacts
          ARTIFACTS=$(curl -s -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${{ github.repository }}/actions/artifacts?per_page=100")
          
          # Calculate cutoff date (3 days ago)
          CUTOFF_TIMESTAMP=$(date -d '3 days ago' +%s)
          
          # Delete old artifacts
          echo "$ARTIFACTS" | jq -r '.artifacts[] | select(.name == "vps-backup") | "\(.id):\(.created_at)"' | while IFS=: read -r id created_at; do
            ARTIFACT_TIMESTAMP=$(date -d "$created_at" +%s 2>/dev/null || echo 0)
            if [ $ARTIFACT_TIMESTAMP -lt $CUTOFF_TIMESTAMP ] && [ $ARTIFACT_TIMESTAMP -gt 0 ]; then
              echo "üóëÔ∏è Deleting old artifact: $id (created: $created_at)"
              curl -X DELETE -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
                -H "Accept: application/vnd.github.v3+json" \
                "https://api.github.com/repos/${{ github.repository }}/actions/artifacts/$id"
            fi
          done
          
          echo "‚úÖ Cleanup completed"

      # ===== DISPLAY RESTORATION INFO =====
      - name: Show restoration summary
        if: always()
        run: |
          echo "=================================="
          echo "üì¶ Backup & Restoration Summary"
          echo "=================================="
          
          if [ "${{ steps.check-mega-link.outputs.link_found }}" = "true" ]; then
            echo "üîó Source: MEGA stored link"
            if [ "${{ steps.download-from-mega-link.outputs.download_success }}" = "true" ]; then
              echo "‚úÖ Restoration: SUCCESS"
            else
              echo "‚ùå Restoration: FAILED (link expired/invalid)"
            fi
          elif [ "${{ steps.download-artifact.outputs.download_success }}" = "true" ]; then
            echo "üîó Source: API discovery"
            echo "‚úÖ Restoration: SUCCESS"
          else
            echo "üÜï Source: Fresh installation"
            echo "‚ÑπÔ∏è No previous backup found or restoration failed"
          fi
          
          echo "=================================="
          echo "üíæ New backup saved to:"
          echo "   - GitHub Artifacts (${{ env.BACKUP_RETENTION_DAYS }} days)"
          echo "   - MEGA link file (persistent)"
          echo "üîÑ Next session will auto-restore from MEGA link"
          echo "=================================="

      # ===== FINAL REPORT =====
      - name: Session report
        if: always()
        run: |
          echo "=================================="
          echo "üìä VPS Session Report"
          echo "=================================="
          echo "Status: ${{ job.status }}"
          echo "Duration: ${{ env.SESSION_TIMEOUT }}"
          echo "Backup: ‚úÖ Uploaded to GitHub Artifacts"
          echo "Link: ‚úÖ Saved to MEGA for persistence"
          echo "Next session will auto-restore this exact state"
          echo ""
          echo "Resource Usage:"
          echo "$(df -h / | tail -1 | awk '{print "  Disk: "$3" / "$2" ("$5")"}')"
          echo "$(free -h | grep Mem | awk '{print "  Memory: "$3" / "$2}')"
          echo "=================================="

      # ===== SEND NOTIFICATION ON FAILURE =====
      - name: Send failure notification
        if: failure()
        continue-on-error: true
        run: |
          echo "‚ùå Workflow failed! Check logs for details."
          # Add webhook/email notification here if needed
