
# Persistent VPS Session Workflow
# Required secrets:
# - TAILSCALE_AUTHKEY: Tailscale auth key for VPN access
# - MEGA_RCLONE: Base64 encoded rclone config for MEGA remote
# - DB_ROOT_PASSWORD: MariaDB root password

name: Persistent VPS Session

on:
  workflow_dispatch:
  schedule:
    - cron: '0 */6 * * *'  # Every 6 hours

jobs:
  vps:
    runs-on: ubuntu-22.04
    timeout-minutes: 420  # 7 hours to account for 6h runtime + overhead
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Prepare environment
      run: |
        set -euo pipefail
        
        # Update package lists
        sudo apt-get update
        
        # Install required packages
        sudo apt-get install -y curl jq tar gzip expect mariadb-server
        
        # Install rclone
        curl https://rclone.org/install.sh | sudo bash
        
        # Install Tailscale
        curl -fsSL https://tailscale.com/install.sh | sh
        
        # Install tmate for debugging (optional)
        sudo apt-get install -y tmate
        
        # Create rclone config directory
        mkdir -p ~/.config/rclone
        
        # Decode and write rclone config from secret
        echo "${{ secrets.MEGA_RCLONE }}" | base64 -d > ~/.config/rclone/rclone.conf || \
        echo "${{ secrets.MEGA_RCLONE }}" > ~/.config/rclone/rclone.conf
        
        echo "Environment preparation completed"

    - name: Attempt restore from GitHub artifact
      id: artifact_restore
      continue-on-error: true
      run: |
        set -euo pipefail
        
        echo "Attempting to download latest backup artifact..."
        
        # Try to download the most recent artifact
        REPO_OWNER="${{ github.repository_owner }}"
        REPO_NAME="${{ github.event.repository.name }}"
        
        # Get latest workflow run artifacts
        ARTIFACTS_URL="https://api.github.com/repos/$REPO_OWNER/$REPO_NAME/actions/artifacts"
        
        # Download artifact using GitHub CLI or curl
        if command -v gh &> /dev/null; then
          gh auth login --with-token <<< "${{ secrets.GITHUB_TOKEN }}"
          ARTIFACT_ID=$(gh api repos/$REPO_OWNER/$REPO_NAME/actions/artifacts --jq '.artifacts[] | select(.name=="vps-backup") | .id' | head -1)
          if [ -n "$ARTIFACT_ID" ]; then
            gh api repos/$REPO_OWNER/$REPO_NAME/actions/artifacts/$ARTIFACT_ID/zip > artifact.zip
            unzip artifact.zip
            if [ -f "vps-backup.tar.gz" ]; then
              echo "artifact_found=true" >> $GITHUB_OUTPUT
              mkdir -p /tmp/restore
              tar -xzf vps-backup.tar.gz -C /tmp/restore
              echo "Artifact extracted successfully"
            fi
          fi
        fi

    - name: Download latest artifact (fallback method)
      if: steps.artifact_restore.outputs.artifact_found != 'true'
      uses: actions/download-artifact@v4
      with:
        name: vps-backup
        path: /tmp/restore
      continue-on-error: true

    - name: Restore from artifact
      if: steps.artifact_restore.outputs.artifact_found == 'true'
      id: restore_artifact
      continue-on-error: true
      run: |
        set -euo pipefail
        
        echo "Restoring from GitHub artifact..."
        
        # Create restore script
        cat > /tmp/restore.sh << 'EOF'
        #!/bin/bash
        set -euo pipefail
        
        RESTORE_DIR="/tmp/restore"
        
        if [ ! -d "$RESTORE_DIR" ]; then
          echo "Restore directory not found"
          exit 1
        fi
        
        # Restore Tailscale state
        if [ -d "$RESTORE_DIR/var/lib/tailscale" ]; then
          echo "Restoring Tailscale state..."
          sudo mkdir -p /var/lib/tailscale
          sudo cp -r "$RESTORE_DIR/var/lib/tailscale/"* /var/lib/tailscale/
          sudo chown -R root:root /var/lib/tailscale
        fi
        
        # Restore home directories
        if [ -d "$RESTORE_DIR/home" ]; then
          echo "Restoring home directories..."
          sudo cp -r "$RESTORE_DIR/home/"* /home/ 2>/dev/null || true
        fi
        
        # Restore root directory
        if [ -d "$RESTORE_DIR/root" ]; then
          echo "Restoring root directory..."
          sudo cp -r "$RESTORE_DIR/root/"* /root/ 2>/dev/null || true
        fi
        
        # Restore selected etc configs
        if [ -d "$RESTORE_DIR/etc" ]; then
          echo "Restoring etc configs..."
          sudo cp -r "$RESTORE_DIR/etc/"* /etc/ 2>/dev/null || true
        fi
        
        # Restore web content
        if [ -d "$RESTORE_DIR/var/www" ]; then
          echo "Restoring web content..."
          sudo mkdir -p /var/www
          sudo cp -r "$RESTORE_DIR/var/www/"* /var/www/
          sudo chown -R www-data:www-data /var/www
        fi
        
        # Restore opt directory
        if [ -d "$RESTORE_DIR/opt" ]; then
          echo "Restoring opt directory..."
          sudo cp -r "$RESTORE_DIR/opt/"* /opt/ 2>/dev/null || true
        fi
        
        # Restore MariaDB data
        if [ -d "$RESTORE_DIR/var/lib/mysql" ]; then
          echo "Restoring MariaDB data..."
          sudo systemctl stop mysql || true
          sudo mkdir -p /var/lib/mysql
          sudo cp -r "$RESTORE_DIR/var/lib/mysql/"* /var/lib/mysql/
          sudo chown -R mysql:mysql /var/lib/mysql
          sudo systemctl start mysql
        fi
        
        echo "Restore completed successfully"
        EOF
        
        chmod +x /tmp/restore.sh
        sudo /tmp/restore.sh
        
        echo "restore_success=true" >> $GITHUB_OUTPUT

    - name: Attempt restore from MEGA
      if: steps.restore_artifact.outputs.restore_success != 'true'
      id: restore_mega
      continue-on-error: true
      run: |
        set -euo pipefail
        
        echo "Attempting to restore from MEGA..."
        
        # List MEGA backups and get the latest
        LATEST_BACKUP=$(rclone lsf mega:vps-backups/ --include "vps-backup-*.tar.gz" | sort -r | head -1)
        
        if [ -n "$LATEST_BACKUP" ]; then
          echo "Found latest backup: $LATEST_BACKUP"
          rclone copy "mega:vps-backups/$LATEST_BACKUP" /tmp/
          
          mkdir -p /tmp/restore
          tar -xzf "/tmp/$LATEST_BACKUP" -C /tmp/restore
          
          # Use the same restore script
          sudo /tmp/restore.sh
          
          echo "mega_restore_success=true" >> $GITHUB_OUTPUT
        else
          echo "No backup found on MEGA"
          echo "mega_restore_success=false" >> $GITHUB_OUTPUT
        fi

    - name: Fresh provision
      if: steps.restore_artifact.outputs.restore_success != 'true' && steps.restore_mega.outputs.mega_restore_success != 'true'
      run: |
        set -euo pipefail
        
        echo "Performing fresh provision..."
        
        # Create sudo user jacky
        sudo useradd -m -s /bin/bash jacky || true
        echo "jacky:spidey" | sudo chpasswd
        sudo usermod -aG sudo jacky
        
        # Set hostname
        sudo hostnamectl set-hostname Spidey
        
        # Install aaPanel with automation
        echo "Installing aaPanel..."
        wget -O install.sh http://www.aapanel.com/script/install_6.0_en.sh
        
        # Create expect script for aaPanel installation
        cat > /tmp/aapanel_install.exp << 'EOF'
        #!/usr/bin/expect -f
        set timeout 300
        spawn bash install.sh aapanel
        expect "Do you want to install aaPanel to the /www directory now?(y/n):"
        send "y\r"
        expect "force install"
        send "yes\r"
        expect eof
        EOF
        
        chmod +x /tmp/aapanel_install.exp
        sudo /tmp/aapanel_install.exp || sudo bash install.sh aapanel
        
        # Configure aaPanel credentials
        sudo /www/server/panel/pyenv/bin/python /www/server/panel/tools.py panel Jacky
        sudo /www/server/panel/pyenv/bin/python /www/server/panel/tools.py password spidey
        
        # Configure MariaDB
        echo "Configuring MariaDB..."
        sudo systemctl start mysql
        sudo systemctl enable mysql
        
        # Set root password and create test database
        sudo mysql -e "ALTER USER 'root'@'localhost' IDENTIFIED BY '${{ secrets.DB_ROOT_PASSWORD }}';"
        sudo mysql -u root -p"${{ secrets.DB_ROOT_PASSWORD }}" -e "CREATE DATABASE IF NOT EXISTS test;"
        
        # Install and configure Tailscale
        echo "Configuring Tailscale..."
        sudo tailscale up --authkey "${{ secrets.TAILSCALE_AUTHKEY }}"
        
        echo "Fresh provision completed"

    - name: Start tmate session (optional debugging)
      if: github.event_name == 'workflow_dispatch'
      run: |
        # Start tmate in background for debugging
        tmate -S /tmp/tmate.sock new-session -d
        tmate -S /tmp/tmate.sock wait tmate-ready
        tmate -S /tmp/tmate.sock display -p '#{tmate_ssh}' > /tmp/tmate_ssh.txt
        echo "Tmate session available at: $(cat /tmp/tmate_ssh.txt)"
      continue-on-error: true

    - name: Start/restart services
      run: |
        set -euo pipefail
        
        echo "Starting/restarting services..."
        
        # Start MariaDB
        sudo systemctl start mysql || true
        sudo systemctl enable mysql || true
        
        # Start aaPanel
        sudo systemctl start bt || true
        sudo systemctl enable bt || true
        
        # Start Tailscale
        sudo systemctl start tailscaled || true
        sudo systemctl enable tailscaled || true
        
        # Verify service health
        echo "Service status:"
        sudo systemctl is-active mysql || echo "MySQL not active"
        sudo systemctl is-active bt || echo "aaPanel not active"
        sudo systemctl is-active tailscaled || echo "Tailscale not active"

    - name: Runtime loop with backup and shutdown detection
      run: |
        set -euo pipefail
        
        echo "Starting runtime loop..."
        
        # Function to create backup
        create_backup() {
          echo "Creating backup..."
          
          TIMESTAMP=$(date +%Y%m%d_%H%M%S)
          BACKUP_NAME="vps-backup-${TIMESTAMP}.tar.gz"
          
          # Create backup manifest
          cat > /tmp/backup-manifest.txt << EOF
        Backup created: $(date)
        Hostname: $(hostname)
        Included directories:
        - /home
        - /root
        - /etc (selected configs)
        - /var/www
        - /opt
        - /var/lib/tailscale
        - /var/lib/mysql
        EOF
          
          # Create backup directory structure
          mkdir -p /tmp/backup/{home,root,etc,var/www,var/lib/tailscale,var/lib/mysql,opt}
          
          # Copy directories to backup
          sudo cp -r /home/* /tmp/backup/home/ 2>/dev/null || true
          sudo cp -r /root/* /tmp/backup/root/ 2>/dev/null || true
          sudo cp -r /etc/hostname /etc/hosts /etc/passwd /etc/group /etc/shadow /tmp/backup/etc/ 2>/dev/null || true
          sudo cp -r /var/www/* /tmp/backup/var/www/ 2>/dev/null || true
          sudo cp -r /opt/* /tmp/backup/opt/ 2>/dev/null || true
          sudo cp -r /var/lib/tailscale/* /tmp/backup/var/lib/tailscale/ 2>/dev/null || true
          
          # Backup MariaDB data (stop service first)
          sudo systemctl stop mysql || true
          sudo cp -r /var/lib/mysql/* /tmp/backup/var/lib/mysql/ 2>/dev/null || true
          sudo systemctl start mysql || true
          
          # Copy manifest
          cp /tmp/backup-manifest.txt /tmp/backup/
          
          # Create tar.gz
          cd /tmp
          sudo tar -czf "$BACKUP_NAME" backup/
          sudo chown runner:runner "$BACKUP_NAME"
          
          echo "Backup created: $BACKUP_NAME"
          echo "backup_file=$BACKUP_NAME" >> $GITHUB_ENV
        }
        
        # Create initial backup after 30 minutes
        sleep 1800  # 30 minutes
        create_backup
        
        # Main runtime loop (run for approximately 5.5 more hours)
        END_TIME=$(($(date +%s) + 19800))  # 5.5 hours from now
        
        while [ $(date +%s) -lt $END_TIME ]; do
          # Check for shutdown signal
          if [ -f /tmp/stop ]; then
            echo "Shutdown signal detected, creating final backup..."
            create_backup
            exit 0
          fi
          
          # Sleep for 5 minutes before next check
          sleep 300
        done
        
        # Create final backup before job ends
        create_backup

    - name: Upload backup to GitHub artifacts
      uses: actions/upload-artifact@v4
      with:
        name: vps-backup
        path: /tmp/vps-backup-*.tar.gz
        retention-days: 30
      continue-on-error: true

    - name: Upload backup to MEGA
      run: |
        set -euo pipefail
        
        if [ -n "${backup_file:-}" ] && [ -f "/tmp/$backup_file" ]; then
          echo "Uploading backup to MEGA..."
          
          # Create vps-backups directory if it doesn't exist
          rclone mkdir mega:vps-backups/ || true
          
          # Upload backup
          rclone copy "/tmp/$backup_file" mega:vps-backups/
          
          # Try to create a public share link (MEGA specific)
          # Note: This requires MEGA to support public links via rclone
          rclone link "mega:vps-backups/$backup_file" > /tmp/mega-backup-link.txt 2>/dev/null || \
          echo "https://mega.nz - backup uploaded as $backup_file" > /tmp/mega-backup-link.txt
          
          echo "MEGA backup link:"
          cat /tmp/mega-backup-link.txt
          
          # Upload the link file as well
          rclone copy /tmp/mega-backup-link.txt mega:vps-backups/
        else
          echo "No backup file found to upload"
        fi
      continue-on-error: true

    - name: Final cleanup and status
      if: always()
      run: |
        echo "VPS session completed"
        echo "Final service status:"
        sudo systemctl is-active mysql || echo "MySQL not active"
        sudo systemctl is-active bt || echo "aaPanel not active" 
        sudo systemctl is-active tailscaled || echo "Tailscale not active"
        
        # Display backup info if available
        if [ -f /tmp/backup-manifest.txt ]; then
          echo "Backup manifest:"
          cat /tmp/backup-manifest.txt
        fi
        
        # Display MEGA link if available
        if [ -f /tmp/mega-backup-link.txt ]; then
          echo "MEGA backup link:"
          cat /tmp/mega-backup-link.txt
        fi
