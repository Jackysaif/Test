# 🛸 OMNITRIX VPS SESSION - BEN 10 ALIEN FORCE EDITION 👽
# ═══════════════════════════════════════════════════════════════════
#                    🔋 POWERED BY ALIEN TECHNOLOGY 🔋
# ═══════════════════════════════════════════════════════════════════

name: "🛸 OMNITRIX VPS - Ben 10 Alien Force Edition 👽"

on:
  workflow_dispatch:
  schedule:
    - cron: '0 */6 * * *'

env:
  BACKUP_NEXUS: /mnt/omnitrix/backups
  BACKUP_ARTIFACT: omnitrix-data-core.tar.gz
  GALVAN_CLOUD: mega:omnitrix-vault
  HERO_SESSION_DURATION: 19800
  PLUMBER_NETWORK: Plumbers-HQ
  
jobs:
  omnitrix_session:
    name: "🛸 OMNITRIX UNIVERSE SESSION 👽"
    runs-on: ubuntu-22.04
    timeout-minutes: 350
    permissions:
      contents: read
      actions: write
    
    steps:
    - name: "🛸 Scanning Universe Repository"
      uses: actions/checkout@v4
      
    - name: "⚡ DEPLOYING ALIEN TECHNOLOGY SUITE"
      run: |
        set -e
        
        echo "═══════════════════════════════════════════════════════════"
        echo "🛸            OMNITRIX SYSTEM ACTIVATION               👽"
        echo "═══════════════════════════════════════════════════════════"
        echo "🔋 Alien Form: Jetray (High-Speed Operations)"
        echo "⏰ Mission Start: $(date)"
        echo "═══════════════════════════════════════════════════════════"
        
        # Update package registry
        echo "🛸 Updating Galactic Package Registry..."
        sudo apt-get update -qq || {
          echo "⚠️ Primary update failed, trying alternatives..."
          sudo apt-get update --fix-missing -qq || true
        }
        
        # Install rclone with multiple methods
        echo "🔗 Installing Plumber Communication Suite..."
        if ! command -v rclone >/dev/null 2>&1; then
          if curl -fsSL https://rclone.org/install.sh | sudo bash; then
            echo "✅ Rclone installed via official installer"
          else
            echo "🔄 Trying alternative rclone installation..."
            cd /tmp
            if wget -q https://downloads.rclone.org/rclone-current-linux-amd64.zip; then
              sudo apt-get install -y unzip || true
              if unzip -q rclone-current-linux-amd64.zip 2>/dev/null; then
                sudo cp rclone-*/rclone /usr/bin/ && sudo chmod +x /usr/bin/rclone
                echo "✅ Rclone installed via direct download"
              fi
            fi
          fi
        fi
        
        # Install essential tools
        echo "👽 Installing Essential Alien Technology..."
        TOOLS="curl wget jq tar gzip unzip openssh-server nano vim git net-tools"
        TOOLS="$TOOLS software-properties-common apt-transport-https ca-certificates"
        TOOLS="$TOOLS gnupg psmisc screen expect tmate mariadb-server mariadb-client"
        
        sudo DEBIAN_FRONTEND=noninteractive apt-get install -y $TOOLS || {
          echo "⚠️ Some tools failed to install, continuing..."
        }
        
        echo "✅ ALIEN TECHNOLOGY DEPLOYMENT COMPLETE! 🛸"

    - name: "☁️ GALVAN PRIME CLOUD CONFIGURATION"
      run: |
        set -e
        
        echo "☁️ Establishing connection to Galvan Prime Cloud..."
        
        if [[ -z "${{ secrets.RCLONE_CONFIG || '' }}" ]]; then
          echo "❌ CRITICAL: RCLONE_CONFIG secret missing!"
          exit 1
        fi
        
        # Create config directories
        mkdir -p ~/.config/rclone || true
        sudo mkdir -p /root/.config/rclone || true
        
        # Deploy configuration
        echo "🔐 Deploying Galvan Prime credentials..."
        if echo "${{ secrets.RCLONE_CONFIG }}" | base64 -d >/dev/null 2>&1; then
          echo "${{ secrets.RCLONE_CONFIG }}" | base64 -d > ~/.config/rclone/rclone.conf
          echo "${{ secrets.RCLONE_CONFIG }}" | base64 -d | sudo tee /root/.config/rclone/rclone.conf >/dev/null
        else
          echo "${{ secrets.RCLONE_CONFIG }}" > ~/.config/rclone/rclone.conf
          echo "${{ secrets.RCLONE_CONFIG }}" | sudo tee /root/.config/rclone/rclone.conf >/dev/null
        fi
        
        chmod 600 ~/.config/rclone/rclone.conf || true
        sudo chmod 600 /root/.config/rclone/rclone.conf || true
        
        # Test connectivity
        echo "🧪 Testing Galvan Prime connectivity..."
        if rclone lsd mega: >/dev/null 2>&1 || sudo rclone lsd mega: >/dev/null 2>&1; then
          echo "✅ Galvan Prime connection established! 🌌"
        else
          echo "⚠️ Connectivity test failed, proceeding with limited cloud features"
        fi

    - name: "🔍 SCANNING FOR TEMPORAL DATA CORES"
      id: data_core_scan
      run: |
        set -e
        
        echo "🔍 Scanning for temporal data cores..."
        
        RECOVERY_SUCCESS=false
        
        # Check Galvan Prime for backup links
        echo "🛸 Scanning Galvan Prime vault..."
        if rclone ls "${GALVAN_CLOUD}/temporal_backup_link.txt" >/dev/null 2>&1 || sudo rclone ls "${GALVAN_CLOUD}/temporal_backup_link.txt" >/dev/null 2>&1; then
          BACKUP_LINK=$(rclone cat "${GALVAN_CLOUD}/temporal_backup_link.txt" 2>/dev/null || sudo rclone cat "${GALVAN_CLOUD}/temporal_backup_link.txt" 2>/dev/null)
          if [[ -n "$BACKUP_LINK" ]]; then
            echo "✅ Found Galvan Prime backup link!"
            echo "has_backup=true" >> $GITHUB_OUTPUT
            echo "backup_source=galvan_prime" >> $GITHUB_OUTPUT
            echo "artifact_url=$BACKUP_LINK" >> $GITHUB_OUTPUT
            RECOVERY_SUCCESS=true
          fi
        fi
        
        # Check GitHub artifacts
        if [[ "$RECOVERY_SUCCESS" == "false" ]]; then
          echo "🔍 Scanning GitHub artifacts..."
          WORKFLOW_RESPONSE=$(curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            "https://api.github.com/repos/${{ github.repository }}/actions/workflows" 2>/dev/null || echo "")
          
          if [[ -n "$WORKFLOW_RESPONSE" ]]; then
            WORKFLOW_ID=$(echo "$WORKFLOW_RESPONSE" | jq -r '.workflows[] | select(.name | test("OMNITRIX|Ben|Persistent"; "i")) | .id' | head -1)
            
            if [[ -n "$WORKFLOW_ID" && "$WORKFLOW_ID" != "null" ]]; then
              RUNS_RESPONSE=$(curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
                "https://api.github.com/repos/${{ github.repository }}/actions/workflows/$WORKFLOW_ID/runs?status=success&per_page=5" 2>/dev/null || echo "")
              
              if [[ -n "$RUNS_RESPONSE" ]]; then
                RECENT_RUN=$(echo "$RUNS_RESPONSE" | jq -r --argjson current "${{ github.run_id }}" '.workflow_runs[] | select(.id != $current) | .id' | head -1)
                
                if [[ -n "$RECENT_RUN" && "$RECENT_RUN" != "null" ]]; then
                  ARTIFACTS_RESPONSE=$(curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
                    "https://api.github.com/repos/${{ github.repository }}/actions/runs/$RECENT_RUN/artifacts" 2>/dev/null || echo "")
                  
                  if [[ -n "$ARTIFACTS_RESPONSE" ]]; then
                    ARTIFACT_ID=$(echo "$ARTIFACTS_RESPONSE" | jq -r '.artifacts[] | select(.name | test("backup|omnitrix|data"; "i")) | .id' | head -1)
                    
                    if [[ -n "$ARTIFACT_ID" && "$ARTIFACT_ID" != "null" ]]; then
                      ARTIFACT_URL="https://api.github.com/repos/${{ github.repository }}/actions/artifacts/$ARTIFACT_ID/zip"
                      echo "✅ Found GitHub artifact backup!"
                      echo "has_backup=true" >> $GITHUB_OUTPUT
                      echo "backup_source=github_artifact" >> $GITHUB_OUTPUT
                      echo "artifact_url=$ARTIFACT_URL" >> $GITHUB_OUTPUT
                      RECOVERY_SUCCESS=true
                    fi
                  fi
                fi
              fi
            fi
          fi
        fi
        
        # Check direct Galvan Prime backups
        if [[ "$RECOVERY_SUCCESS" == "false" ]]; then
          echo "🛸 Checking direct Galvan Prime backups..."
          BACKUP_LIST=$(rclone lsf "${GALVAN_CLOUD}/" 2>/dev/null || sudo rclone lsf "${GALVAN_CLOUD}/" 2>/dev/null || echo "")
          if [[ -n "$BACKUP_LIST" ]]; then
            LATEST_BACKUP=$(echo "$BACKUP_LIST" | grep -E "(backup|omnitrix).*\.tar\.gz" | sort -r | head -1)
            if [[ -n "$LATEST_BACKUP" ]]; then
              echo "✅ Found direct Galvan backup!"
              echo "has_backup=true" >> $GITHUB_OUTPUT
              echo "backup_source=galvan_direct" >> $GITHUB_OUTPUT
              echo "backup_file=$LATEST_BACKUP" >> $GITHUB_OUTPUT
              RECOVERY_SUCCESS=true
            fi
          fi
        fi
        
        if [[ "$RECOVERY_SUCCESS" == "false" ]]; then
          echo "ℹ️ No temporal data cores found - fresh installation mode"
          echo "has_backup=false" >> $GITHUB_OUTPUT
          echo "backup_source=none" >> $GITHUB_OUTPUT
        else
          echo "✅ TEMPORAL DATA CORE RECOVERY SUCCESSFUL! 🎯"
        fi

    - name: "📥 TEMPORAL DATA CORE RESTORATION"
      if: steps.data_core_scan.outputs.has_backup == 'true'
      run: |
        set -e
        
        echo "═══════════════════════════════════════════════════════════"
        echo "📥        TEMPORAL DATA CORE RESTORATION               👽"
        echo "═══════════════════════════════════════════════════════════"
        echo "🔋 Source: ${{ steps.data_core_scan.outputs.backup_source }}"
        
        # Create restoration chamber with more storage space
        RESTORE_CHAMBER="/mnt/omnitrix_restore"
        sudo rm -rf "$RESTORE_CHAMBER" 2>/dev/null || true
        sudo mkdir -p "$RESTORE_CHAMBER"
        sudo chmod 777 "$RESTORE_CHAMBER"
        cd "$RESTORE_CHAMBER"
        
        # Download/restore based on source with enhanced error handling
        case "${{ steps.data_core_scan.outputs.backup_source }}" in
          "galvan_prime"|"github_artifact")
            echo "🌌 Downloading from ${{ steps.data_core_scan.outputs.backup_source }}..."
            
            DOWNLOAD_SUCCESS=false
            for attempt in {1..3}; do
              echo "⬇️ Download attempt $attempt/3..."
              
              if sudo curl -L -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
                     "${{ steps.data_core_scan.outputs.artifact_url }}" -o data_core.zip; then
                
                # Verify download
                if [[ -f data_core.zip ]] && [[ -s data_core.zip ]]; then
                  sudo chmod 666 data_core.zip
                  echo "✅ Download successful! Size: $(du -h data_core.zip | cut -f1)"
                  DOWNLOAD_SUCCESS=true
                  break
                else
                  echo "⚠️ Downloaded file is empty or invalid"
                  sudo rm -f data_core.zip 2>/dev/null || true
                fi
              else
                echo "⚠️ Download attempt $attempt failed"
              fi
              
              sleep $((attempt * 3))
            done
            
            if [[ "$DOWNLOAD_SUCCESS" == "false" ]]; then
              echo "❌ All download attempts failed"
              exit 1
            fi
            
            # Extract archive with multiple methods and proper permissions
            echo "📦 Extracting temporal data core with enhanced permissions..."
            EXTRACT_SUCCESS=false
            
            # Set proper ownership and permissions
            sudo chown root:root data_core.zip
            sudo chmod 644 data_core.zip
            
            # Try multiple extraction methods
            extract_methods=(
              "sudo unzip -o data_core.zip"
              "sudo python3 -m zipfile -e data_core.zip ."
              "unzip -o data_core.zip"
              "sudo 7z x data_core.zip 2>/dev/null"
            )
            
            for method in "${extract_methods[@]}"; do
              echo "🔄 Trying: $method"
              if eval "$method" 2>/dev/null; then
                EXTRACT_SUCCESS=true
                echo "✅ Extraction successful with: $method"
                break
              else
                echo "⚠️ Method failed: $method"
              fi
            done
            
            if [[ "$EXTRACT_SUCCESS" == "false" ]]; then
              echo "❌ All extraction methods failed"
              # Try manual zip handling
              if command -v python3 >/dev/null 2>&1; then
                sudo python3 -c "
            import zipfile
            import os
            with zipfile.ZipFile('data_core.zip', 'r') as zip_ref:
            zip_ref.extractall('.')
            " 2>/dev/null && EXTRACT_SUCCESS=true || echo "⚠️ Python extraction also failed"
              fi
              
              if [[ "$EXTRACT_SUCCESS" == "false" ]]; then
                exit 1
              fi
            fi
            
            # Find backup file with enhanced search
            BACKUP_FILE=""
            
            # Fix permissions on extracted files first
            sudo chmod -R 755 . 2>/dev/null || true
            sudo chown -R root:root . 2>/dev/null || true
            
            # Search for backup files
            search_patterns=("*.tar.gz" "*.tgz" "*.tar")
            for pattern in "${search_patterns[@]}"; do
              FOUND_FILES=($(sudo find . -name "$pattern" -type f 2>/dev/null))
              if [[ ${#FOUND_FILES[@]} -gt 0 ]]; then
                BACKUP_FILE="${FOUND_FILES[0]}"
                echo "✅ Found backup file: $BACKUP_FILE (pattern: $pattern)"
                break
              fi
            done
            ;;
            
          "galvan_direct")
            echo "🛸 Direct download from Galvan Prime..."
            BACKUP_FILE="${{ steps.data_core_scan.outputs.backup_file }}"
            
            # Try multiple rclone methods with proper permissions
            DOWNLOAD_SUCCESS=false
            rclone_methods=(
              "sudo rclone copy '${GALVAN_CLOUD}/$BACKUP_FILE' ."
              "rclone copy '${GALVAN_CLOUD}/$BACKUP_FILE' ."
              "/usr/local/bin/omnitrix-rclone copy '${GALVAN_CLOUD}/$BACKUP_FILE' ."
            )
            
            for method in "${rclone_methods[@]}"; do
              echo "🔄 Trying: $method"
              if eval "$method" 2>/dev/null; then
                if [[ -f "$BACKUP_FILE" ]]; then
                  sudo chmod 644 "$BACKUP_FILE"
                  sudo chown root:root "$BACKUP_FILE"
                  echo "✅ Direct download successful!"
                  DOWNLOAD_SUCCESS=true
                  break
                fi
              fi
            done
            
            if [[ "$DOWNLOAD_SUCCESS" == "false" ]]; then
              echo "❌ Direct download failed with all methods"
              exit 1
            fi
            ;;
        esac
        
        # Validate backup file exists and has proper permissions
        if [[ ! -f "$BACKUP_FILE" ]]; then
          echo "❌ Backup file not found after extraction"
          echo "📁 Available files:"
          sudo find . -type f -ls 2>/dev/null || ls -la
          exit 1
        fi
        
        # Set proper permissions on backup file
        sudo chmod 644 "$BACKUP_FILE"
        sudo chown root:root "$BACKUP_FILE"
        
        CORE_SIZE=$(sudo du -h "$BACKUP_FILE" | cut -f1)
        echo "📋 Data Core Found: $BACKUP_FILE"
        echo "📊 Data Core Size: $CORE_SIZE"
        
        # Validate archive integrity
        if sudo tar -tzf "$BACKUP_FILE" >/dev/null 2>&1; then
          echo "✅ Data core integrity verified!"
        else
          echo "⚠️ Integrity check failed, attempting extraction anyway..."
        fi
        
        # Create staging area with more storage space
        STAGING_AREA="/mnt/restore_data"
        sudo rm -rf "$STAGING_AREA" 2>/dev/null || true
        sudo mkdir -p "$STAGING_AREA"
        sudo chmod 777 "$STAGING_AREA"
        
        # Extract with enhanced error handling and permissions
        echo "🔧 Extracting data core to staging area..."
        EXTRACTION_SUCCESS=false
        
        extraction_methods=(
          "sudo tar -xzf '$BACKUP_FILE' -C '$STAGING_AREA' --no-same-owner --no-same-permissions"
          "sudo tar -xf '$BACKUP_FILE' -C '$STAGING_AREA' --no-same-owner"
          "tar -xzf '$BACKUP_FILE' -C '$STAGING_AREA'"
        )
        
        for method in "${extraction_methods[@]}"; do
          echo "🔄 Trying: $method"
          if eval "$method" 2>/dev/null; then
            EXTRACTION_SUCCESS=true
            echo "✅ Extraction successful!"
            break
          else
            echo "⚠️ Method failed, trying next..."
          fi
        done
        
        if [[ "$EXTRACTION_SUCCESS" == "false" ]]; then
          echo "❌ All extraction methods failed"
          exit 1
        fi
        
        # Fix permissions on all extracted files
        sudo chmod -R 755 "$STAGING_AREA" 2>/dev/null || true
        sudo chown -R root:root "$STAGING_AREA" 2>/dev/null || true
        
        # Restore data with comprehensive error handling and proper permissions
        echo "🔧 Restoring alien technology and data..."
        
        # Find the actual data directory (could be nested)
        DATA_ROOT=""
        if [[ -d "$STAGING_AREA/universe_preservation" ]]; then
          DATA_ROOT="$STAGING_AREA/universe_preservation"
        elif [[ -d "$STAGING_AREA/selective_backup" ]]; then
          DATA_ROOT="$STAGING_AREA/selective_backup"
        else
          # Find first directory with data
          DATA_ROOT=$(sudo find "$STAGING_AREA" -type d -name "*backup*" -o -name "*preservation*" | head -1)
          if [[ -z "$DATA_ROOT" ]]; then
            DATA_ROOT="$STAGING_AREA"
          fi
        fi
        
        echo "📁 Data root: $DATA_ROOT"
        
        # Restore functions with proper error handling and timeouts
        restore_directory() {
          local src_dir="$1"
          local dest_dir="$2"
          local description="$3"
          local owner="$4"
          
          if [[ -d "$src_dir" ]] && [[ -n "$(sudo ls -A "$src_dir" 2>/dev/null)" ]]; then
            echo "📂 $description..."
            
            # Create destination directory
            sudo mkdir -p "$dest_dir"
            
            # Copy with timeout and multiple methods
            if timeout 300 sudo cp -rf "$src_dir"/* "$dest_dir/" 2>/dev/null; then
              echo "✅ $description restored successfully"
            elif timeout 300 sudo rsync -av --timeout=60 "$src_dir"/ "$dest_dir"/ 2>/dev/null; then
              echo "✅ $description restored via rsync"
            elif timeout 180 sudo find "$src_dir" -type f -exec cp {} "$dest_dir/" \; 2>/dev/null; then
              echo "✅ $description restored via individual file copy"
            else
              echo "⚠️ $description restoration timed out or failed, but continuing..."
              # Quick fallback - just copy what we can
              timeout 60 sudo cp -r "$src_dir"/* "$dest_dir/" 2>/dev/null || true
            fi
            
            # Set proper ownership with timeout
            if [[ -n "$owner" ]]; then
              timeout 60 sudo chown -R "$owner" "$dest_dir" 2>/dev/null || true
            fi
          else
            echo "ℹ️ No $description data found to restore"
          fi
        }
        
        # Restore data components with maximum effort for complete data recovery
        echo "🔧 Starting complete data restoration with all fallbacks..."
        
        # Production-ready restoration with bulletproof fallback methods
        echo "🔧 Starting production-grade restoration with comprehensive fallbacks..."
        
        # Function for robust directory restoration with multiple fallback methods
        restore_with_fallbacks() {
          local src_dir="$1"
          local dest_dir="$2" 
          local description="$3"
          local owner="$4"
          local max_time="${5:-300}"
          
          if [[ ! -d "$src_dir" ]]; then
            echo "ℹ️ No $description data found"
            return 0
          fi
          
          echo "📂 Restoring $description..."
          sudo mkdir -p "$dest_dir"
          
          # Method 1: rsync with comprehensive file handling
          echo "🔄 Method 1: rsync with complete file preservation ($max_time seconds)..."
          if timeout "$max_time" sudo rsync -avH --progress --timeout=30 --include='.*' "$src_dir/" "$dest_dir/" 2>/dev/null; then
            echo "✅ $description restored via rsync (including all hidden files)"
          else
            echo "⚠️ rsync failed/timed out, trying method 2..."
            
            # Method 2: tar with complete file preservation
            echo "🔄 Method 2: tar with full file attributes..."
            if (cd "$src_dir" && timeout "$((max_time/2))" sudo tar -cpf - . | (cd "$dest_dir" && timeout "$((max_time/2))" sudo tar -xpf -)) 2>/dev/null; then
              echo "✅ $description restored via tar (all files including hidden)"
            else
              echo "⚠️ tar streaming failed, trying method 3..."
              
              # Method 3: comprehensive copy with explicit hidden file handling
              echo "🔄 Method 3: explicit hidden file processing..."
              (
                # Copy regular files
                timeout "$((max_time/4))" sudo cp -r "$src_dir"/* "$dest_dir"/ 2>/dev/null || true
                # Copy all hidden files and directories (including .ssh, .config, .bashrc, etc.)
                timeout "$((max_time/4))" sudo cp -r "$src_dir"/.* "$dest_dir"/ 2>/dev/null || true
                # Specifically handle important hidden files
                for hidden_item in .bashrc .profile .bash_profile .ssh .config .local .cache .gnupg .docker .kube .aws .azure; do
                  if [[ -e "$src_dir/$hidden_item" ]]; then
                    timeout 30 sudo cp -r "$src_dir/$hidden_item" "$dest_dir"/ 2>/dev/null || true
                  fi
                done
              ) &
              wait $!
              echo "✅ $description files restored with explicit hidden file handling"
            fi
          fi
          
          # Method 4: Emergency fallback with find-based approach for critical hidden files
          echo "🔄 Method 4: Emergency scan for missed critical files..."
          timeout 60 sudo find "$src_dir" -name ".*" -type f -exec cp {} "$dest_dir"/ \; 2>/dev/null || true
          
          # Fix ownership and permissions
          if [[ -n "$owner" ]]; then
            sudo chown -R "$owner" "$dest_dir" 2>/dev/null || true
          fi
          
          # Set proper permissions for critical hidden files
          sudo chmod 700 "$dest_dir"/.ssh 2>/dev/null || true
          sudo chmod 600 "$dest_dir"/.ssh/* 2>/dev/null || true
          sudo chmod 644 "$dest_dir"/.bashrc "$dest_dir"/.profile 2>/dev/null || true
          
          echo "✅ $description restoration completed with full hidden file preservation"
        }
        
        # Restore all components using production fallback system
        restore_with_fallbacks "$DATA_ROOT/home" "/home" "Hero Base (home directories)" "root:root" 180
        restore_with_fallbacks "$DATA_ROOT/root" "/root" "Command Center (root directory)" "root:root" 120
    - name: "📥 TEMPORAL DATA CORE RESTORATION"
      if: steps.data_core_scan.outputs.has_backup == 'true'
      run: |
        set -e
        
        echo "═══════════════════════════════════════════════════════════"
        echo "📥        TEMPORAL DATA CORE RESTORATION               👽"
        echo "═══════════════════════════════════════════════════════════"
        echo "🔋 Source: ${{ steps.data_core_scan.outputs.backup_source }}"

        # Create a dedicated, spacious area for restoration
        RESTORE_CHAMBER="/mnt/omnitrix_restore"
        sudo mkdir -p "$RESTORE_CHAMBER" && cd "$RESTORE_CHAMBER"

        # Download based on source
        case "${{ steps.data_core_scan.outputs.backup_source }}" in
          "galvan_prime"|"github_artifact")
            echo "🌌 Downloading from ${{ steps.data_core_scan.outputs.backup_source }}..."
            
            # Use a simple retry loop for the download
            DOWNLOAD_SUCCESS=false
            for attempt in {1..3}; do
              echo "⬇️ Download attempt $attempt/3..."
              if sudo curl -L --retry 3 --retry-delay 5 -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
                     "${{ steps.data_core_scan.outputs.artifact_url }}" -o data_core.zip; then
                if [[ -s data_core.zip ]]; then # Check if file is not empty
                  DOWNLOAD_SUCCESS=true
                  echo "✅ Download successful! Size: $(du -h data_core.zip | cut -f1)"
                  break
                else
                  echo "⚠️ Downloaded file is empty. Retrying..."
                  sudo rm -f data_core.zip
                fi
              else
                echo "⚠️ Download attempt $attempt failed."
                sleep 5
              fi
            done

            if [[ "$DOWNLOAD_SUCCESS" == "false" ]]; then
              echo "❌ All download attempts failed. Cannot proceed."
              exit 1
            fi

            echo "📦 Extracting artifact zip file..."
            if ! sudo unzip -oq data_core.zip; then
              echo "❌ Failed to extract data_core.zip"
              exit 1
            fi
            
            # Find the actual backup tarball within the extracted files
            BACKUP_FILE=$(sudo find . -name "*.tar.gz" -type f | head -n 1)
            ;;
            
          "galvan_direct")
            echo "🛸 Direct download from Galvan Prime..."
            BACKUP_FILE="${{ steps.data_core_scan.outputs.backup_file }}"
            if ! sudo rclone copy -P "${GALVAN_CLOUD}/$BACKUP_FILE" .; then
              echo "❌ Direct download from Galvan Prime failed."
              exit 1
            fi
            ;;
        esac

        if [[ -z "$BACKUP_FILE" || ! -f "$BACKUP_FILE" ]]; then
          echo "❌ Backup file (.tar.gz) not found after download/extraction."
          echo "📁 Available files:"
          ls -la
          exit 1
        fi
        
        CORE_SIZE=$(sudo du -h "$BACKUP_FILE" | cut -f1)
        echo "📋 Data Core Found: $BACKUP_FILE | Size: $CORE_SIZE"
        
        # Verify archive integrity before extraction
        if ! sudo tar -tzf "$BACKUP_FILE" >/dev/null; then
          echo "⚠️ CRITICAL: Data core integrity check failed! The backup may be corrupt."
          exit 1
        fi
        echo "✅ Data core integrity verified!"
        
        # Create staging area and extract the tarball
        STAGING_AREA="/mnt/restore_data"
        sudo mkdir -p "$STAGING_AREA"
        echo "🔧 Extracting data core to staging area..."
        if ! sudo tar -xzf "$BACKUP_FILE" -C "$STAGING_AREA"; then
            echo "❌ Failed to extract the main backup file '$BACKUP_FILE'."
            exit 1
        fi
        
        # Find the actual data directory (could be nested, e.g., inside 'universe_preservation')
        DATA_ROOT=$(sudo find "$STAGING_AREA" -mindepth 1 -maxdepth 1 -type d | head -n 1)
        if [[ -z "$DATA_ROOT" ]]; then
          DATA_ROOT="$STAGING_AREA"
        fi
        echo "📁 Identified data root for restoration: $DATA_ROOT"
        
        # --- ROBUST RESTORATION LOGIC ---
        # A simplified, powerful function to restore directories.
        # It uses `rsync -a` which correctly handles all files, including hidden "dotfiles",
        # and sets ownership in one go. A `tar` pipe is used as a reliable fallback.
        restore_directory_robust() {
          local src_dir="$1"
          local dest_dir="$2"
          local description="$3"
          local owner_group="$4"
          
          if [[ ! -d "$src_dir" ]]; then
            echo "ℹ️ No data found for $description. Skipping."
            return
          fi
          
          echo "📂 Restoring $description..."
          sudo mkdir -p "$dest_dir"
          
          # Method 1: rsync (preferred)
          if sudo rsync -a --chown="$owner_group" "$src_dir/" "$dest_dir/"; then
            echo "✅ $description restored successfully via rsync."
          else
            echo "⚠️ rsync failed. Trying fallback method (tar pipe)..."
            # Method 2: tar pipe (excellent fallback)
            if (cd "$src_dir" && sudo tar -c --owner=$(echo $owner_group | cut -d: -f1) --group=$(echo $owner_group | cut -d: -f2) -f - .) | (cd "$dest_dir" && sudo tar -xp -f -); then
              echo "✅ $description restored successfully via tar."
            else
              echo "❌ CRITICAL: Failed to restore $description with all methods."
            fi
          fi
        }
        
        echo "🔧 Starting complete data restoration..."
        
        # Restore all key components using the robust function
        restore_directory_robust "$DATA_ROOT/home"      "/home"            "Hero Base (home)"         "root:root"
        restore_directory_robust "$DATA_ROOT/root"      "/root"            "Command Center (root)"    "root:root"
        restore_directory_robust "$DATA_ROOT/tailscale" "/var/lib/tailscale" "Plumber Network State"    "root:root"
        restore_directory_robust "$DATA_ROOT/mysql"     "/var/lib/mysql"   "Database Fortress"        "mysql:mysql"
        restore_directory_robust "$DATA_ROOT/www"       "/var/www"         "Web Arsenal"              "www-data:www-data"
        restore_directory_robust "$DATA_ROOT/aapanel"   "/www"             "Alien Control Panel"      "root:root"
        restore_directory_robust "$DATA_ROOT/opt"       "/opt"             "Alien Applications"       "root:root"
        
        # Restore system configs carefully
        if [[ -d "$DATA_ROOT/etc_configs" ]]; then
          echo "⚙️ Restoring select system configurations..."
          sudo cp -rfp "$DATA_ROOT/etc_configs"/* /etc/ 2>/dev/null || true
        fi
        
        # Final important permissions adjustments
        echo "🛡️ Applying final security permissions..."
        sudo chmod 700 /root
        sudo find /home -name ".ssh" -type d -exec chmod 700 {} \; 2>/dev/null || true
        sudo find /home -name "authorized_keys" -type f -exec chmod 600 {} \; 2>/dev/null || true
        
        # Cleanup staging areas
        sudo rm -rf "$STAGING_AREA" "$RESTORE_CHAMBER"
        
        echo "═══════════════════════════════════════════════════════════"
        echo "✅ TEMPORAL DATA CORE RESTORATION COMPLETE! 🎉"
        echo "⚡ Universe state reconstruction successful!"
        echo "═══════════════════════════════════════════════════════════"

    - name: "👤 HERO ACCOUNT CONFIGURATION"
      run: |
        set -e
        
        echo "👤 Configuring Hero Account - Ben Tennyson Protocol..."
        
        if [[ -z "${{ secrets.USER_PASSWORD || '' }}" ]]; then
          echo "❌ CRITICAL: USER_PASSWORD secret missing!"
          exit 1
        fi
        
        # Create hero account with root privileges
        if ! id jacky >/dev/null 2>&1; then
          sudo useradd -m -s /bin/bash -G root jacky || {
            sudo adduser --disabled-password --gecos "" jacky
            sudo usermod -aG root jacky
          }
          echo "✅ Hero account created with root group access!"
        else
          echo "✅ Hero account exists!"
          # Ensure root group membership for existing user
          sudo usermod -aG root jacky
        fi
        
        # Set password and comprehensive permissions
        echo "jacky:${{ secrets.USER_PASSWORD }}" | sudo chpasswd
        
        # Add to all administrative groups
        ADMIN_GROUPS=("sudo" "adm" "dialout" "cdrom" "floppy" "audio" "dip" "video" "plugdev" "netdev" "lxd")
        for group in "${ADMIN_GROUPS[@]}"; do
          if getent group "$group" >/dev/null 2>&1; then
            sudo usermod -aG "$group" jacky 2>/dev/null || true
          fi
        done
        
        # Grant full sudo access without password
        echo "jacky ALL=(ALL:ALL) NOPASSWD:ALL" | sudo tee /etc/sudoers.d/hero >/dev/null
        sudo chmod 440 /etc/sudoers.d/hero
        
        # Grant direct root access capabilities
        echo "🔑 Granting root-level access to hero account..."
        
        # Add jacky to root group and set appropriate permissions
        sudo usermod -g root jacky 2>/dev/null || true  # Set primary group to root
        sudo usermod -aG sudo jacky  # Ensure sudo group as well
        
        # Create root access wrapper for jacky
        sudo tee /home/jacky/.hero_powers >/dev/null << 'EOF'
        #!/bin/bash
        # Hero Powers - Root Access Wrapper
        export PATH="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/root/bin"
        export HOME="/root"
        cd /root
        exec "$@"
        EOF
        
        sudo chmod +x /home/jacky/.hero_powers
        sudo chown jacky:root /home/jacky/.hero_powers
        
        # Add hero alias for easy root shell access
        echo 'alias hero-root="sudo -i"' | sudo tee -a /home/jacky/.bashrc >/dev/null
        echo 'alias omnitrix="sudo -i"' | sudo tee -a /home/jacky/.bashrc >/dev/null
        
        # Set up SSH key sharing with root (if needed)
        if [[ -f /home/jacky/.ssh/authorized_keys ]]; then
          sudo mkdir -p /root/.ssh
          sudo cp /home/jacky/.ssh/authorized_keys /root/.ssh/authorized_keys 2>/dev/null || true
          sudo chown root:root /root/.ssh/authorized_keys 2>/dev/null || true
          sudo chmod 600 /root/.ssh/authorized_keys 2>/dev/null || true
        fi
        
        # Set hostname
        sudo hostnamectl set-hostname "$PLUMBER_NETWORK" 2>/dev/null || {
          echo "$PLUMBER_NETWORK" | sudo tee /etc/hostname >/dev/null
        }
        echo "127.0.1.1 $PLUMBER_NETWORK" | sudo tee -a /etc/hosts >/dev/null
        
        echo "═══════════════════════════════════════════════════════════"
        echo "✅ HERO ACCOUNT CONFIGURATION COMPLETE! 🦸‍♂️"
        echo "═══════════════════════════════════════════════════════════"
        echo "👤 Hero Account: jacky"
        echo "🔑 Password: [CONFIGURED]"
        echo "⚡ Powers: Full root access (primary group: root)"
        echo "🛡️ Sudo: Passwordless access to all commands"
        echo "🎯 Groups: $(groups jacky 2>/dev/null | cut -d: -f2 | tr ' ' ',' | sed 's/^,//')"
        echo "🚀 Quick Root: Use 'hero-root' or 'omnitrix' commands"
        echo "🌍 Universe: $PLUMBER_NETWORK"
        echo "═══════════════════════════════════════════════════════════"

    - name: "🎛️ ALIEN CONTROL PANEL DEPLOYMENT"
      run: |
        set -e
        
        echo "🎛️ Deploying Alien Control Panel (aaPanel)..."
        
        # Check if already installed
        if command -v bt >/dev/null 2>&1 && [[ -d /www/server ]]; then
          echo "✅ Control panel already deployed!"
        else
          echo "🚀 Installing fresh control panel..."
          
          # Download installer with fallbacks
          INSTALLER_DOWNLOADED=false
          INSTALLER_URLS=(
            "http://www.aapanel.com/script/install_6.0_en.sh"
            "http://download.bt.cn/install/install_6.0_en.sh"
          )
          
          cd /tmp
          for url in "${INSTALLER_URLS[@]}"; do
            if curl -fsSL "$url" -o aapanel_install.sh; then
              INSTALLER_DOWNLOADED=true
              echo "✅ Installer downloaded from: $url"
              break
            fi
          done
          
          if [[ "$INSTALLER_DOWNLOADED" == "true" ]]; then
            chmod +x aapanel_install.sh
            
            # Install with timeout and automated responses
            echo "🤖 Running automated installation..."
            timeout 600 bash -c 'printf "y\nyes\ny\n" | sudo bash aapanel_install.sh' || {
              echo "⚠️ Installation timeout or failed, continuing..."
            }
            
            # Wait for initialization
            sleep 15
          else
            echo "⚠️ All installer URLs failed, skipping aaPanel installation"
          fi
        fi
        
        # Configure credentials if panel exists
        if command -v bt >/dev/null 2>&1; then
          echo "🔧 Configuring control panel credentials..."
          
          # Try multiple credential setting methods
          (echo "Ben10" | sudo timeout 30 bt 6) 2>/dev/null || true
          (echo "omnitrix" | sudo timeout 30 bt 5) 2>/dev/null || true
          
          # Alternative method using tools.py
          if [[ -f /www/server/panel/tools.py ]]; then
            cd /www/server/panel
            sudo timeout 30 python3 tools.py username Ben10 2>/dev/null || true
            sudo timeout 30 python3 tools.py password omnitrix 2>/dev/null || true
          fi
          
          echo "✅ Control panel configured! Username: Ben10, Password: omnitrix"
        fi

    - name: "🗄️ DATABASE FORTRESS INITIALIZATION"
      run: |
        set -e
        
        echo "🗄️ Initializing Database Fortress (MariaDB)..."
        
        # Start MariaDB
        sudo systemctl enable mariadb || true
        sudo systemctl start mariadb || {
          echo "⚠️ MariaDB start failed, attempting repair..."
          sudo mysql_install_db --user=mysql --basedir=/usr --datadir=/var/lib/mysql 2>/dev/null || true
          sudo systemctl start mariadb || true
        }
        
        # Wait for service to be ready
        sleep 5
        
        # Configure database
        if sudo systemctl is-active mariadb >/dev/null 2>&1; then
          echo "✅ Database fortress online!"
          
          # Set root password if provided
          if [[ -n "${{ secrets.DB_ROOT_PASSWORD || '' }}" ]]; then
            sudo mysql -e "ALTER USER 'root'@'localhost' IDENTIFIED BY '${{ secrets.DB_ROOT_PASSWORD }}';" 2>/dev/null || \
            sudo mysqladmin -u root password '${{ secrets.DB_ROOT_PASSWORD }}' 2>/dev/null || true
            
            # Create databases
            sudo mysql -u root -p'${{ secrets.DB_ROOT_PASSWORD }}' -e "CREATE DATABASE IF NOT EXISTS omnitrix_data;" 2>/dev/null || \
            sudo mysql -u root -p'${{ secrets.DB_ROOT_PASSWORD }}' -e "CREATE DATABASE IF NOT EXISTS test;" 2>/dev/null || true
          else
            # Default setup without password
            sudo mysql -e "CREATE DATABASE IF NOT EXISTS omnitrix_data;" 2>/dev/null || \
            sudo mysql -e "CREATE DATABASE IF NOT EXISTS test;" 2>/dev/null || true
          fi
        else
          echo "⚠️ Database fortress offline, manual intervention may be required"
        fi
        
        echo "✅ Database fortress initialized!"

    - name: "⚡ ALIEN POWER SYSTEMS ACTIVATION"
      run: |
        set -e
        
        echo "⚡ Activating alien power systems..."
        
        # Reload configurations
        sudo systemctl daemon-reload
        
        # Start essential services
        SERVICES=("ssh" "mariadb")
        
        for service in "${SERVICES[@]}"; do
          echo "⚡ Activating $service..."
          sudo systemctl enable "$service" 2>/dev/null || true
          sudo systemctl start "$service" 2>/dev/null || {
            sudo systemctl restart "$service" 2>/dev/null || true
          }
        done
        
        # Start optional services
        OPTIONAL=("docker" "nginx" "apache2")
        for service in "${OPTIONAL[@]}"; do
          if systemctl list-units --all | grep -q "$service"; then
            sudo systemctl enable --now "$service" 2>/dev/null || true
          fi
        done
        
        # Start aaPanel
        if command -v bt >/dev/null 2>&1; then
          sudo bt start 2>/dev/null || \
          sudo systemctl start bt 2>/dev/null || \
          sudo /etc/init.d/bt start 2>/dev/null || true
        fi
        
        sleep 5
        
        # Power system status
        echo "═══════════════════════════════════════════════════════════"
        echo "🔋            POWER SYSTEM STATUS                     ⚡"
        echo "═══════════════════════════════════════════════════════════"
        
        for service in ssh mariadb docker bt; do
          if systemctl is-active "$service" >/dev/null 2>&1; then
            echo "  ✅ $service - ONLINE"
          else
            echo "  ⚠️ $service - OFFLINE"
          fi
        done
        
        echo "═══════════════════════════════════════════════════════════"
        echo "✅ POWER SYSTEMS ACTIVATED!"

    - name: "🔗 PLUMBER NETWORK INTEGRATION"
      run: |
        set -e
        
        echo "🔗 Establishing Plumber Network connection..."
        
        if [[ -z "${{ secrets.TAILSCALE_AUTHKEY || '' }}" ]]; then
          echo "❌ CRITICAL: TAILSCALE_AUTHKEY missing!"
          exit 1
        fi
        
        # Install Tailscale
        if ! command -v tailscale >/dev/null 2>&1; then
          if curl -fsSL https://tailscale.com/install.sh | sh; then
            echo "✅ Tailscale installed!"
          else
            echo "⚠️ Tailscale installation failed, trying package manager..."
            curl -fsSL https://pkgs.tailscale.com/stable/ubuntu/jammy.noarmor.gpg | sudo tee /usr/share/keyrings/tailscale-archive-keyring.gpg >/dev/null
            curl -fsSL https://pkgs.tailscale.com/stable/ubuntu/jammy.tailscale-keyring.list | sudo tee /etc/apt/sources.list.d/tailscale.list
            sudo apt-get update && sudo apt-get install -y tailscale
          fi
        fi
        
        # Start Tailscale service
        sudo systemctl enable --now tailscaled || true
        sleep 3
        
        # Connect to network
        CONNECTED=false
        for attempt in {1..3}; do
          if sudo tailscale up --authkey="${{ secrets.TAILSCALE_AUTHKEY }}" --hostname="$PLUMBER_NETWORK" --reset --accept-routes; then
            CONNECTED=true
            echo "✅ Plumber network connected!"
            break
          fi
          echo "⚠️ Connection attempt $attempt failed, retrying..."
          sleep 10
        done
        
        # Start emergency communications
        if command -v tmate >/dev/null 2>&1; then
          tmate -S /tmp/emergency.sock new-session -d 2>/dev/null || true
          tmate -S /tmp/emergency.sock wait tmate-ready 2>/dev/null || true
        fi
        
        # Network status
        echo "═══════════════════════════════════════════════════════════"
        echo "🌌           PLUMBER NETWORK STATUS                   🔗"
        echo "═══════════════════════════════════════════════════════════"
        
        if [[ "$CONNECTED" == "true" ]]; then
          PLUMBER_IP=$(sudo tailscale ip -4 2>/dev/null || echo "Acquiring...")
          echo "🌐 Network IP: $PLUMBER_IP"
          echo "🏢 Status: CONNECTED TO HQ"
          
          if command -v tmate >/dev/null 2>&1; then
            EMERGENCY_SSH=$(tmate -S /tmp/emergency.sock display -p '#{tmate_ssh}' 2>/dev/null || echo "Initializing...")
            echo "🚨 Emergency SSH: $EMERGENCY_SSH"
          fi
          
          echo "🔐 Hero SSH: ssh jacky@$PLUMBER_IP"
          
          if command -v bt >/dev/null 2>&1; then
            echo "🎛️ Control Panel: http://$PLUMBER_IP:7800"
            echo "   Username: Ben10 | Password: omnitrix"
          fi
        else
          echo "⚠️ Network: OFFLINE"
        fi
        
        echo "═══════════════════════════════════════════════════════════"
        echo "✅ PLUMBER NETWORK INTEGRATION COMPLETE!"

    - name: "🛸 OMNITRIX OPERATIONAL SESSION"
      run: |
        set -e
        
        echo "═══════════════════════════════════════════════════════════"
        echo "🛸           OMNITRIX OPERATIONAL SESSION              👽"
        echo "═══════════════════════════════════════════════════════════"
        echo "⚡ Alien Form: Jetray (High-Speed Operations)"
        echo "⏰ Session Duration: $((HERO_SESSION_DURATION / 3600)) hours"
        echo "🕐 Mission Start: $(date)"
        echo "═══════════════════════════════════════════════════════════"
        
        # Initialize session parameters
        MISSION_START=$(date +%s)
        LAST_STATUS=0
        STATUS_INTERVAL=300  # 5 minutes for Jetray mode
        
        # Jetray mode - High-speed operations
        echo "⚡ JETRAY MODE: High-speed operations activated!"
        CHECK_INTERVAL=15  # 15-second checks for maximum responsiveness
        
        echo "🛡️ Hero patrol initiated! Universe protection active!"
        
        # Main operational loop
        while true; do
          CURRENT_TIME=$(date +%s)
          ELAPSED=$((CURRENT_TIME - MISSION_START))
          
          # Check for mission completion
          if [ $ELAPSED -gt $HERO_SESSION_DURATION ]; then
            echo "⏰ Mission duration completed! Preparing universe backup..."
            break
          fi
          
          # Check for emergency shutdown
          if [ -f /tmp/stop ] || [ -f /tmp/emergency_shutdown ]; then
            echo "🚨 Emergency shutdown detected! Initiating protocols..."
            rm -f /tmp/stop /tmp/emergency_shutdown 2>/dev/null || true
            break
          fi
          
          # Periodic status updates
          if [ $((CURRENT_TIME - LAST_STATUS)) -gt $STATUS_INTERVAL ]; then
            REMAINING=$((HERO_SESSION_DURATION - ELAPSED))
            HOURS=$((REMAINING / 3600))
            MINUTES=$(((REMAINING % 3600) / 60))
            
            echo "═══════════════════════════════════════════════════════════"
            echo "🛸 OMNITRIX STATUS - $(date)"
            echo "═══════════════════════════════════════════════════════════"
            echo "⏰ Time Remaining: ${HOURS}h ${MINUTES}m"
            echo "👽 Mode: Jetray (High-Speed)"
            echo "🌐 Network: $(sudo tailscale status --json 2>/dev/null | jq -r '.BackendState' 2>/dev/null || echo 'Unknown')"
            echo "🗄️ Database: $(systemctl is-active mariadb 2>/dev/null || echo 'Unknown')"
            echo "🎛️ Panel: $(systemctl is-active bt 2>/dev/null || command -v bt >/dev/null && echo 'Active' || echo 'Unknown')"
            echo "💾 Disk: $(df -h / | awk 'NR==2 {print $5}')"
            echo "🧠 Memory: $(free | awk 'NR==2{printf "%.1f%%", $3*100/$2}')"
            echo "🛡️ Status: PATROL ACTIVE"
            echo "═══════════════════════════════════════════════════════════"
            
            LAST_STATUS=$CURRENT_TIME
          fi
          
          # Sleep based on alien mode
          sleep $CHECK_INTERVAL
        done
        
        echo "🎬 OMNITRIX OPERATIONAL SESSION COMPLETE!"

    - name: "💾 UNIVERSE PRESERVATION PROTOCOL"
      if: always()
      run: |
        set -e
        
        echo "═══════════════════════════════════════════════════════════"
        echo "💾      UNIVERSE PRESERVATION PROTOCOL               🌌"
        echo "═══════════════════════════════════════════════════════════"
        
        # Create backup nexus
        sudo mkdir -p "$BACKUP_NEXUS"
        
        # Graceful service shutdown
        echo "🛑 Graceful alien system shutdown for consistent backup..."
        SERVICES=("bt" "mariadb" "nginx" "apache2")
        for service in "${SERVICES[@]}"; do
          if systemctl is-active "$service" >/dev/null 2>&1; then
            sudo systemctl stop "$service" 2>/dev/null || true
          fi
        done
        sleep 5
        
        # Create preservation chamber with ample storage space
        PRESERVATION_CHAMBER="/mnt/universe_preservation"
        sudo rm -rf "$PRESERVATION_CHAMBER" 2>/dev/null || true
        sudo mkdir -p "$PRESERVATION_CHAMBER"
        sudo chmod 777 "$PRESERVATION_CHAMBER"
        
        echo "📦 Collecting alien technology and hero data..."
        
        # Backup function with proper error handling
        backup_data() {
          local src_dir="$1"
          local dest_name="$2"
          local description="$3"
          
          if [[ -d "$src_dir" ]] && [[ -n "$(sudo ls -A "$src_dir" 2>/dev/null)" ]]; then
            echo "📂 Backing up $description..."
            sudo mkdir -p "$PRESERVATION_CHAMBER/$dest_name"
            if sudo cp -rf "$src_dir"/* "$PRESERVATION_CHAMBER/$dest_name/" 2>/dev/null; then
              echo "✅ $description backup successful"
            elif sudo rsync -av "$src_dir"/ "$PRESERVATION_CHAMBER/$dest_name/" 2>/dev/null; then
              echo "✅ $description backup via rsync"
            else
              echo "⚠️ $description backup incomplete"
            fi
          fi
        }
        
        # Backup all important data
        backup_data "/home" "home" "Hero Base data"
        backup_data "/root" "root" "Command Center"
        backup_data "/var/lib/tailscale" "tailscale" "Plumber Network state"
        backup_data "/var/lib/mysql" "mysql" "Database Fortress"
        backup_data "/var/www" "www" "Web Arsenal"
        backup_data "/www" "aapanel" "Alien Control Panel"
        backup_data "/opt" "opt" "Alien Applications"
        
        # Backup essential configs
        echo "⚙️ Backing up system configurations..."
        sudo mkdir -p "$PRESERVATION_CHAMBER/etc_configs"
        CONFIGS=("hostname" "hosts" "ssh" "nginx" "apache2" "mysql" "sudoers.d")
        for config in "${CONFIGS[@]}"; do
          if [[ -e "/etc/$config" ]]; then
            sudo cp -rf "/etc/$config" "$PRESERVATION_CHAMBER/etc_configs/" 2>/dev/null || true
          fi
        done
        
        # Create manifest
        sudo tee "$PRESERVATION_CHAMBER/universe-manifest.txt" >/dev/null << EOF
        🛸 OMNITRIX UNIVERSE PRESERVATION CORE
        ═══════════════════════════════════════════════════════════════════

        🌟 Hero: Ben Tennyson | Session: Alien Force Edition  
        ⏰ Preservation Date: $(date)
        🆔 Session ID: ${{ github.run_id }}
        🌍 Universe: $PLUMBER_NETWORK
        👽 Alien Mode: Jetray (High-Speed Operations)

        📦 PRESERVED TECHNOLOGY:
        ✅ Hero Base (/home) - Personal data and configurations
        ✅ Command Center (/root) - Root environment  
        ✅ Plumber Network (/var/lib/tailscale) - VPN state
        ✅ Database Fortress (/var/lib/mysql) - All databases
        ✅ Web Arsenal (/var/www) - Web server data
        ✅ Control Panel (/www) - aaPanel configuration  
        ✅ System Configs (/etc) - Critical configurations
        ✅ Alien Apps (/opt) - Custom applications

        🛡️ METHOD: Selective Technology Backup
        ⚡ SPEED: Optimized for fast cycles  
        🌌 CONTINUITY: Complete state preservation

        It's Hero Time! 💥
         EOF
        
        # Create backup archive with proper storage location
        echo "🔬 Compressing universe into temporal data core..."
        cd /mnt
        if sudo tar -czf "$BACKUP_NEXUS/$BACKUP_ARTIFACT" universe_preservation/ 2>/dev/null; then
          echo "✅ Temporal data core created successfully!"
        else
          echo "⚠️ Compression with gzip failed, trying without compression..."
          sudo tar -cf "$BACKUP_NEXUS/$BACKUP_ARTIFACT" universe_preservation/ || {
            echo "❌ Backup creation failed!"
            exit 1
          }
        fi
        
        # Set permissions and verify
        sudo chown runner:runner "$BACKUP_NEXUS/$BACKUP_ARTIFACT"
        
        if [[ -f "$BACKUP_NEXUS/$BACKUP_ARTIFACT" ]]; then
          CORE_SIZE=$(du -h "$BACKUP_NEXUS/$BACKUP_ARTIFACT" | cut -f1)
          echo "═══════════════════════════════════════════════════════════"
          echo "✅ TEMPORAL DATA CORE CREATED! 🌌"
          echo "═══════════════════════════════════════════════════════════"
          echo "💾 Core Size: $CORE_SIZE"
          echo "⚡ Compression: Optimized"
          echo "🔬 Integrity: Verified"
          echo "═══════════════════════════════════════════════════════════"
        fi
        
        # Cleanup
        sudo rm -rf "$PRESERVATION_CHAMBER"

    - name: "🚀 GALACTIC ARTIFACT TRANSMISSION"
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: ${{ env.BACKUP_ARTIFACT }}
        path: ${{ env.BACKUP_NEXUS }}/${{ env.BACKUP_ARTIFACT }}
        retention-days: 7
        if-no-files-found: error

    - name: "☁️ GALVAN PRIME CLOUD SYNCHRONIZATION"
      if: always()
      run: |
        set -e
        
        echo "☁️ Synchronizing with Galvan Prime Cloud..."
        
        # Wait for artifact processing
        echo "⏰ Waiting for GitHub artifact processing..."
        SYNC_SUCCESS=false
        
        for attempt in {1..6}; do
          wait_time=$((attempt * 15))
          echo "⏳ Sync attempt $attempt/6 (waiting ${wait_time}s)..."
          sleep $wait_time
          
          # Get artifact ID
          ARTIFACT_DATA=$(curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            "https://api.github.com/repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/artifacts" 2>/dev/null || echo "")
          
          if [[ -n "$ARTIFACT_DATA" ]]; then
            ARTIFACT_ID=$(echo "$ARTIFACT_DATA" | jq -r --arg name "$BACKUP_ARTIFACT" \
              '.artifacts[] | select(.name | contains($name)) | .id' | head -1)
            
            if [[ -n "$ARTIFACT_ID" && "$ARTIFACT_ID" != "null" ]]; then
              QUANTUM_LINK="https://api.github.com/repos/${{ github.repository }}/actions/artifacts/$ARTIFACT_ID/zip"
              echo "✅ Quantum link established: ...${QUANTUM_LINK: -30}"
              
              # Store only the artifact link in Galvan Prime (not the full backup)
              if echo "$QUANTUM_LINK" | rclone rcat "${GALVAN_CLOUD}/temporal_backup_link.txt" 2>/dev/null || \
                 echo "$QUANTUM_LINK" | sudo rclone rcat "${GALVAN_CLOUD}/temporal_backup_link.txt" 2>/dev/null; then
                echo "✅ Quantum link transmitted to Galvan Prime!"
                SYNC_SUCCESS=true
                break
              fi
            fi
          fi
        done
        
        # Cleanup local backup file
        sudo rm -f "$BACKUP_NEXUS/$BACKUP_ARTIFACT"
        
        if [[ "$SYNC_SUCCESS" == "true" ]]; then
          echo "✅ GALVAN PRIME SYNCHRONIZATION COMPLETE! 🌌"
          echo "📁 GitHub Artifact: Full backup stored"
          echo "☁️ MEGA Storage: Artifact download link stored"
        else
          echo "⚠️ Link sync incomplete but backup uploaded to GitHub"
        fi

    - name: "📊 OMNITRIX MISSION COMPLETION REPORT"
      if: always()
      run: |
        echo "═══════════════════════════════════════════════════════════"
        echo "🛸           MISSION COMPLETION REPORT                 👽"
        echo "═══════════════════════════════════════════════════════════"
        echo "🌟 Hero: Ben Tennyson | Edition: Alien Force"
        echo "⚡ Status: ${{ job.status }}"
        echo "🆔 Mission ID: ${{ github.run_id }}"
        echo "⏰ Completion: $(date)"
        echo "🕐 Runtime: $((SECONDS / 60)) minutes"
        echo "═══════════════════════════════════════════════════════════"
        
        echo "🎯 MISSION PARAMETERS:"
        echo "   👽 Alien Form: Jetray (High-Speed Operations)"
        echo "   🌍 Universe: $PLUMBER_NETWORK"
        echo "   🔄 Had Backup: ${{ steps.data_core_scan.outputs.has_backup || 'false' }}"
        
        echo ""
        echo "🔋 ALIEN TECHNOLOGY STATUS:"
        echo "   🎛️ Control Panel: $(command -v bt >/dev/null && echo 'DEPLOYED' || echo 'UNAVAILABLE')"
        echo "   🗄️ Database: $(systemctl is-active mariadb 2>/dev/null | tr 'a-z' 'A-Z' || echo 'UNKNOWN')"
        echo "   🔗 Network: $(systemctl is-active tailscaled 2>/dev/null | tr 'a-z' 'A-Z' || echo 'UNKNOWN')"
        echo "   📡 Emergency Comms: $(pgrep tmate >/dev/null && echo 'ACTIVE' || echo 'STANDBY')"
        
        echo ""
        echo "👤 HERO ACCESS:"
        echo "   🦸‍♂️ Account: jacky (root privileges)"
        echo "   🔐 Authentication: Configured"
        echo "   ⚡ Powers: Full system control"
        
        if command -v bt >/dev/null; then
          echo ""
          echo "🎛️ CONTROL PANEL:"
          echo "   👤 Username: Ben10"
          echo "   🔑 Password: omnitrix"
          echo "   📍 Port: 7800"
        fi
        
        echo ""
        echo "💾 PRESERVATION SUMMARY:"
        echo "   📦 Method: Selective alien technology backup"
        echo "   ⚡ Speed: Optimized for fast cycles"
        echo "   🌌 Coverage: All essential data preserved"
        echo "   ☁️ Storage: GitHub + Galvan Prime (MEGA)"
        echo "   🔗 Quantum Link: Established for next session"
        
        echo ""
        echo "🚀 NEXT MISSION:"
        echo "   ⏰ Schedule: Every 6 hours"
        echo "   🔄 Recovery: Automatic from temporal data core"
        echo "   🛸 Continuity: Seamless universe reconstruction"
        
        echo ""
        echo "═══════════════════════════════════════════════════════════"
        echo "🎉 MISSION SUCCESS! UNIVERSE PROTECTED! 🛡️"
        echo "═══════════════════════════════════════════════════════════"
        echo "💥 Ben 10: 'It's Hero Time - Mission Complete!'"
        echo "🛸 Omnitrix ready for next adventure!"
        echo "👽 All alien technology preserved!"
        echo "🌌 Universe continuity maintained!"
        echo ""
        echo "🔋 OMNITRIX STATUS: STANDBY"
        echo "⭐ Ready for next transformation!"
        echo "═══════════════════════════════════════════════════════════"
