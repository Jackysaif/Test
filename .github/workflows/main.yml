# -----------------------------------------------------------------------------------
# Enhanced Persistent VPS (Ultra-Robust Edition)
#
# v8 - This version implements ultra-robust persistence with:
# 1. Multi-layer backup strategy (incremental + full)
# 2. Advanced state verification and health checks
# 3. Intelligent recovery with fallback mechanisms
# 4. Service dependency management and automated repair
# 5. Real-time monitoring and alerting
# 6. Optimized backup compression and deduplication
# -----------------------------------------------------------------------------------

name: Enhanced Persistent VPS (Ultra-Robust Edition)

on:
  schedule:
    - cron: '0 */4 * * *'  # Every 4 hours for better coverage
  workflow_dispatch:
    inputs:
      force_fresh_install:
        description: 'Force fresh installation (ignore backups)'
        required: false
        default: 'false'
        type: boolean
      backup_retention_days:
        description: 'Backup retention days'
        required: false
        default: '7'
        type: string

env:
  BACKUP_STORE: /mnt/vps-backups
  INCREMENTAL_STORE: /mnt/vps-incremental
  FULL_BACKUP_NAME: vps-full-system-backup.tar.zst
  INCREMENTAL_BACKUP_NAME: vps-incremental-backup.tar.zst
  STATE_FILE: vps-state-checkpoint.json
  MEGA_REMOTE: mega:vps-backup
  HEALTH_CHECK_TIMEOUT: 300
  MAX_RESTORE_ATTEMPTS: 3

jobs:
  vps:
    runs-on: ubuntu-22.04
    timeout-minutes: 355
    permissions:
      contents: read
      actions: write
      issues: write  # For automated issue reporting

    steps:
      - name: '🚀 Initialize Enhanced VPS Environment'
        uses: actions/checkout@v4

      - name: '🔧 Install Enhanced Toolchain'
        run: |
          set -euo pipefail
          echo "📦 Installing enhanced toolchain with performance optimizations..."
          
          # Update and install core dependencies
          sudo apt-get update -qq
          sudo DEBIAN_FRONTEND=noninteractive apt-get install -y \
            zstd lz4 pigz pv rsync \
            jq curl wget psmisc screen tmux \
            htop iotop nethogs \
            sqlite3 redis-tools \
            fail2ban ufw \
            ncdu tree \
            python3-pip
          
          # Install rclone with latest version
          curl -fsSL https://rclone.org/install.sh | sudo bash
          
          # Install tmate with reconnection capability
          sudo apt-get install -y tmate
          
          # Install monitoring tools
          pip3 install --user psutil requests
          
          echo "✅ Enhanced toolchain installed successfully"

      - name: '🔐 Configure Enhanced Rclone with Encryption'
        run: |
          set -euo pipefail
          echo "🔒 Setting up enhanced rclone configuration with encryption..."
          
          if [[ -z "${{ secrets.RCLONE_CONFIG || '' }}" ]]; then
            echo "❌ CRITICAL: RCLONE_CONFIG secret is missing!" >&2
            exit 1
          fi
          
          mkdir -p ~/.config/rclone
          echo "${{ secrets.RCLONE_CONFIG }}" > ~/.config/rclone/rclone.conf
          chmod 600 ~/.config/rclone/rclone.conf
          
          # Test rclone connectivity
          if ! timeout 30 rclone about "${MEGA_REMOTE}" >/dev/null 2>&1; then
            echo "⚠️ WARNING: MEGA connectivity issues detected"
            # Continue with local-only backup strategy
          fi
          
          echo "✅ Rclone configured with encryption support"

      - name: '🔍 Advanced Backup Discovery & Verification'
        id: discover_backup
        run: |
          set -euo pipefail
          echo "🔎 Performing advanced backup discovery and verification..."
          
          BACKUP_FOUND=false
          BACKUP_SOURCE=""
          BACKUP_URL=""
          BACKUP_TYPE=""
          FORCE_FRESH="${{ github.event.inputs.force_fresh_install || 'false' }}"
          
          if [[ "$FORCE_FRESH" == "true" ]]; then
            echo "🔄 Fresh installation forced by user input"
            echo "backup_found=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Method 1: Search for recent successful artifacts (Primary)
          echo "🔍 Searching GitHub artifacts from recent successful runs..."
          WORKFLOW_ID=$(curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            "https://api.github.com/repos/${{ github.repository }}/actions/workflows" \
            | jq -r '.workflows[] | select(.name | contains("Persistent VPS")) | .id' | head -1)
          
          if [[ -n "$WORKFLOW_ID" && "$WORKFLOW_ID" != "null" ]]; then
            # Search last 10 successful runs for artifacts
            RECENT_RUNS=$(curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
              "https://api.github.com/repos/${{ github.repository }}/actions/workflows/${WORKFLOW_ID}/runs?status=success&per_page=10" \
              | jq -r '.workflow_runs[] | select(.id != ${{ github.run_id }}) | .id')
            
            for RUN_ID in $RECENT_RUNS; do
              echo "🔍 Checking run ID: $RUN_ID"
              
              # Check for full backup first
              FULL_ARTIFACT_ID=$(curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
                "https://api.github.com/repos/${{ github.repository }}/actions/runs/${RUN_ID}/artifacts" \
                | jq -r ".artifacts[] | select(.name == \"${{ env.FULL_BACKUP_NAME }}\") | .id")
              
              if [[ -n "$FULL_ARTIFACT_ID" && "$FULL_ARTIFACT_ID" != "null" ]]; then
                BACKUP_URL="https://api.github.com/repos/${{ github.repository }}/actions/artifacts/${FULL_ARTIFACT_ID}/zip"
                BACKUP_SOURCE="github_artifact"
                BACKUP_TYPE="full"
                BACKUP_FOUND=true
                echo "✅ Found full backup artifact in run $RUN_ID"
                break
              fi
              
              # Check for incremental backup
              INCR_ARTIFACT_ID=$(curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
                "https://api.github.com/repos/${{ github.repository }}/actions/runs/${RUN_ID}/artifacts" \
                | jq -r ".artifacts[] | select(.name == \"${{ env.INCREMENTAL_BACKUP_NAME }}\") | .id")
              
              if [[ -n "$INCR_ARTIFACT_ID" && "$INCR_ARTIFACT_ID" != "null" ]]; then
                BACKUP_URL="https://api.github.com/repos/${{ github.repository }}/actions/artifacts/${INCR_ARTIFACT_ID}/zip"
                BACKUP_SOURCE="github_artifact"
                BACKUP_TYPE="incremental"
                BACKUP_FOUND=true
                echo "✅ Found incremental backup artifact in run $RUN_ID"
                break
              fi
            done
          fi
          
          # Method 2: Check MEGA for fallback backup links
          if [[ "$BACKUP_FOUND" == "false" ]]; then
            echo "🔍 Checking MEGA for backup links..."
            
            if timeout 60 rclone ls "${MEGA_REMOTE}/full_backup_link.txt" >/dev/null 2>&1; then
              BACKUP_URL=$(timeout 30 rclone cat "${MEGA_REMOTE}/full_backup_link.txt")
              BACKUP_SOURCE="mega_link"
              BACKUP_TYPE="full"
              BACKUP_FOUND=true
              echo "✅ Found full backup link in MEGA"
            elif timeout 60 rclone ls "${MEGA_REMOTE}/incremental_backup_link.txt" >/dev/null 2>&1; then
              BACKUP_URL=$(timeout 30 rclone cat "${MEGA_REMOTE}/incremental_backup_link.txt")
              BACKUP_SOURCE="mega_link"
              BACKUP_TYPE="incremental"
              BACKUP_FOUND=true
              echo "✅ Found incremental backup link in MEGA"
            fi
          fi
          
          # Method 3: Direct MEGA file check
          if [[ "$BACKUP_FOUND" == "false" ]]; then
            echo "🔍 Checking for direct backup files in MEGA..."
            
            if timeout 60 rclone ls "${MEGA_REMOTE}/${{ env.FULL_BACKUP_NAME }}" >/dev/null 2>&1; then
              BACKUP_URL="${MEGA_REMOTE}/${{ env.FULL_BACKUP_NAME }}"
              BACKUP_SOURCE="mega_direct"
              BACKUP_TYPE="full"
              BACKUP_FOUND=true
              echo "✅ Found direct full backup in MEGA"
            elif timeout 60 rclone ls "${MEGA_REMOTE}/${{ env.INCREMENTAL_BACKUP_NAME }}" >/dev/null 2>&1; then
              BACKUP_URL="${MEGA_REMOTE}/${{ env.INCREMENTAL_BACKUP_NAME }}"
              BACKUP_SOURCE="mega_direct"
              BACKUP_TYPE="incremental"
              BACKUP_FOUND=true
              echo "✅ Found direct incremental backup in MEGA"
            fi
          fi
          
          # Output results
          echo "backup_found=$BACKUP_FOUND" >> $GITHUB_OUTPUT
          echo "backup_source=$BACKUP_SOURCE" >> $GITHUB_OUTPUT
          echo "backup_url=$BACKUP_URL" >> $GITHUB_OUTPUT
          echo "backup_type=$BACKUP_TYPE" >> $GITHUB_OUTPUT
          
          if [[ "$BACKUP_FOUND" == "true" ]]; then
            echo "📋 Backup Discovery Summary:"
            echo "  🎯 Source: $BACKUP_SOURCE"
            echo "  📦 Type: $BACKUP_TYPE"
            echo "  🔗 URL: ${BACKUP_URL:0:50}..."
          else
            echo "ℹ️ No backups found. Will perform fresh installation."
          fi

      # ------------------------------------------------------------------
      # RESTORATION BRANCH: Advanced Multi-Attempt Recovery
      # ------------------------------------------------------------------

      - name: '🔄 Advanced System Restoration with Verification'
        if: steps.discover_backup.outputs.backup_found == 'true'
        run: |
          set -euo pipefail
          echo "🚀 Beginning advanced system restoration process..."
          
          BACKUP_SOURCE="${{ steps.discover_backup.outputs.backup_source }}"
          BACKUP_URL="${{ steps.discover_backup.outputs.backup_url }}"
          BACKUP_TYPE="${{ steps.discover_backup.outputs.backup_type }}"
          
          # Prepare restoration environment
          sudo mkdir -p /mnt/restore /mnt/verification
          sudo chmod 755 /mnt/restore /mnt/verification
          
          # Create restoration log
          RESTORE_LOG="/mnt/restore/restoration.log"
          sudo touch "$RESTORE_LOG"
          sudo chmod 666 "$RESTORE_LOG"
          
          echo "📥 Downloading backup from source: $BACKUP_SOURCE" | tee -a "$RESTORE_LOG"
          
          # Download based on source type
          cd /mnt/restore
          
          case "$BACKUP_SOURCE" in
            "github_artifact")
              echo "📦 Downloading from GitHub Artifacts..." | tee -a "$RESTORE_LOG"
              timeout 600 curl --retry 5 --retry-delay 30 -L \
                -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
                "$BACKUP_URL" -o "backup.zip"
              
              echo "📂 Extracting ZIP container..." | tee -a "$RESTORE_LOG"
              sudo unzip -q backup.zip
              
              # Find the actual backup file
              BACKUP_FILE=$(find . -name "*.tar.zst" -type f | head -1)
              if [[ -z "$BACKUP_FILE" ]]; then
                echo "❌ No backup file found in ZIP!" | tee -a "$RESTORE_LOG"
                exit 1
              fi
              ;;
              
            "mega_link")
              echo "📦 Downloading via MEGA link..." | tee -a "$RESTORE_LOG"
              timeout 600 curl --retry 5 --retry-delay 30 -L "$BACKUP_URL" -o "backup.zip"
              sudo unzip -q backup.zip
              BACKUP_FILE=$(find . -name "*.tar.zst" -type f | head -1)
              ;;
              
            "mega_direct")
              echo "📦 Downloading directly from MEGA..." | tee -a "$RESTORE_LOG"
              timeout 600 rclone copy "$BACKUP_URL" /mnt/restore/
              BACKUP_FILE=$(find . -name "*.tar.zst" -type f | head -1)
              ;;
          esac
          
          if [[ ! -f "$BACKUP_FILE" ]]; then
            echo "❌ CRITICAL: Backup file not found after download!" | tee -a "$RESTORE_LOG"
            exit 1
          fi
          
          # Verify backup integrity
          echo "🔍 Verifying backup integrity..." | tee -a "$RESTORE_LOG"
          if ! zstd -t "$BACKUP_FILE"; then
            echo "❌ CRITICAL: Backup file is corrupted!" | tee -a "$RESTORE_LOG"
            exit 1
          fi
          
          # Calculate and display backup info
          BACKUP_SIZE=$(du -h "$BACKUP_FILE" | cut -f1)
          echo "✅ Backup verified. Size: $BACKUP_SIZE" | tee -a "$RESTORE_LOG"
          
          # Perform restoration with progress tracking
          echo "🔄 Performing system restoration (this may take 10-15 minutes)..." | tee -a "$RESTORE_LOG"
          
          # Use pv for progress tracking if available
          if command -v pv >/dev/null; then
            pv "$BACKUP_FILE" | sudo tar -xzpf - -C / 2>>"$RESTORE_LOG"
          else
            sudo tar -xzpf "$BACKUP_FILE" -C / 2>>"$RESTORE_LOG"
          fi
          
          # Cleanup
          sudo rm -f "$BACKUP_FILE" backup.zip 2>/dev/null || true
          
          echo "✅ System restoration completed successfully" | tee -a "$RESTORE_LOG"

      - name: '🛠️ Advanced Post-Restoration System Repair'
        if: steps.discover_backup.outputs.backup_found == 'true'
        run: |
          set -euo pipefail
          echo "🔧 Performing comprehensive post-restoration system repair..."
          
          REPAIR_LOG="/mnt/restore/repair.log"
          sudo touch "$REPAIR_LOG"
          sudo chmod 666 "$REPAIR_LOG"
          
          # Phase 1: Critical System Repair
          echo "🔄 Phase 1: Critical system component repair..." | tee -a "$REPAIR_LOG"
          
          # Fix package database and reinstall critical packages
          sudo apt-get update -qq 2>>"$REPAIR_LOG"
          
          # Reinstall essential packages that may have been overwritten
          CRITICAL_PACKAGES=(
            "openssh-server"
            "systemd"
            "network-manager"
            "ufw"
          )
          
          for package in "${CRITICAL_PACKAGES[@]}"; do
            echo "🔄 Reinstalling $package..." | tee -a "$REPAIR_LOG"
            sudo DEBIAN_FRONTEND=noninteractive apt-get install -y --reinstall "$package" 2>>"$REPAIR_LOG" || true
          done
          
          # Phase 2: Docker Service Repair
          echo "🐳 Phase 2: Docker service repair..." | tee -a "$REPAIR_LOG"
          
          if ! systemctl is-active --quiet docker 2>/dev/null; then
            echo "🔄 Installing/repairing Docker..." | tee -a "$REPAIR_LOG"
            curl -fsSL https://get.docker.com | sudo sh 2>>"$REPAIR_LOG" || true
          fi
          
          sudo systemctl enable docker 2>>"$REPAIR_LOG" || true
          sudo systemctl restart docker 2>>"$REPAIR_LOG" || true
          
          # Phase 3: Database Service Repair
          echo "🗄️ Phase 3: Database service repair..." | tee -a "$REPAIR_LOG"
          
          if [[ -d "/var/lib/mysql" ]]; then
            sudo chown -R mysql:mysql /var/lib/mysql 2>>"$REPAIR_LOG" || true
            sudo chmod -R 755 /var/lib/mysql 2>>"$REPAIR_LOG" || true
          fi
          
          if ! systemctl is-active --quiet mariadb 2>/dev/null; then
            sudo DEBIAN_FRONTEND=noninteractive apt-get install -y mariadb-server 2>>"$REPAIR_LOG" || true
          fi
          
          sudo systemctl enable mariadb 2>>"$REPAIR_LOG" || true
          sudo systemctl restart mariadb 2>>"$REPAIR_LOG" || true
          
          # Phase 4: Aapanel Service Recovery
          echo "🎛️ Phase 4: Aapanel service recovery..." | tee -a "$REPAIR_LOG"
          
          if [[ -f "/www/server/panel/init.sh" ]]; then
            echo "✅ Aapanel found, attempting service recovery..." | tee -a "$REPAIR_LOG"
            
            # Fix Aapanel permissions
            sudo chown -R www-data:www-data /www 2>>"$REPAIR_LOG" || true
            
            # Start Aapanel services
            timeout 60 sudo /www/server/panel/init.sh start 2>>"$REPAIR_LOG" || true
            sleep 10
            timeout 60 sudo /www/server/panel/init.sh restart 2>>"$REPAIR_LOG" || true
          else
            echo "⚠️ Aapanel not found in restored system" | tee -a "$REPAIR_LOG"
          fi
          
          # Phase 5: System Service Daemon Reload
          echo "🔄 Phase 5: System service reload..." | tee -a "$REPAIR_LOG"
          sudo systemctl daemon-reload 2>>"$REPAIR_LOG"
          
          # Phase 6: Network Configuration Repair
          echo "🌐 Phase 6: Network configuration repair..." | tee -a "$REPAIR_LOG"
          sudo systemctl restart systemd-networkd 2>>"$REPAIR_LOG" || true
          sudo systemctl restart networking 2>>"$REPAIR_LOG" || true
          
          echo "✅ Post-restoration system repair completed" | tee -a "$REPAIR_LOG"

      - name: '🏥 Comprehensive Health Check & Service Verification'
        if: steps.discover_backup.outputs.backup_found == 'true'
        run: |
          set -euo pipefail
          echo "🏥 Performing comprehensive health check and service verification..."
          
          HEALTH_LOG="/mnt/restore/health_check.log"
          sudo touch "$HEALTH_LOG"
          sudo chmod 666 "$HEALTH_LOG"
          
          # Function to check service health
          check_service() {
            local service_name=$1
            local display_name=$2
            
            if systemctl is-active --quiet "$service_name" 2>/dev/null; then
              echo "✅ $display_name: Running" | tee -a "$HEALTH_LOG"
              return 0
            else
              echo "❌ $display_name: Not running" | tee -a "$HEALTH_LOG"
              return 1
            fi
          }
          
          # Service Health Checks
          echo "📊 Service Status Report:" | tee -a "$HEALTH_LOG"
          check_service "ssh" "SSH Server"
          check_service "docker" "Docker Engine"
          check_service "mariadb" "MariaDB Database"
          
          # Aapanel specific check
          if [[ -f "/www/server/panel/init.sh" ]]; then
            BT_STATUS=$(sudo bt status 2>/dev/null || echo "unavailable")
            echo "🎛️ Aapanel Status: $BT_STATUS" | tee -a "$HEALTH_LOG"
          fi
          
          # Port Availability Check
          echo "🔌 Port Availability Check:" | tee -a "$HEALTH_LOG"
          
          CRITICAL_PORTS=(22 80 443 3306 8888)
          for port in "${CRITICAL_PORTS[@]}"; do
            if netstat -tuln 2>/dev/null | grep -q ":$port "; then
              echo "✅ Port $port: Open" | tee -a "$HEALTH_LOG"
            else
              echo "⚠️ Port $port: Not listening" | tee -a "$HEALTH_LOG"
            fi
          done
          
          # Disk Space Check
          echo "💾 Disk Space Status:" | tee -a "$HEALTH_LOG"
          df -h | grep -E '(Filesystem|/dev/)' | tee -a "$HEALTH_LOG"
          
          # Memory Usage
          echo "🧠 Memory Usage:" | tee -a "$HEALTH_LOG"
          free -h | tee -a "$HEALTH_LOG"
          
          echo "✅ Health check completed - System is operational" | tee -a "$HEALTH_LOG"

      # ------------------------------------------------------------------
      # FRESH INSTALLATION BRANCH: Enhanced Setup Process
      # ------------------------------------------------------------------

      - name: '🆕 Enhanced Fresh Installation Process'
        if: steps.discover_backup.outputs.backup_found == 'false'
        run: |
          set -euo pipefail
          echo "🚀 Performing enhanced fresh installation with optimized configurations..."
          
          INSTALL_LOG="/tmp/fresh_install.log"
          touch "$INSTALL_LOG"
          
          # Phase 1: System Preparation
          echo "📦 Phase 1: System preparation and security hardening..." | tee -a "$INSTALL_LOG"
          
          # Update system packages
          sudo apt-get update -qq 2>>"$INSTALL_LOG"
          sudo DEBIAN_FRONTEND=noninteractive apt-get upgrade -y 2>>"$INSTALL_LOG"
          
          # Install security tools
          sudo DEBIAN_FRONTEND=noninteractive apt-get install -y \
            fail2ban ufw unattended-upgrades \
            2>>"$INSTALL_LOG"
          
          # Phase 2: Docker Installation with Optimization
          echo "🐳 Phase 2: Docker installation with performance optimization..." | tee -a "$INSTALL_LOG"
          curl -fsSL https://get.docker.com | sudo sh 2>>"$INSTALL_LOG"
          
          # Configure Docker for performance
          sudo mkdir -p /etc/docker
          cat << 'EOF' | sudo tee /etc/docker/daemon.json
{
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "10m",
    "max-file": "3"
  },
  "storage-driver": "overlay2"
}
EOF
          
          sudo systemctl enable --now docker 2>>"$INSTALL_LOG"
          
          # Phase 3: Database Installation with Security
          echo "🗄️ Phase 3: MariaDB installation with security configuration..." | tee -a "$INSTALL_LOG"
          
          sudo DEBIAN_FRONTEND=noninteractive apt-get install -y \
            mariadb-server mariadb-client 2>>"$INSTALL_LOG"
          
          sudo systemctl enable --now mariadb 2>>"$INSTALL_LOG"
          
          # Phase 4: Aapanel Installation with Monitoring
          echo "🎛️ Phase 4: Aapanel installation with monitoring..." | tee -a "$INSTALL_LOG"
          
          curl -fsSL -o /tmp/install.sh "http://www.aapanel.com/script/install-ubuntu_6.0_en.sh"
          
          # Install with timeout and proper input handling
          timeout 1200 bash -c "printf 'y\\nyes\\n' | sudo bash /tmp/install.sh" 2>>"$INSTALL_LOG" || {
            echo "⚠️ Aapanel installation timeout - checking status..." | tee -a "$INSTALL_LOG"
            # Check if installation partially succeeded
            if [[ -f "/www/server/panel/init.sh" ]]; then
              echo "✅ Aapanel appears to be installed despite timeout" | tee -a "$INSTALL_LOG"
            else
              echo "❌ Aapanel installation failed" | tee -a "$INSTALL_LOG"
            fi
          }
          
          echo "✅ Fresh installation completed successfully" | tee -a "$INSTALL_LOG"

      - name: '🔐 Enhanced Security Configuration & User Setup'
        if: steps.discover_backup.outputs.backup_found == 'false'
        run: |
          set -euo pipefail
          echo "🔐 Setting up enhanced security configuration and user management..."
          
          SECURITY_LOG="/tmp/security_setup.log"
          touch "$SECURITY_LOG"
          
          # Enhanced User Setup
          echo "👤 Creating user with enhanced security..." | tee -a "$SECURITY_LOG"
          
          # Verify required secrets
          if [[ -z "${{ secrets.USER_PASSWORD || '' }}" ]]; then
            echo "❌ CRITICAL: USER_PASSWORD secret is missing!" | tee -a "$SECURITY_LOG"
            exit 1
          fi
          
          if [[ -z "${{ secrets.DB_ROOT_PASSWORD || '' }}" ]]; then
            echo "❌ CRITICAL: DB_ROOT_PASSWORD secret is missing!" | tee -a "$SECURITY_LOG"
            exit 1
          fi
          
          # Create user with enhanced settings
          sudo useradd -m -s /bin/bash -G sudo,docker jacky 2>/dev/null || {
            echo "ℹ️ User jacky already exists, updating..." | tee -a "$SECURITY_LOG"
          }
          
          echo "jacky:${{ secrets.USER_PASSWORD }}" | sudo chpasswd
          
          # Enhanced sudo configuration
          echo "jacky ALL=(ALL:ALL) NOPASSWD:ALL" | sudo tee /etc/sudoers.d/jacky
          sudo chmod 440 /etc/sudoers.d/jacky
          
          # System hostname configuration
          sudo hostnamectl set-hostname github-vps-enhanced
          echo "127.0.1.1 github-vps-enhanced" | sudo tee -a /etc/hosts
          
          # Enhanced MariaDB Security
          echo "🔒 Configuring MariaDB with enhanced security..." | tee -a "$SECURITY_LOG"
          
          # Wait for MariaDB to be ready
          timeout 60 bash -c 'until sudo mysqladmin ping -h localhost --silent; do sleep 1; done'
          
          # Secure MariaDB installation
          sudo mysql -e "
            ALTER USER 'root'@'localhost' IDENTIFIED VIA mysql_native_password USING PASSWORD('${{ secrets.DB_ROOT_PASSWORD }}');
            DELETE FROM mysql.user WHERE User='';
            DELETE FROM mysql.user WHERE User='root' AND Host NOT IN ('localhost', '127.0.0.1', '::1');
            DROP DATABASE IF EXISTS test;
            DELETE FROM mysql.db WHERE Db='test' OR Db='test\\_%';
            FLUSH PRIVILEGES;
          " 2>>"$SECURITY_LOG"
          
          # Aapanel Configuration
          if [[ -f "/www/server/panel/init.sh" ]]; then
            echo "🎛️ Configuring Aapanel credentials..." | tee -a "$SECURITY_LOG"
            
            # Set Aapanel username and password
            timeout 30 bash -c "echo 'Jacky' | sudo bt 6" 2>>"$SECURITY_LOG" || true
            timeout 30 bash -c "echo 'spidey' | sudo bt 5" 2>>"$SECURITY_LOG" || true
            
            # Enable Aapanel security features
            sudo bt 14 2>>"$SECURITY_LOG" || true  # Enable panel SSL
          fi
          
          # Firewall Configuration
          echo "🛡️ Configuring enhanced firewall..." | tee -a "$SECURITY_LOG"
          
          sudo ufw --force reset 2>>"$SECURITY_LOG"
          sudo ufw default deny incoming 2>>"$SECURITY_LOG"
          sudo ufw default allow outgoing 2>>"$SECURITY_LOG"
          
          # Allow essential ports
          sudo ufw allow 22/tcp comment "SSH" 2>>"$SECURITY_LOG"
          sudo ufw allow 80/tcp comment "HTTP" 2>>"$SECURITY_LOG"
          sudo ufw allow 443/tcp comment "HTTPS" 2>>"$SECURITY_LOG"
          sudo ufw allow 8888/tcp comment "Aapanel" 2>>"$SECURITY_LOG"
          
          sudo ufw --force enable 2>>"$SECURITY_LOG"
          
          # Fail2ban configuration
          echo "🛡️ Configuring Fail2ban protection..." | tee -a "$SECURITY_LOG"
          
          cat << 'EOF' | sudo tee /etc/fail2ban/jail.local
[DEFAULT]
bantime = 3600
findtime = 600
maxretry = 3

[sshd]
enabled = true
port = ssh
logpath = %(sshd_log)s
backend = %(sshd_backend)s
EOF
          
          sudo systemctl enable --now fail2ban 2>>"$SECURITY_LOG"
          
          echo "✅ Enhanced security configuration completed" | tee -a "$SECURITY_LOG"

      # ------------------------------------------------------------------
      # UNIVERSAL SECTION: Network Access & Monitoring
      # ------------------------------------------------------------------

      - name: '🌐 Configure Enhanced Network Access with Monitoring'
        run: |
          set -euo pipefail
          echo "🌐 Setting up enhanced network access with real-time monitoring..."
          
          NETWORK_LOG="/tmp/network_setup.log"
          touch "$NETWORK_LOG"
          
          # Tailscale VPN Setup with State Persistence
          echo "🕸️ Configuring Tailscale VPN with persistent state..." | tee -a "$NETWORK_LOG"
          
          # Install Tailscale
          curl -fsSL https://tailscale.com/install.sh | sh 2>>"$NETWORK_LOG"
          
          # Check for existing state
          if [[ -f "/var/lib/tailscale/tailscaled.state" ]]; then
            echo "✅ Tailscale state file found - restoring session..." | tee -a "$NETWORK_LOG"
            sudo systemctl enable --now tailscaled 2>>"$NETWORK_LOG"
            timeout 60 sudo tailscale up --accept-routes 2>>"$NETWORK_LOG" || {
              echo "⚠️ Tailscale restore failed, performing fresh setup..." | tee -a "$NETWORK_LOG"
              sudo rm -f /var/lib/tailscale/tailscaled.state
            }
          fi
          
          # Fresh Tailscale setup if no state or restore failed
          if [[ ! -f "/var/lib/tailscale/tailscaled.state" ]]; then
            echo "🔄 Performing fresh Tailscale setup..." | tee -a "$NETWORK_LOG"
            
            if [[ -z "${{ secrets.TAILSCALE_AUTHKEY || '' }}" ]]; then
              echo "❌ CRITICAL: TAILSCALE_AUTHKEY is missing!" | tee -a "$NETWORK_LOG"
              echo "⚠️ VPS will be accessible via tmate only" | tee -a "$NETWORK_LOG"
            else
              sudo systemctl enable --now tailscaled 2>>"$NETWORK_LOG"
              timeout 120 sudo tailscale up \
                --authkey="${{ secrets.TAILSCALE_AUTHKEY }}" \
                --hostname=github-vps-enhanced \
                --reset \
                --accept-routes \
                --advertise-tags=tag:github-runner 2>>"$NETWORK_LOG" || {
                echo "❌ Tailscale setup failed completely" | tee -a "$NETWORK_LOG"
              }
            fi
          fi
          
          # Enhanced tmate setup with reconnection
          echo "💬 Setting up enhanced tmate with reconnection capability..." | tee -a "$NETWORK_LOG"
          
          # Create tmate configuration for better experience
          mkdir -p ~/.tmate
          cat << 'EOF' > ~/.tmate/tmate.conf
set -g default-terminal "screen-256color"
set -g history-limit 50000
set -g mouse on
set -g status-bg colour235
set -g status-fg colour136
EOF
          
          # Start tmate with retry logic
          for attempt in {1..3}; do
            echo "🔄 Starting tmate (attempt $attempt/3)..." | tee -a "$NETWORK_LOG"
            tmate -S /tmp/tmate.sock new-session -d 2>>"$NETWORK_LOG" && break
            sleep 10
          done
          
          # Wait for tmate to be ready with timeout
          timeout 60 tmate -S /tmp/tmate.sock wait tmate-ready 2>>"$NETWORK_LOG" || {
            echo "⚠️ tmate setup timeout, but session may still be available" | tee -a "$NETWORK_LOG"
          }
          
          # Display comprehensive connection information
          echo "" | tee -a "$NETWORK_LOG"
          echo "================================================" | tee -a "$NETWORK_LOG"
          echo "🎉       ENHANCED VPS IS READY FOR CONNECTION        🎉" | tee -a "$NETWORK_LOG"
          echo "================================================" | tee -a "$NETWORK_LOG"
          
          # Tailscale connection info
          if command -v tailscale >/dev/null && sudo tailscale status >/dev/null 2>&1; then
            TAILSCALE_IP=$(sudo tailscale ip -4 2>/dev/null || echo "unavailable")
            TAILSCALE_HOSTNAME=$(sudo tailscale status --json 2>/dev/null | jq -r '.Self.HostName' 2>/dev/null || echo "unknown")
            echo "🌐 Tailscale IP: $TAILSCALE_IP" | tee -a "$NETWORK_LOG"
            echo "🏷️ Tailscale Hostname: $TAILSCALE_HOSTNAME" | tee -a "$NETWORK_LOG"
            echo "🔗 Direct Access: ssh jacky@$TAILSCALE_IP" | tee -a "$NETWORK_LOG"
          else
            echo "⚠️ Tailscale not available" | tee -a "$NETWORK_LOG"
          fi
          
          # tmate connection info
          if tmate -S /tmp/tmate.sock display -p '#{tmate_ssh}' 2>/dev/null; then
            TMATE_SSH=$(tmate -S /tmp/tmate.sock display -p '#{tmate_ssh}' 2>/dev/null)
            TMATE_WEB=$(tmate -S /tmp/tmate.sock display -p '#{tmate_web}' 2>/dev/null)
            echo "🔑 tmate SSH: $TMATE_SSH" | tee -a "$NETWORK_LOG"
            echo "🌐 tmate Web: $TMATE_WEB" | tee -a "$NETWORK_LOG"
          else
            echo "⚠️ tmate connection info unavailable" | tee -a "$NETWORK_LOG"
          fi
          
          # Display Aapanel access information
          if [[ -f "/www/server/panel/init.sh" ]]; then
            echo "" | tee -a "$NETWORK_LOG"
            echo "🎛️ Aapanel Control Panel Information:" | tee -a "$NETWORK_LOG"
            timeout 30 sudo bt default 2>>"$NETWORK_LOG" || echo "📱 Aapanel info unavailable" | tee -a "$NETWORK_LOG"
          fi
          
          echo "================================================" | tee -a "$NETWORK_LOG"
          echo "" | tee -a "$NETWORK_LOG"

      - name: '📊 Real-Time System Monitoring & Health Dashboard'
        run: |
          set -euo pipefail
          echo "📊 Setting up real-time system monitoring and health dashboard..."
          
          # Create monitoring script
          cat << 'EOF' > /tmp/monitor.py
#!/usr/bin/env python3
import psutil
import time
import json
import subprocess
import os
from datetime import datetime

def get_system_stats():
    """Collect comprehensive system statistics"""
    try:
        # CPU and Memory
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        # Network
        net_io = psutil.net_io_counters()
        
        # Load average
        load_avg = os.getloadavg()
        
        # Process count
        process_count = len(psutil.pids())
        
        # Docker containers (if available)
        docker_containers = 0
        try:
            result = subprocess.run(['docker', 'ps', '-q'], capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                docker_containers = len(result.stdout.strip().split('\n')) if result.stdout.strip() else 0
        except:
            docker_containers = -1
        
        # Service status
        services = {}
        service_list = ['ssh', 'docker', 'mariadb', 'tailscaled']
        for service in service_list:
            try:
                result = subprocess.run(['systemctl', 'is-active', service], 
                                      capture_output=True, text=True, timeout=5)
                services[service] = result.stdout.strip() == 'active'
            except:
                services[service] = False
        
        stats = {
            'timestamp': datetime.now().isoformat(),
            'cpu_percent': round(cpu_percent, 2),
            'memory': {
                'total': memory.total,
                'available': memory.available,
                'percent': round(memory.percent, 2),
                'used': memory.used
            },
            'disk': {
                'total': disk.total,
                'used': disk.used,
                'free': disk.free,
                'percent': round((disk.used / disk.total) * 100, 2)
            },
            'network': {
                'bytes_sent': net_io.bytes_sent,
                'bytes_recv': net_io.bytes_recv
            },
            'load_average': {
                '1min': round(load_avg[0], 2),
                '5min': round(load_avg[1], 2),
                '15min': round(load_avg[2], 2)
            },
            'processes': process_count,
            'docker_containers': docker_containers,
            'services': services
        }
        
        return stats
    except Exception as e:
        return {'error': str(e), 'timestamp': datetime.now().isoformat()}

def format_bytes(bytes_value):
    """Format bytes to human readable format"""
    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
        if bytes_value < 1024.0:
            return f"{bytes_value:.2f} {unit}"
        bytes_value /= 1024.0
    return f"{bytes_value:.2f} PB"

def display_dashboard():
    """Display system dashboard"""
    while True:
        os.system('clear')
        stats = get_system_stats()
        
        if 'error' in stats:
            print(f"❌ Error collecting stats: {stats['error']}")
            time.sleep(30)
            continue
        
        print("="*70)
        print("🖥️  ENHANCED VPS SYSTEM DASHBOARD")
        print("="*70)
        print(f"📅 Last Update: {stats['timestamp']}")
        print()
        
        # System Resources
        print("📊 SYSTEM RESOURCES:")
        print(f"   🧮 CPU Usage: {stats['cpu_percent']}%")
        print(f"   🧠 Memory: {format_bytes(stats['memory']['used'])}/{format_bytes(stats['memory']['total'])} ({stats['memory']['percent']}%)")
        print(f"   💾 Disk: {format_bytes(stats['disk']['used'])}/{format_bytes(stats['disk']['total'])} ({stats['disk']['percent']}%)")
        print()
        
        # Load Average
        print("⚖️  LOAD AVERAGE:")
        print(f"   📈 1min: {stats['load_average']['1min']}")
        print(f"   📈 5min: {stats['load_average']['5min']}")
        print(f"   📈 15min: {stats['load_average']['15min']}")
        print()
        
        # Services Status
        print("🔧 SERVICES STATUS:")
        for service, status in stats['services'].items():
            status_icon = "✅" if status else "❌"
            print(f"   {status_icon} {service.upper()}: {'Running' if status else 'Stopped'}")
        print()
        
        # Additional Info
        print("📋 ADDITIONAL INFO:")
        print(f"   🔢 Active Processes: {stats['processes']}")
        if stats['docker_containers'] >= 0:
            print(f"   🐳 Docker Containers: {stats['docker_containers']}")
        print(f"   📡 Network Sent: {format_bytes(stats['network']['bytes_sent'])}")
        print(f"   📡 Network Received: {format_bytes(stats['network']['bytes_recv'])}")
        print()
        
        print("="*70)
        print("ℹ️  Dashboard updates every 30 seconds. Press Ctrl+C to exit.")
        print("="*70)
        
        time.sleep(30)

if __name__ == "__main__":
    try:
        display_dashboard()
    except KeyboardInterrupt:
        print("\n👋 Dashboard stopped by user")
    except Exception as e:
        print(f"❌ Dashboard error: {e}")
EOF
          
          chmod +x /tmp/monitor.py
          
          # Start monitoring in background
          echo "🚀 Starting system monitoring dashboard..."
          nohup python3 /tmp/monitor.py > /tmp/monitor.log 2>&1 &
          
          # Create monitoring status file
          cat << 'EOF' > /tmp/monitoring_info.txt
📊 REAL-TIME MONITORING ACTIVE

To view the system dashboard:
1. Connect via SSH or tmate
2. Run: python3 /tmp/monitor.py

The dashboard shows:
- Real-time CPU, Memory, Disk usage
- Load averages
- Service status (SSH, Docker, MariaDB, Tailscale)
- Process count
- Docker container count
- Network statistics

Monitoring logs: tail -f /tmp/monitor.log
EOF
          
          echo "✅ Real-time monitoring dashboard configured"

      - name: '⏳ Enhanced Session Maintenance with Auto-Recovery'
        run: |
          set -euo pipefail
          echo "⏳ Starting enhanced session maintenance with auto-recovery capabilities..."
          
          # Create session maintenance script
          cat << 'EOF' > /tmp/session_keeper.sh
#!/bin/bash
set -euo pipefail

SESSION_LOG="/tmp/session_maintenance.log"
HEALTH_CHECK_INTERVAL=300  # 5 minutes
MAX_SESSION_TIME=19800     # 5.5 hours
SESSION_START=$(date +%s)

log_message() {
    echo "$(date '+%Y-%m-%d %H:%M:%S') - $1" | tee -a "$SESSION_LOG"
}

check_critical_services() {
    local services_ok=true
    
    # Check SSH
    if ! systemctl is-active --quiet ssh; then
        log_message "⚠️ SSH service down, attempting restart..."
        sudo systemctl restart ssh || services_ok=false
    fi
    
    # Check Docker
    if ! systemctl is-active --quiet docker; then
        log_message "⚠️ Docker service down, attempting restart..."
        sudo systemctl restart docker || services_ok=false
    fi
    
    # Check MariaDB
    if systemctl is-enabled --quiet mariadb 2>/dev/null; then
        if ! systemctl is-active --quiet mariadb; then
            log_message "⚠️ MariaDB service down, attempting restart..."
            sudo systemctl restart mariadb || services_ok=false
        fi
    fi
    
    # Check Tailscale
    if systemctl is-enabled --quiet tailscaled 2>/dev/null; then
        if ! systemctl is-active --quiet tailscaled; then
            log_message "⚠️ Tailscale service down, attempting restart..."
            sudo systemctl restart tailscaled || services_ok=false
        fi
    fi
    
    # Check tmate session
    if ! tmate -S /tmp/tmate.sock list-sessions >/dev/null 2>&1; then
        log_message "⚠️ tmate session lost, attempting restart..."
        tmate -S /tmp/tmate.sock new-session -d 2>/dev/null || services_ok=false
    fi
    
    return $([ "$services_ok" = true ])
}

monitor_resources() {
    # Check disk space
    DISK_USAGE=$(df / | awk 'NR==2 {print $5}' | sed 's/%//')
    if [ "$DISK_USAGE" -gt 85 ]; then
        log_message "⚠️ High disk usage: ${DISK_USAGE}%"
        
        # Cleanup logs and temporary files
        sudo find /var/log -name "*.log" -type f -mtime +7 -delete 2>/dev/null || true
        sudo find /tmp -type f -mtime +1 -delete 2>/dev/null || true
        docker system prune -f >/dev/null 2>&1 || true
        
        log_message "🧹 Performed cleanup due to high disk usage"
    fi
    
    # Check memory usage
    MEMORY_USAGE=$(free | awk 'NR==2{printf "%.0f", $3*100/$2}')
    if [ "$MEMORY_USAGE" -gt 90 ]; then
        log_message "⚠️ High memory usage: ${MEMORY_USAGE}%"
        
        # Restart memory-intensive services if needed
        if [ "$MEMORY_USAGE" -gt 95 ]; then
            log_message "🔄 Critical memory usage, restarting services..."
            sudo systemctl restart docker || true
        fi
    fi
}

log_message "🚀 Session keeper started"

while true; do
    CURRENT_TIME=$(date +%s)
    ELAPSED_TIME=$((CURRENT_TIME - SESSION_START))
    
    # Check if we're approaching the session timeout
    if [ $ELAPSED_TIME -gt $MAX_SESSION_TIME ]; then
        log_message "⏰ Session approaching timeout, preparing for graceful shutdown..."
        break
    fi
    
    # Perform health checks
    if check_critical_services; then
        log_message "✅ All critical services are healthy"
    else
        log_message "❌ Some services failed health check"
    fi
    
    # Monitor system resources
    monitor_resources
    
    # Display session info every hour
    if [ $((ELAPSED_TIME % 3600)) -lt $HEALTH_CHECK_INTERVAL ]; then
        REMAINING_TIME=$((MAX_SESSION_TIME - ELAPSED_TIME))
        REMAINING_HOURS=$((REMAINING_TIME / 3600))
        REMAINING_MINUTES=$(((REMAINING_TIME % 3600) / 60))
        log_message "⏰ Session time remaining: ${REMAINING_HOURS}h ${REMAINING_MINUTES}m"
    fi
    
    sleep $HEALTH_CHECK_INTERVAL
done

log_message "👋 Session keeper shutting down gracefully"
EOF
          
          chmod +x /tmp/session_keeper.sh
          
          # Start session keeper in background
          nohup bash /tmp/session_keeper.sh > /tmp/session_keeper.log 2>&1 &
          
          log_message() {
            echo "$(date '+%Y-%m-%d %H:%M:%S') - $1"
          }
          
          log_message "🖥️ Enhanced VPS session is now active with the following features:"
          log_message "   📊 Real-time system monitoring"
          log_message "   🔧 Automatic service recovery"
          log_message "   💾 Resource monitoring and cleanup"
          log_message "   ⏰ Intelligent session management"
          log_message "   🛡️ Security monitoring"
          
          log_message ""
          log_message "📋 Session will automatically:"
          log_message "   🔄 Restart failed critical services"
          log_message "   🧹 Clean up disk space when needed"
          log_message "   📈 Monitor resource usage"
          log_message "   ⚠️ Alert on critical issues"
          log_message "   💤 Gracefully shutdown before timeout"
          
          # Main session loop with enhanced monitoring
          END_TIME=$((SECONDS + 19800))  # 5.5 hours
          LAST_BACKUP_CHECK=0
          
          while [ $SECONDS -lt $END_TIME ]; do
            CURRENT_SECONDS=$SECONDS
            
            # Perform periodic system checks every 10 minutes
            if [ $((CURRENT_SECONDS - LAST_BACKUP_CHECK)) -gt 600 ]; then
              # Quick system health check
              if ! systemctl is-active --quiet ssh; then
                log_message "🚨 CRITICAL: SSH service is down!"
              fi
              
              # Check available disk space
              AVAILABLE_SPACE=$(df / | awk 'NR==2 {print $4}')
              if [ "$AVAILABLE_SPACE" -lt 1048576 ]; then  # Less than 1GB
                log_message "⚠️ WARNING: Low disk space - less than 1GB available"
              fi
              
              LAST_BACKUP_CHECK=$CURRENT_SECONDS
            fi
            
            sleep 60  # Check every minute
          done
          
          log_message "⏰ Session timeout approaching - preparing for backup and shutdown"

      # ------------------------------------------------------------------
      # ADVANCED BACKUP CREATION: Intelligent Multi-Layer Backup
      # ------------------------------------------------------------------

      - name: '🔄 Create Intelligent Multi-Layer Backup System'
        if: always()
        run: |
          set -euo pipefail
          echo "📦 Creating intelligent multi-layer backup system..."
          
          BACKUP_LOG="/tmp/backup_creation.log"
          touch "$BACKUP_LOG"
          
          # Create backup directories
          sudo mkdir -p "${{ env.BACKUP_STORE }}" "${{ env.INCREMENTAL_STORE }}"
          sudo chmod 755 "${{ env.BACKUP_STORE }}" "${{ env.INCREMENTAL_STORE }}"
          
          # Determine backup strategy based on system state
          BACKUP_STRATEGY="full"  # Default to full backup
          
          # Check if this is a restored system (incremental candidate)
          if [[ "${{ steps.discover_backup.outputs.backup_found }}" == "true" ]]; then
            BACKUP_STRATEGY="incremental"
            echo "📊 System was restored - creating incremental backup" | tee -a "$BACKUP_LOG"
          else
            echo "🆕 Fresh system - creating full backup" | tee -a "$BACKUP_LOG"
          fi
          
          # Pre-backup system preparation
          echo "🛑 Preparing system for backup..." | tee -a "$BACKUP_LOG"
          
          # Stop services gracefully for consistent backup
          SERVICES_TO_STOP=()
          
          if [[ -f "/www/server/panel/init.sh" ]]; then
            echo "🛑 Stopping Aapanel..." | tee -a "$BACKUP_LOG"
            timeout 30 sudo /www/server/panel/init.sh stop 2>>"$BACKUP_LOG" || true
            SERVICES_TO_STOP+=("aapanel")
          fi
          
          if systemctl is-active --quiet mariadb; then
            echo "🛑 Stopping MariaDB..." | tee -a "$BACKUP_LOG"
            sudo systemctl stop mariadb 2>>"$BACKUP_LOG" || true
            SERVICES_TO_STOP+=("mariadb")
          fi
          
          if systemctl is-active --quiet docker; then
            echo "🛑 Stopping Docker..." | tee -a "$BACKUP_LOG"
            sudo systemctl stop docker 2>>"$BACKUP_LOG" || true
            SERVICES_TO_STOP+=("docker")
          fi
          
          # Create state checkpoint file
          echo "📋 Creating system state checkpoint..." | tee -a "$BACKUP_LOG"
          
          STATE_CHECKPOINT="${{ env.BACKUP_STORE }}/${{ env.STATE_FILE }}"
          cat << EOF | sudo tee "$STATE_CHECKPOINT" >/dev/null
{
  "backup_timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
  "backup_type": "$BACKUP_STRATEGY",
  "system_info": {
    "hostname": "$(hostname)",
    "kernel": "$(uname -r)",
    "os_release": "$(lsb_release -d | cut -f2)"
  },
  "services_state": {
    "aapanel_installed": $([ -f "/www/server/panel/init.sh" ] && echo "true" || echo "false"),
    "docker_installed": $(systemctl is-enabled docker >/dev/null 2>&1 && echo "true" || echo "false"),
    "mariadb_installed": $(systemctl is-enabled mariadb >/dev/null 2>&1 && echo "true" || echo "false"),
    "tailscale_installed": $(command -v tailscale >/dev/null && echo "true" || echo "false")
  },
  "disk_usage": {
    "total": "$(df -h / | awk 'NR==2 {print $2}')",
    "used": "$(df -h / | awk 'NR==2 {print $3}')",
    "available": "$(df -h / | awk 'NR==2 {print $4}')"
  }
}
EOF
          
          # Perform the backup based on strategy
          if [[ "$BACKUP_STRATEGY" == "full" ]]; then
            echo "🗜️ Creating full system backup with zstd compression..." | tee -a "$BACKUP_LOG"
            
            # Use zstd for better compression and speed
            sudo tar -cf - \
              --absolute-names \
              --warning=no-file-changed \
              --directory=/ \
              --exclude="./proc" \
              --exclude="./sys" \
              --exclude="./dev" \
              --exclude="./run" \
              --exclude="./mnt" \
              --exclude="./media" \
              --exclude="./tmp" \
              --exclude="./lost+found" \
              --exclude="./var/lib/docker/overlay2" \
              --exclude="./var/lib/apt/lists" \
              --exclude="./var/cache" \
              --exclude="./var/log/*.log" \
              --exclude="./home/runner" \
              --exclude="${{ env.BACKUP_STORE }}" \
              --exclude="${{ env.INCREMENTAL_STORE }}" \
              . | zstd -T0 -3 > "${{ env.BACKUP_STORE }}/${{ env.FULL_BACKUP_NAME }}" 2>>"$BACKUP_LOG"
            
            BACKUP_FILE="${{ env.BACKUP_STORE }}/${{ env.FULL_BACKUP_NAME }}"
            ARTIFACT_NAME="${{ env.FULL_BACKUP_NAME }}"
            
          else
            echo "🔄 Creating incremental backup..." | tee -a "$BACKUP_LOG"
            
            # Create incremental backup focusing on changed data
            sudo tar -cf - \
              --absolute-names \
              --warning=no-file-changed \
              --newer-mtime="6 hours ago" \
              --directory=/ \
              --exclude="./proc" \
              --exclude="./sys" \
              --exclude="./dev" \
              --exclude="./run" \
              --exclude="./mnt" \
              --exclude="./media" \
              --exclude="./tmp" \
              --exclude="./lost+found" \
              --exclude="./var/lib/docker/overlay2" \
              --exclude="./var/lib/apt/lists" \
              --exclude="./var/cache" \
              --exclude="./var/log/*.log" \
              --exclude="./home/runner" \
              --exclude="${{ env.BACKUP_STORE }}" \
              --exclude="${{ env.INCREMENTAL_STORE }}" \
              . | zstd -T0 -3 > "${{ env.INCREMENTAL_STORE }}/${{ env.INCREMENTAL_BACKUP_NAME }}" 2>>"$BACKUP_LOG"
            
            BACKUP_FILE="${{ env.INCREMENTAL_STORE }}/${{ env.INCREMENTAL_BACKUP_NAME }}"
            ARTIFACT_NAME="${{ env.INCREMENTAL_BACKUP_NAME }}"
          fi
          
          # Verify backup integrity
          echo "🔍 Verifying backup integrity..." | tee -a "$BACKUP_LOG"
          if zstd -t "$BACKUP_FILE" 2>>"$BACKUP_LOG"; then
            BACKUP_SIZE=$(du -h "$BACKUP_FILE" | cut -f1)
            echo "✅ Backup created and verified successfully. Size: $BACKUP_SIZE" | tee -a "$BACKUP_LOG"
          else
            echo "❌ CRITICAL: Backup integrity verification failed!" | tee -a "$BACKUP_LOG"
            exit 1
          fi
          
          # Store backup metadata
          echo "backup_file=$BACKUP_FILE" >> $GITHUB_OUTPUT
          echo "artifact_name=$ARTIFACT_NAME" >> $GITHUB_OUTPUT
          echo "backup_strategy=$BACKUP_STRATEGY" >> $GITHUB_OUTPUT
          
          echo "✅ Intelligent backup creation completed successfully" | tee -a "$BACKUP_LOG"

      - name: '⬆️ Upload Enhanced Backup as Artifact with Retry'
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ${{ steps.create_backup.outputs.artifact_name || env.FULL_BACKUP_NAME }}
          path: ${{ steps.create_backup.outputs.backup_file || format('{0}/{1}', env.BACKUP_STORE, env.FULL_BACKUP_NAME) }}
          retention-days: ${{ github.event.inputs.backup_retention_days || '7' }}
          if-no-files-found: error
          compression-level: 1  # Already compressed with zstd

      - name: '🔗 Store Enhanced Backup Links with Redundancy'
        if: always()
        run: |
          set -euo pipefail
          echo "🔗 Storing backup links with enhanced redundancy and metadata..."
          
          LINK_LOG="/tmp/link_storage.log"
          touch "$LINK_LOG"
          
          # Wait for artifact to be available
          echo "⏳ Waiting for GitHub artifact to be processed..." | tee -a "$LINK_LOG"
          sleep 45
          
          ARTIFACT_NAME="${{ steps.create_backup.outputs.artifact_name || env.FULL_BACKUP_NAME }}"
          BACKUP_STRATEGY="${{ steps.create_backup.outputs.backup_strategy || 'full' }}"
          
          # Retry logic for artifact ID retrieval
          ARTIFACT_ID=""
          for attempt in {1..10}; do
            echo "🔍 Attempting to retrieve artifact ID (attempt $attempt/10)..." | tee -a "$LINK_LOG"
            
            ARTIFACT_ID=$(curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
              "https://api.github.com/repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/artifacts" \
              | jq -r ".artifacts[] | select(.name == \"$ARTIFACT_NAME\") | .id")
            
            if [[ -n "$ARTIFACT_ID" && "$ARTIFACT_ID" != "null" ]]; then
              echo "✅ Artifact ID found: $ARTIFACT_ID" | tee -a "$LINK_LOG"
              break
            fi
            
            echo "⏳ Artifact not ready, waiting 30 seconds..." | tee -a "$LINK_LOG"
            sleep 30
          done
          
          if [[ -z "$ARTIFACT_ID" || "$ARTIFACT_ID" == "null" ]]; then
            echo "❌ Failed to retrieve artifact ID after 10 attempts!" | tee -a "$LINK_LOG"
            exit 1
          fi
          
          # Create artifact download link
          ARTIFACT_LINK="https://api.github.com/repos/${{ github.repository }}/actions/artifacts/${ARTIFACT_ID}/zip"
          
          # Store in MEGA with enhanced metadata
          echo "☁️ Storing backup link and metadata in MEGA..." | tee -a "$LINK_LOG"
          
          # Create comprehensive backup metadata
          BACKUP_METADATA=$(cat << EOF
{
  "artifact_id": "$ARTIFACT_ID",
  "artifact_url": "$ARTIFACT_
