# 🛸 OMNITRIX VPS SESSION - BEN 10 ALIEN FORCE EDITION 👽
# ═══════════════════════════════════════════════════════════════════
#                    🔋 POWERED BY ALIEN TECHNOLOGY 🔋
# ═══════════════════════════════════════════════════════════════════

name: "🛸 OMNITRIX VPS - Ben 10 Alien Force Edition 👽"

on:
  workflow_dispatch:
  schedule:
    - cron: '0 */6 * * *'

env:
  BACKUP_NEXUS: /mnt/omnitrix/backups
  BACKUP_ARTIFACT: userdata-backup.tar.gz
  GALVAN_CLOUD: mega:omnitrix-vault
  HERO_SESSION_DURATION: 19800
  PLUMBER_NETWORK: Plumbers-HQ
  
jobs:
  omnitrix_session:
    name: "🛸 OMNITRIX UNIVERSE SESSION 👽"
    runs-on: ubuntu-22.04
    timeout-minutes: 350
    permissions:
      contents: read
      actions: write
    
    steps:
    - name: "🛸 Scanning Universe Repository"
      uses: actions/checkout@v4
      
    - name: "⚡ DEPLOYING ALIEN TECHNOLOGY SUITE"
      run: |
        set -e
        echo "🛸 OMNITRIX SYSTEM ACTIVATION 👽"
        echo "⏰ Mission Start: $(date)"
        
        # Update package registry
        sudo apt-get update -qq || sudo apt-get update --fix-missing -qq || true
        
        # Install rclone and essential tools
        if ! command -v rclone >/dev/null 2>&1; then
          curl -fsSL https://rclone.org/install.sh | sudo bash || {
            cd /tmp
            wget -q https://downloads.rclone.org/rclone-current-linux-amd64.zip
            sudo apt-get install -y unzip
            unzip -q rclone-current-linux-amd64.zip
            sudo cp rclone-*/rclone /usr/bin/ && sudo chmod +x /usr/bin/rclone
          }
        fi
        
        # Install essential tools
        TOOLS="curl wget jq tar gzip unzip openssh-server nano vim git net-tools"
        TOOLS="$TOOLS software-properties-common apt-transport-https ca-certificates"
        TOOLS="$TOOLS gnupg psmisc screen expect tmate mariadb-server mariadb-client"
        
        sudo DEBIAN_FRONTEND=noninteractive apt-get install -y $TOOLS || true

    - name: "☁️ GALVAN PRIME CLOUD CONFIGURATION"
      run: |
        set -e
        echo "☁️ Establishing connection to Galvan Prime Cloud..."
        
        if [[ -z "${{ secrets.RCLONE_CONFIG || '' }}" ]]; then
          echo "❌ CRITICAL: RCLONE_CONFIG secret missing!"
          exit 1
        fi
        
        # Create config directories and deploy configuration
        mkdir -p ~/.config/rclone
        sudo mkdir -p /root/.config/rclone
        
        if echo "${{ secrets.RCLONE_CONFIG }}" | base64 -d >/dev/null 2>&1; then
          echo "${{ secrets.RCLONE_CONFIG }}" | base64 -d > ~/.config/rclone/rclone.conf
          echo "${{ secrets.RCLONE_CONFIG }}" | base64 -d | sudo tee /root/.config/rclone/rclone.conf >/dev/null
        else
          echo "${{ secrets.RCLONE_CONFIG }}" > ~/.config/rclone/rclone.conf
          echo "${{ secrets.RCLONE_CONFIG }}" | sudo tee /root/.config/rclone/rclone.conf >/dev/null
        fi
        
        chmod 600 ~/.config/rclone/rclone.conf
        sudo chmod 600 /root/.config/rclone/rclone.conf

    - name: "🔍 SCANNING FOR USER DATA BACKUPS"
      id: data_backup_scan
      run: |
        set -e
        echo "🔍 Scanning for user data backups..."
        
        # Install backup scripts
        sudo mkdir -p /usr/local/bin
        
        # Create backup.sh script
        cat > /tmp/backup.sh << 'EOF'
        #!/bin/bash
        # User Data Backup Script - Only backs up user data with persistence

        BACKUP_DIR="/mnt/omnitrix/backups"
        BACKUP_FILE="userdata-backup-$(date +%Y%m%d-%H%M%S).tar.gz"
        LATEST_LINK="latest-userdata-backup.tar.gz"
        CLOUD_STORAGE="mega:omnitrix-vault"

        sudo mkdir -p "$BACKUP_DIR"

        # Define directories to backup (only user data)
        USER_DIRS=("/home" "/root" "/var/www/html")

        # Application data directories
        APP_DIRS=(
        "/etc/mysql"         # MySQL configuration
        "/etc/php"           # PHP configuration
        "/etc/apache2"       # Apache configuration
        "/etc/nginx"         # Nginx configuration (if used)
        "/var/lib/mysql"     # MySQL data
        "/var/lib/php"       # PHP sessions and data
        "/etc/letsencrypt"   # SSL certificates
        "/usr/local/aapanel" # aaPanel data (if installed)
        )

        # Optional directories (only backed up if they exist)
        OPTIONAL_DIRS=("/var/lib/tailscale" "/etc/ssh")

        echo "🛸 USER DATA BACKUP STARTING 👽"
        echo "⏰ Backup Start: $(date)"

        # Create temporary directory for backup
        TEMP_DIR=$(mktemp -d)
        mkdir -p "$TEMP_DIR/selective_backup"

        # Backup function
        backup_directory() {
        local src_dir="$1"
        local dest_dir="$2"
        local description="$3"
  
        if [[ -d "$src_dir" ]]; then
        echo "📂 Backing up $description..."
        mkdir -p "$dest_dir"
        sudo cp -rf "$src_dir" "$dest_dir/" 2>/dev/null || sudo rsync -av "$src_dir" "$dest_dir/" 2>/dev/null || true
        fi
        }

        # Backup required user directories
        for dir in "${USER_DIRS[@]}"; do
        dir_name=$(basename "$dir")
        backup_directory "$dir" "$TEMP_DIR/selective_backup" "$dir_name"
        done

        # Backup application data directories if they exist
        for dir in "${APP_DIRS[@]}"; do
        if [[ -d "$dir" ]]; then
        dir_name=$(basename "$dir")
        backup_directory "$dir" "$TEMP_DIR/selective_backup" "$dir_name"
        fi
        done

        # Backup optional directories if they exist
        for dir in "${OPTIONAL_DIRS[@]}"; do
        if [[ -d "$dir" ]]; then
        dir_name=$(basename "$dir")
        backup_directory "$dir" "$TEMP_DIR/selective_backup" "$dir_name"
        fi
        done

        # Special handling for MySQL databases
        if command -v mysqldump >/dev/null 2>&1; then
        echo "📂 Backing up MySQL databases..."
        mkdir -p "$TEMP_DIR/selective_backup/mysql_dumps"
  
        # Create MySQL dump with all databases
        sudo mysqldump --all-databases --single-transaction --quick --lock-tables=false > "$TEMP_DIR/selective_backup/mysql_dumps/all_databases.sql" 2>/dev/null || echo "⚠️ MySQL dump failed, but continuing..."
        fi

        # Create the backup archive
        echo "📦 Creating backup archive..."
        sudo tar -czf "$BACKUP_DIR/$BACKUP_FILE" -C "$TEMP_DIR" selective_backup
        sudo ln -sf "$BACKUP_DIR/$BACKUP_FILE" "$BACKUP_DIR/$LATEST_LINK"

        # Upload to cloud storage
         if command -v rclone >/dev/null 2>&1; then
         echo "☁️ Uploading to cloud storage..."
         rclone copy "$BACKUP_DIR/$BACKUP_FILE" "$CLOUD_STORAGE/" 2>/dev/null || true
         echo "$BACKUP_DIR/$BACKUP_FILE" | rclone rcat "$CLOUD_STORAGE/temporal_backup_link.txt" 2>/dev/null || true
         fi

         # Clean up and set permissions
         sudo rm -rf "$TEMP_DIR"
         sudo chmod 600 "$BACKUP_DIR/$BACKUP_FILE"

         echo "✅ USER DATA BACKUP COMPLETE!"
         echo "📁 Backup Location: $BACKUP_DIR/$BACKUP_FILE"
         echo "📊 Backup Size: $(du -h "$BACKUP_DIR/$BACKUP_FILE" | cut -f1)"
         EOF

        # Create restore.sh script
        cat > /tmp/restore.sh << 'EOF'
        #!/bin/bash
        # User Data Restore Script - Only restores user data with persistence

        BACKUP_DIR="/mnt/omnitrix/backups"
        LATEST_LINK="latest-userdata-backup.tar.gz"
        CLOUD_STORAGE="mega:omnitrix-vault"

        echo "🛸 USER DATA RESTORATION STARTING 👽"
        echo "⏰ Restore Start: $(date)"

        # Create temporary directory for restoration
        RESTORE_CHAMBER="/tmp/userdata_restore"
        sudo rm -rf "$RESTORE_CHAMBER" 2>/dev/null || true
        sudo mkdir -p "$RESTORE_CHAMBER"
        sudo chmod 777 "$RESTORE_CHAMBER"
        cd "$RESTORE_CHAMBER"

        # Find backup file (local or cloud)
        BACKUP_FILE=""

        # Check local backup first
        if [[ -f "$BACKUP_DIR/$LATEST_LINK" ]]; then
        BACKUP_FILE="$BACKUP_DIR/$LATEST_LINK"
        elif [[ -d "$BACKUP_DIR" ]]; then
        LATEST_BACKUP=$(find "$BACKUP_DIR" -name "userdata-backup-*.tar.gz" -type f -printf "%T@ %p\n" | sort -nr | head -1 | cut -d' ' -f2-)
        if [[ -n "$LATEST_BACKUP" ]]; then
        BACKUP_FILE="$LATEST_BACKUP"
        fi
        fi

        # If no local backup, try cloud storage
        if [[ -z "$BACKUP_FILE" ]] && command -v rclone >/dev/null 2>&1; then
        if rclone ls "$CLOUD_STORAGE/temporal_backup_link.txt" >/dev/null 2>&1; then
        BACKUP_LINK=$(rclone cat "$CLOUD_STORAGE/temporal_backup_link.txt" 2>/dev/null)
        if [[ -n "$BACKUP_LINK" ]]; then
        CLOUD_BACKUP=$(basename "$BACKUP_LINK")
        rclone copy "$CLOUD_STORAGE/$CLOUD_BACKUP" . 2>/dev/null && BACKUP_FILE="./$CLOUD_BACKUP"
        fi
        fi
  
        if [[ -z "$BACKUP_FILE" ]]; then
        CLOUD_BACKUPS=$(rclone lsf "$CLOUD_STORAGE/" 2>/dev/null | grep -E "userdata-backup-.*\.tar\.gz" || echo "")
        if [[ -n "$CLOUD_BACKUPS" ]]; then
        LATEST_CLOUD=$(echo "$CLOUD_BACKUPS" | sort -r | head -1)
        rclone copy "$CLOUD_STORAGE/$LATEST_CLOUD" . 2>/dev/null && BACKUP_FILE="./$LATEST_CLOUD"
        fi
        fi
        fi

        # Exit if no backup found
        if [[ -z "$BACKUP_FILE" ]]; then
        echo "❌ No backup file found. Cannot restore user data."
        exit 1
        fi

        # Extract backup
        STAGING_AREA="/tmp/restore_data"
        sudo rm -rf "$STAGING_AREA" 2>/dev/null || true
        sudo mkdir -p "$STAGING_AREA"
        sudo chmod 777 "$STAGING_AREA"

        if ! tar -xzf "$BACKUP_FILE" -C "$STAGING_AREA"; then
        echo "❌ Failed to extract backup."
        exit 1
        fi

        # Find data directory
        DATA_ROOT=""
        if [[ -d "$STAGING_AREA/selective_backup" ]]; then
        DATA_ROOT="$STAGING_AREA/selective_backup"
        else
        DATA_ROOT=$(find "$STAGING_AREA" -type d -name "*backup*" -o -name "*selective*" | head -1)
        if [[ -z "$DATA_ROOT" ]]; then
        DATA_ROOT="$STAGING_AREA"
        fi
        fi

        # Restore function
        restore_directory() {
        local src_dir="$1"
        local dest_dir="$2"
        local description="$3"
        local owner="$4"
  
        if [[ -d "$src_dir" ]] && [[ -n "$(ls -A "$src_dir" 2>/dev/null)" ]]; then
        echo "📂 Restoring $description..."
        sudo mkdir -p "$dest_dir"
        sudo cp -rf "$src_dir"/* "$dest_dir/" 2>/dev/null || sudo rsync -av "$src_dir"/ "$dest_dir"/ 2>/dev/null || true
        if [[ -n "$owner" ]]; then
        sudo chown -R "$owner" "$dest_dir" 2>/dev/null || true
        fi
        fi
        }

        # Restore user data
        [[ -d "$DATA_ROOT/home" ]] && restore_directory "$DATA_ROOT/home" "/home" "User home directories" "root:root"
        [[ -d "$DATA_ROOT/root" ]] && restore_directory "$DATA_ROOT/root" "/root" "Root user data" "root:root"
        [[ -d "$DATA_ROOT/html" ]] && restore_directory "$DATA_ROOT/html" "/var/www/html" "Web content" "www-data:www-data"

        # Restore application data
        [[ -d "$DATA_ROOT/mysql" ]] && restore_directory "$DATA_ROOT/mysql" "/etc/mysql" "MySQL configuration" "mysql:mysql"
        [[ -d "$DATA_ROOT/php" ]] && restore_directory "$DATA_ROOT/php" "/etc/php" "PHP configuration" "root:root"
        [[ -d "$DATA_ROOT/apache2" ]] && restore_directory "$DATA_ROOT/apache2" "/etc/apache2" "Apache configuration" "root:www-data"
        [[ -d "$DATA_ROOT/nginx" ]] && restore_directory "$DATA_ROOT/nginx" "/etc/nginx" "Nginx configuration" "root:www-data"
        [[ -d "$DATA_ROOT/mysql" ]] && restore_directory "$DATA_ROOT/mysql" "/var/lib/mysql" "MySQL data" "mysql:mysql"
        [[ -d "$DATA_ROOT/php" ]] && restore_directory "$DATA_ROOT/php" "/var/lib/php" "PHP data" "root:root"
        [[ -d "$DATA_ROOT/letsencrypt" ]] && restore_directory "$DATA_ROOT/letsencrypt" "/etc/letsencrypt" "SSL certificates" "root:root"
        [[ -d "$DATA_ROOT/aapanel" ]] && restore_directory "$DATA_ROOT/aapanel" "/usr/local/aapanel" "aaPanel data" "root:root"

         # Restore MySQL dumps if they exist
         if [[ -d "$DATA_ROOT/mysql_dumps" ]]; then
         echo "📂 Restoring MySQL databases..."
         if [[ -f "$DATA_ROOT/mysql_dumps/all_databases.sql" ]]; then
         # Start MySQL service if not running
         sudo service mysql start 2>/dev/null || sudo systemctl start mysql 2>/dev/null || sudo systemctl start mariadb 2>/dev/null || true
    
         # Restore databases
         sudo mysql < "$DATA_ROOT/mysql_dumps/all_databases.sql" 2>/dev/null || echo "⚠️ MySQL restore failed, but continuing..."
         fi
         fi

         # Restore optional directories
         [[ -d "$DATA_ROOT/tailscale" ]] && restore_directory "$DATA_ROOT/tailscale" "/var/lib/tailscale" "Network configuration" "root:root"
         [[ -d "$DATA_ROOT/ssh" ]] && restore_directory "$DATA_ROOT/ssh" "/etc/ssh" "SSH configuration" "root:root"

         # Fix permissions
         sudo chmod -R 755 /home/* 2>/dev/null || true
         sudo chmod 700 /root 2>/dev/null || true
         sudo chmod 644 /etc/ssh/ssh_config* 2>/dev/null || true
         sudo chmod 600 /etc/ssh/ssh_host_* 2>/dev/null || true
         sudo chmod 644 /etc/mysql/my.cnf 2>/dev/null || true
         sudo chmod 644 /etc/php/*/*/php.ini 2>/dev/null || true
         sudo chmod 644 /etc/apache2/apache2.conf 2>/dev/null || true
         sudo chmod 644 /etc/nginx/nginx.conf 2>/dev/null || true

         # Restart services if needed
         sudo service mysql restart 2>/dev/null || sudo systemctl restart mysql 2>/dev/null || sudo systemctl restart mariadb 2>/dev/null || true
         sudo service apache2 restart 2>/dev/null || sudo systemctl restart apache2 2>/dev/null || true
         sudo service nginx restart 2>/dev/null || sudo systemctl restart nginx 2>/dev/null || true
         sudo service php* restart 2>/dev/null || sudo systemctl restart php* 2>/dev/null || true

         # Cleanup
        sudo rm -rf "$STAGING_AREA" "$RESTORE_CHAMBER" 2>/dev/null || true

        echo "✅ USER DATA RESTORATION COMPLETE!"
        EOF

        # Create persistence.sh script
        cat > /tmp/persistence.sh << 'EOF'
        #!/bin/bash
        # Persistence Mechanism for User Data Backups

        BACKUP_DIR="/mnt/omnitrix/backups"
        CLOUD_STORAGE="mega:omnitrix-vault"
        PERSISTENCE_FILE="backup_persistence.json"

        sudo mkdir -p "$BACKUP_DIR"

        # Create persistence file if it doesn't exist
        if [[ ! -f "$BACKUP_DIR/$PERSISTENCE_FILE" ]]; then
        echo "[$(date '+%Y-%m-%d %H:%M:%S')] Creating persistence file..."
        cat > "$BACKUP_DIR/$PERSISTENCE_FILE" << EOF
        {
        "last_backup": "",
        "backup_history": [],
        "restore_history": [],
        "session_count": 0
        }
        EOF
        sudo chmod 644 "$BACKUP_DIR/$PERSISTENCE_FILE"
        fi

        # Sync persistence file with cloud
        if command -v rclone >/dev/null 2>&1; then
        # Try to retrieve from cloud first
        if [[ ! -f "$BACKUP_DIR/$PERSISTENCE_FILE" ]]; then
        rclone copy "$CLOUD_STORAGE/$PERSISTENCE_FILE" "$BACKUP_DIR/" 2>/dev/null || true
        fi
  
        # Upload current persistence file
        rclone copy "$BACKUP_DIR/$PERSISTENCE_FILE" "$CLOUD_STORAGE/" 2>/dev/null || true
        fi

        # Update session count
        if [[ -f "$BACKUP_DIR/$PERSISTENCE_FILE" ]]; then
        SESSION_COUNT=$(grep -o '"session_count": [0-9]*' "$BACKUP_DIR/$PERSISTENCE_FILE" | awk '{print $2}')
        SESSION_COUNT=$((SESSION_COUNT + 1))
        sed -i "s/\"session_count\": [0-9]*/\"session_count\": $SESSION_COUNT/" "$BACKUP_DIR/$PERSISTENCE_FILE"
  
        # Check if we need to run a backup
        LAST_BACKUP=$(grep -o '"last_backup": "[^"]*"' "$BACKUP_DIR/$PERSISTENCE_FILE" | cut -d'"' -f4)
        if [[ -z "$LAST_BACKUP" ]] || [[ ! -f "$LAST_BACKUP" ]] || [[ $(find "$LAST_BACKUP" -mtime +1 -print 2>/dev/null) ]]; then
        echo "[$(date '+%Y-%m-%d %H:%M:%S')] Running scheduled backup..."
        bash /usr/local/bin/backup.sh
        fi
        fi
        EOF

        # Install the scripts
        sudo mv /tmp/backup.sh /usr/local/bin/backup.sh
        sudo mv /tmp/restore.sh /usr/local/bin/restore.sh
        sudo mv /tmp/persistence.sh /usr/local/bin/persistence.sh
        
        sudo chmod +x /usr/local/bin/backup.sh
        sudo chmod +x /usr/local/bin/restore.sh
        sudo chmod +x /usr/local/bin/persistence.sh
        
        # Create backup directory
        sudo mkdir -p "$BACKUP_NEXUS"
        
        # Check for existing backups
        RECOVERY_SUCCESS=false
        
        # Check cloud storage for backups
        if rclone ls "${GALVAN_CLOUD}/temporal_backup_link.txt" >/dev/null 2>&1; then
          BACKUP_LINK=$(rclone cat "${GALVAN_CLOUD}/temporal_backup_link.txt" 2>/dev/null)
          if [[ -n "$BACKUP_LINK" ]]; then
            echo "has_backup=true" >> $GITHUB_OUTPUT
            echo "backup_source=galvan_prime" >> $GITHUB_OUTPUT
            echo "artifact_url=$BACKUP_LINK" >> $GITHUB_OUTPUT
            RECOVERY_SUCCESS=true
          fi
        fi
        
        # Check direct cloud backups
        if [[ "$RECOVERY_SUCCESS" == "false" ]]; then
          BACKUP_LIST=$(rclone lsf "${GALVAN_CLOUD}/" 2>/dev/null || echo "")
          if [[ -n "$BACKUP_LIST" ]]; then
            LATEST_BACKUP=$(echo "$BACKUP_LIST" | grep -E "userdata-backup-.*\.tar\.gz" | sort -r | head -1)
            if [[ -n "$LATEST_BACKUP" ]]; then
              echo "has_backup=true" >> $GITHUB_OUTPUT
              echo "backup_source=galvan_direct" >> $GITHUB_OUTPUT
              echo "backup_file=$LATEST_BACKUP" >> $GITHUB_OUTPUT
              RECOVERY_SUCCESS=true
            fi
          fi
        fi
        
        if [[ "$RECOVERY_SUCCESS" == "false" ]]; then
          echo "has_backup=false" >> $GITHUB_OUTPUT
          echo "backup_source=none" >> $GITHUB_OUTPUT
        fi

    - name: "📥 USER DATA RESTORATION"
      if: steps.data_backup_scan.outputs.has_backup == 'true'
      run: |
        set -e
        echo "📥 USER DATA RESTORATION 👽"
        echo "🔋 Source: ${{ steps.data_backup_scan.outputs.backup_source }}"
        
        # Run the restore script
        sudo /usr/local/bin/restore.sh
        
        echo "✅ USER DATA RESTORATION COMPLETE!"

    - name: "👤 HERO ACCOUNT CONFIGURATION"
      run: |
        set -e
        echo "👤 Configuring Hero Account..."
        
        if [[ -z "${{ secrets.USER_PASSWORD || '' }}" ]]; then
          echo "❌ CRITICAL: USER_PASSWORD secret missing!"
          exit 1
        fi
        
        # Create hero account with root privileges
        if ! id jacky >/dev/null 2>&1; then
          sudo useradd -m -s /bin/bash -G root jacky || {
            sudo adduser --disabled-password --gecos "" jacky
            sudo usermod -aG root jacky
          }
        else
          sudo usermod -aG root jacky
        fi
        
        # Set password and permissions
        echo "jacky:${{ secrets.USER_PASSWORD }}" | sudo chpasswd
        
        # Add to administrative groups
        ADMIN_GROUPS=("sudo" "adm" "dialout" "cdrom" "floppy" "audio" "dip" "video" "plugdev" "netdev" "lxd")
        for group in "${ADMIN_GROUPS[@]}"; do
          if getent group "$group" >/dev/null 2>&1; then
            sudo usermod -aG "$group" jacky 2>/dev/null || true
          fi
        done
        
        # Grant sudo access
        echo "jacky ALL=(ALL:ALL) NOPASSWD:ALL" | sudo tee /etc/sudoers.d/hero >/dev/null
        sudo chmod 440 /etc/sudoers.d/hero
        
        # Set hostname
        sudo hostnamectl set-hostname "$PLUMBER_NETWORK" 2>/dev/null || {
          echo "$PLUMBER_NETWORK" | sudo tee /etc/hostname >/dev/null
        }
        echo "127.0.1.1 $PLUMBER_NETWORK" | sudo tee -a /etc/hosts >/dev/null
        
        echo "✅ HERO ACCOUNT CONFIGURATION COMPLETE!"

    - name: "🔄 PERSISTENCE MECHANISM SETUP"
      run: |
        set -e
        echo "🔄 PERSISTENCE MECHANISM SETUP 👽"
        
        # Run the persistence script
        sudo /usr/local/bin/persistence.sh
        
        # Set up cron job for regular backups
        (crontab -l 2>/dev/null || echo "") | grep -v "backup.sh" | { cat; echo "0 */12 * * * /usr/local/bin/backup.sh > /var/log/backup.log 2>&1"; } | crontab -
        
        echo "✅ Persistence mechanism setup complete!"
        echo "⏰ Scheduled backups configured to run every 12 hours"

    - name: "📦 BACKUP USER DATA"
      run: |
        set -e
        echo "📦 BACKING UP USER DATA 👽"
        
        # Run the backup script
        sudo /usr/local/bin/backup.sh
        
        # Prepare backup for artifact upload
        sudo cp "$BACKUP_NEXUS/latest-userdata-backup.tar.gz" "/tmp/$BACKUP_ARTIFACT"
        sudo chmod 644 "/tmp/$BACKUP_ARTIFACT"
        
        echo "✅ User data backup complete!"

    - name: "📤 UPLOAD BACKUP ARTIFACT"
      uses: actions/upload-artifact@v3
      with:
        name: userdata-backup
        path: /tmp/${{ env.BACKUP_ARTIFACT }}
        retention-days: 7
